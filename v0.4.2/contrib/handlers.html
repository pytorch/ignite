



<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="author" content="PyTorch-Ignite Contributors">
  <meta name="creator" content="PyTorch-Ignite Contributors">
  <meta name="publisher" content="PyTorch-Ignite Contributors">
  <meta name="generator" content="Sphinx 5.3.0">
  <meta name="description" content="High-level library to help with training and evaluating neural networks in PyTorch flexibly and transparently.">
  <meta name="keywords" content="pytorch, pytorch ignite, ignite, engine, events, handlers, metrics">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="theme-color" content="#ee4c2c">

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@pytorch_ignite">
  <meta name="twitter:creator" content="@pytorch_ignite">
  <meta name="twitter:description" content="High-level library to help with training and evaluating neural networks in PyTorch flexibly and transparently.">
  <meta name="twitter:title" content="ignite.contrib.handlers &mdash; PyTorch-Ignite v0.4.2 Documentation">
  <meta name="twitter:image" content="https://raw.githubusercontent.com/pytorch/ignite/master/assets/logo/ignite_logo.png">
  <meta name="twitter:image:alt" content="PyTorch-Ignite logo">

  <meta property="og:title" content="ignite.contrib.handlers &mdash; PyTorch-Ignite v0.4.2 Documentation">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://pytorch.org/ignite/">
  <meta property="og:site_name" content="PyTorch-Ignite">
  <meta property="og:image" content="https://raw.githubusercontent.com/pytorch/ignite/master/assets/logo/ignite_logo.png">
  <meta property="og:image:alt" content="PyTorch-Ignite logo">
  <meta property="og:description" content="High-level library to help with training and evaluating neural networks in PyTorch flexibly and transparently.">

  <link rel="preconnect" href="https://BH4D9OD16A-dsn.algolia.net" crossorigin />

  
  <title>ignite.contrib.handlers &mdash; PyTorch-Ignite v0.4.2 Documentation</title>
  

  
  
    <link rel="shortcut icon" type="image/svg+xml" href="../_static/ignite_logomark.svg"/>
  
  
  
    <link rel="canonical" href="https://pytorch.org/ignite/contrib/handlers.html"/>
  

  

  
  
    

  

  <link rel="preload" href="../_static/css/theme.css" as="style" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <link rel="preload" href="../_static/pygments.css" as="style" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="preload" href="../_static/css/theme.css" as="style" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="preload" href="../_static/copybutton.css" as="style" />
  <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
  <link rel="preload" href="../_static/togglebutton.css" as="style" />
  <link rel="stylesheet" href="../_static/togglebutton.css" type="text/css" />
  <link rel="preload" href="../_static/banner.css" as="style" />
  <link rel="stylesheet" href="../_static/banner.css" type="text/css" />
  <link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.css" as="style" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.css" type="text/css" />
  <link rel="preload" href="../_static/katex-math.css" as="style" />
  <link rel="stylesheet" href="../_static/katex-math.css" type="text/css" />
  <link rel="preload" href="../_static/sphinx-design.5ea377869091fd0449014c60fc090103.min.css" as="style" />
  <link rel="stylesheet" href="../_static/sphinx-design.5ea377869091fd0449014c60fc090103.min.css" type="text/css" />
    <link rel="preload" href="../_static/css/ignite_theme.css" as="style" />
    <link rel="stylesheet" href="../_static/css/ignite_theme.css" type="text/css" />
    <link rel="preload" href="https://cdn.jsdelivr.net/npm/@docsearch/css@3" as="style" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@docsearch/css@3" type="text/css" />
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="About us" href="../about.html" />
    <link rel="prev" title="ignite.contrib.metrics" href="metrics.html" /> 

  <!-- katex links / this needs to be loaded before fonts.html -->

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/katex.min.css" crossorigin="anonymous">
<script async src="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/katex.min.js" crossorigin="anonymous"></script>

<!-- Preload the theme fonts -->

<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-5FELLLFHCP"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-5FELLLFHCP');
  </script>
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">

    <a class="header-logo" href="/ignite" aria-label="PyTorch-Ignite"></a>

    <div class="header-container">

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch-ignite.ai/tutorials/beginner/01-getting-started/">Quickstart</a>
          </li>

          <li>
            <a href="https://pytorch-ignite.ai/concepts/">Concepts</a>
          </li>

          <!-- <li>
            <a href="https://pytorch-ignite.ai/tutorials/beginner/01-getting-started/#complete-code">Examples</a>
          </li> -->

          <li>
            <a href="https://pytorch-ignite.ai/how-to-guides/">FAQ</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/ignite" target="_blank" rel="noopener noreferrer">GitHub</a>
          </li>

          <li>
            <a href="https://pytorch-ignite.ai/about/community/">About us</a>
          </li>

          <li>
            <a href="https://pytorch-ignite.ai">‚ä≥ pytorch-ignite.ai</a>
          </li>


        </ul>
      </div>

      <!-- <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a> -->
    </div>

  </div>
</div>


<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <div class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></div>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  v0.4.2
                </div>
              
            

            <div id="docsearch"></div>

            
          </div>

          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quickstart.html">Quick start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../concepts.html">Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Package Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../engine.html">ignite.engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../handlers.html">ignite.handlers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../metrics.html">ignite.metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distributed.html">ignite.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exceptions.html">ignite.exceptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../utils.html">ignite.utils</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contrib Package Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="engines.html">ignite.contrib.engines</a></li>
<li class="toctree-l1"><a class="reference internal" href="metrics.html">ignite.contrib.metrics</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">ignite.contrib.handlers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Team</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../about.html">About us</a></li>
<li class="toctree-l1"><a class="reference internal" href="../governance.html">PyTorch-Ignite governance</a></li>
</ul>

            
          
        </div>
      </div>

      <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
        <span class="fa fa-book"> Other Versions</span>
        v: v0.4.2
        <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
        <dl>
            <dt>Tags</dt>
            <dd><a href="../../v0.3.0/contrib/handlers.html">v0.3.0</a></dd>
            <dd><a href="../../v0.4.0.post1/contrib/handlers.html">v0.4.0.post1</a></dd>
            <dd><a href="../../v0.4.1/contrib/handlers.html">v0.4.1</a></dd>
            <dd><a href="../../v0.4.10/contrib/handlers.html">v0.4.10</a></dd>
            <dd><a href="../../v0.4.11/contrib/handlers.html">v0.4.11</a></dd>
            <dd><a href="../../v0.4.12/contrib/handlers.html">v0.4.12</a></dd>
            <dd><a href="../../v0.4.13/contrib/handlers.html">v0.4.13</a></dd>
            <dd><a href="handlers.html">v0.4.2</a></dd>
            <dd><a href="../../v0.4.3/contrib/handlers.html">v0.4.3</a></dd>
            <dd><a href="../../v0.4.4.post1/contrib/handlers.html">v0.4.4.post1</a></dd>
            <dd><a href="../../v0.4.5/contrib/handlers.html">v0.4.5</a></dd>
            <dd><a href="../../v0.4.6/contrib/handlers.html">v0.4.6</a></dd>
            <dd><a href="../../v0.4.7/contrib/handlers.html">v0.4.7</a></dd>
            <dd><a href="../../v0.4.8/contrib/handlers.html">v0.4.8</a></dd>
            <dd><a href="../../v0.4.9/contrib/handlers.html">v0.4.9</a></dd>
            <dd><a href="../../v0.4rc.0.post1/contrib/handlers.html">v0.4rc.0.post1</a></dd>
            <dd><a href="../../v0.5.0.post2/contrib/handlers.html">v0.5.0.post2</a></dd>
            <dd><a href="../../v0.5.1/contrib/handlers.html">v0.5.1</a></dd>
            <dd><a href="../../v0.5.2/contrib/handlers.html">v0.5.2</a></dd>
            <dd><a href="../../v0.5.3/contrib/handlers.html">v0.5.3</a></dd>
        </dl>
        <dl>
            <dt>Branches</dt>
            <dd><a href="../../master/contrib/handlers.html">master</a></dd>
        </dl>
    </div>
</div>

    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li>ignite.contrib.handlers</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../_sources/contrib/handlers.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <section id="ignite-contrib-handlers">
<h1>ignite.contrib.handlers<a class="headerlink" href="#ignite-contrib-handlers" title="Permalink to this heading">#</a></h1>
<p>Contribution module of handlers</p>
<section id="module-ignite.contrib.handlers.custom_events">
<span id="custom-events"></span><h2>custom_events<a class="headerlink" href="#module-ignite.contrib.handlers.custom_events" title="Permalink to this heading">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.custom_events.CustomPeriodicEvent">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.custom_events.</span></span><span class="sig-name descname"><span class="pre">CustomPeriodicEvent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_iterations</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_epochs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/custom_events.html#CustomPeriodicEvent"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.custom_events.CustomPeriodicEvent" title="Permalink to this definition">#</a></dt>
<dd><p>DEPRECATED. Use filtered events instead.
Handler to define a custom periodic events as a number of elapsed iterations/epochs
for an engine.</p>
<p>When custom periodic event is created and attached to an engine, the following events are fired:
1) K iterations is specified:
- <cite>Events.ITERATIONS_&lt;K&gt;_STARTED</cite>
- <cite>Events.ITERATIONS_&lt;K&gt;_COMPLETED</cite></p>
<p>1) K epochs is specified:
- <cite>Events.EPOCHS_&lt;K&gt;_STARTED</cite>
- <cite>Events.EPOCHS_&lt;K&gt;_COMPLETED</cite></p>
<p>Examples:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.engine</span><span class="w"> </span><span class="kn">import</span> <span class="n">Engine</span><span class="p">,</span> <span class="n">Events</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers</span><span class="w"> </span><span class="kn">import</span> <span class="n">CustomPeriodicEvent</span>

<span class="c1"># Let&#39;s define an event every 1000 iterations</span>
<span class="n">cpe1</span> <span class="o">=</span> <span class="n">CustomPeriodicEvent</span><span class="p">(</span><span class="n">n_iterations</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">cpe1</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>

<span class="c1"># Let&#39;s define an event every 10 epochs</span>
<span class="n">cpe2</span> <span class="o">=</span> <span class="n">CustomPeriodicEvent</span><span class="p">(</span><span class="n">n_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">cpe2</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>

<span class="nd">@trainer</span><span class="o">.</span><span class="n">on</span><span class="p">(</span><span class="n">cpe1</span><span class="o">.</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATIONS_1000_COMPLETED</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">on_every_1000_iterations</span><span class="p">(</span><span class="n">engine</span><span class="p">):</span>
    <span class="c1"># run a computation after 1000 iterations</span>
    <span class="c1"># ...</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">iterations_1000</span><span class="p">)</span>

<span class="nd">@trainer</span><span class="o">.</span><span class="n">on</span><span class="p">(</span><span class="n">cpe2</span><span class="o">.</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCHS_10_STARTED</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">on_every_10_epochs</span><span class="p">(</span><span class="n">engine</span><span class="p">):</span>
    <span class="c1"># run a computation every 10 epochs</span>
    <span class="c1"># ...</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">epochs_10</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_iterations</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><em>optional</em>) ‚Äì number iterations of the custom periodic event</p></li>
<li><p><strong>n_epochs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><em>optional</em>) ‚Äì number iterations of the custom periodic event. Argument is optional, but only one,
either n_iterations or n_epochs should defined.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-ignite.contrib.handlers.param_scheduler">
<span id="param-scheduler"></span><h2>param_scheduler<a class="headerlink" href="#module-ignite.contrib.handlers.param_scheduler" title="Permalink to this heading">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.ConcatScheduler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.param_scheduler.</span></span><span class="sig-name descname"><span class="pre">ConcatScheduler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">schedulers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">durations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_history</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#ConcatScheduler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.ConcatScheduler" title="Permalink to this definition">#</a></dt>
<dd><p>Concat a list of parameter schedulers.</p>
<p>The <cite>ConcatScheduler</cite> goes through a list of schedulers given by <cite>schedulers</cite>. Duration of each
scheduler is defined by <cite>durations</cite> list of integers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>schedulers</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.14)"><em>list</em></a><em> of </em><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ParamScheduler" title="ignite.contrib.handlers.param_scheduler.ParamScheduler"><em>ParamScheduler</em></a>) ‚Äì list of parameter schedulers.</p></li>
<li><p><strong>durations</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.14)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a>) ‚Äì list of number of events that lasts a parameter scheduler from schedulers.</p></li>
<li><p><strong>save_history</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) ‚Äì whether to log the parameter values to
<cite>engine.state.param_history</cite>, (default=False).</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.param_scheduler</span><span class="w"> </span><span class="kn">import</span> <span class="n">ConcatScheduler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.param_scheduler</span><span class="w"> </span><span class="kn">import</span> <span class="n">LinearCyclicalScheduler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.param_scheduler</span><span class="w"> </span><span class="kn">import</span> <span class="n">CosineAnnealingScheduler</span>

<span class="n">scheduler_1</span> <span class="o">=</span> <span class="n">LinearCyclicalScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="n">start_value</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">cycle_size</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>
<span class="n">scheduler_2</span> <span class="o">=</span> <span class="n">CosineAnnealingScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="n">start_value</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">cycle_size</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>

<span class="n">combined_scheduler</span> <span class="o">=</span> <span class="n">ConcatScheduler</span><span class="p">(</span><span class="n">schedulers</span><span class="o">=</span><span class="p">[</span><span class="n">scheduler_1</span><span class="p">,</span> <span class="n">scheduler_2</span><span class="p">],</span> <span class="n">durations</span><span class="o">=</span><span class="p">[</span><span class="mi">30</span><span class="p">,</span> <span class="p">])</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">add_event_handler</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">,</span> <span class="n">combined_scheduler</span><span class="p">)</span>
<span class="c1">#</span>
<span class="c1"># Sets the Learning rate linearly from 0.1 to 0.5 over 30 iterations. Then</span>
<span class="c1"># starts an annealing schedule from 0.5 to 0.01 over 60 iterations.</span>
<span class="c1"># The annealing cycles are repeated indefinitely.</span>
<span class="c1">#</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.ConcatScheduler.get_param">
<span class="sig-name descname"><span class="pre">get_param</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#ConcatScheduler.get_param"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.ConcatScheduler.get_param" title="Permalink to this definition">#</a></dt>
<dd><p>Method to get current optimizer‚Äôs parameter values</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>list of params, or scalar param</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.ConcatScheduler.load_state_dict">
<span class="sig-name descname"><span class="pre">load_state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_dict</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#ConcatScheduler.load_state_dict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.ConcatScheduler.load_state_dict" title="Permalink to this definition">#</a></dt>
<dd><p>Copies parameters from <a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ConcatScheduler.state_dict" title="ignite.contrib.handlers.param_scheduler.ConcatScheduler.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> into this ConcatScheduler.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>state_dict</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.14)"><em>dict</em></a>) ‚Äì a dict containing parameters.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.ConcatScheduler.simulate_values">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">simulate_values</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_events</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">schedulers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">durations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#ConcatScheduler.simulate_values"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.ConcatScheduler.simulate_values" title="Permalink to this definition">#</a></dt>
<dd><p>Method to simulate scheduled values during num_events events.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_events</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a>) ‚Äì number of events during the simulation.</p></li>
<li><p><strong>schedulers</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.14)"><em>list</em></a><em> of </em><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ParamScheduler" title="ignite.contrib.handlers.param_scheduler.ParamScheduler"><em>ParamScheduler</em></a>) ‚Äì list of parameter schedulers.</p></li>
<li><p><strong>durations</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.14)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a>) ‚Äì list of number of events that lasts a parameter scheduler from schedulers.</p></li>
<li><p><strong>param_names</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.14)"><em>list</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.14)"><em>tuple</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) ‚Äì parameter name or list of parameter names to simulate values.
By default, the first scheduler‚Äôs parameter name is taken.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>list of [event_index, value_0, value_1, ‚Ä¶], where values correspond to <cite>param_names</cite>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.ConcatScheduler.state_dict">
<span class="sig-name descname"><span class="pre">state_dict</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#ConcatScheduler.state_dict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.ConcatScheduler.state_dict" title="Permalink to this definition">#</a></dt>
<dd><p>Returns a dictionary containing a whole state of ConcatScheduler.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a dictionary containing a whole state of ConcatScheduler</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.14)">dict</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.CosineAnnealingScheduler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.param_scheduler.</span></span><span class="sig-name descname"><span class="pre">CosineAnnealingScheduler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">start_value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">end_value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cycle_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cycle_mult</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">start_value_mult</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">end_value_mult</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_history</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_group_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#CosineAnnealingScheduler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.CosineAnnealingScheduler" title="Permalink to this definition">#</a></dt>
<dd><p>Anneals ‚Äòstart_value‚Äô to ‚Äòend_value‚Äô over each cycle.</p>
<p>The annealing takes the form of the first half of a cosine
wave (as suggested in <a class="reference internal" href="#smith17" id="id1"><span>[Smith17]</span></a>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch v2.9)"><em>torch.optim.Optimizer</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.14)"><em>object</em></a>) ‚Äì torch optimizer or any object with attribute <code class="docutils literal notranslate"><span class="pre">param_groups</span></code>
as a sequence.</p></li>
<li><p><strong>param_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) ‚Äì name of optimizer‚Äôs parameter to update.</p></li>
<li><p><strong>start_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a>) ‚Äì value at start of cycle.</p></li>
<li><p><strong>end_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a>) ‚Äì value at the end of the cycle.</p></li>
<li><p><strong>cycle_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a>) ‚Äì length of cycle.</p></li>
<li><p><strong>cycle_mult</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>optional</em>) ‚Äì ratio by which to change the cycle_size
at the end of each cycle (default=1).</p></li>
<li><p><strong>start_value_mult</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>optional</em>) ‚Äì ratio by which to change the start value at the
end of each cycle (default=1.0).</p></li>
<li><p><strong>end_value_mult</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>optional</em>) ‚Äì ratio by which to change the end value at the
end of each cycle (default=1.0).</p></li>
<li><p><strong>save_history</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) ‚Äì whether to log the parameter values to
<cite>engine.state.param_history</cite>, (default=False).</p></li>
<li><p><strong>param_group_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><em>optional</em>) ‚Äì optimizer‚Äôs parameters group to use.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If the scheduler is bound to an ‚ÄòITERATION_*‚Äô event, ‚Äòcycle_size‚Äô should
usually be the number of batches in an epoch.</p>
</div>
<p>Examples:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.param_scheduler</span><span class="w"> </span><span class="kn">import</span> <span class="n">CosineAnnealingScheduler</span>

<span class="n">scheduler</span> <span class="o">=</span> <span class="n">CosineAnnealingScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="mf">1e-1</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">))</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">add_event_handler</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">)</span>
<span class="c1">#</span>
<span class="c1"># Anneals the learning rate from 1e-1 to 1e-3 over the course of 1 epoch.</span>
<span class="c1">#</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.param_scheduler</span><span class="w"> </span><span class="kn">import</span> <span class="n">CosineAnnealingScheduler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.param_scheduler</span><span class="w"> </span><span class="kn">import</span> <span class="n">LinearCyclicalScheduler</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">{</span><span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">base</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">},</span>
        <span class="p">{</span><span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">},</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="n">scheduler1</span> <span class="o">=</span> <span class="n">LinearCyclicalScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="mf">1e-7</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">),</span> <span class="n">param_group_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">add_event_handler</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">,</span> <span class="n">scheduler1</span><span class="p">,</span> <span class="s2">&quot;lr (base)&quot;</span><span class="p">)</span>

<span class="n">scheduler2</span> <span class="o">=</span> <span class="n">CosineAnnealingScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">),</span> <span class="n">param_group_index</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">add_event_handler</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">,</span> <span class="n">scheduler2</span><span class="p">,</span> <span class="s2">&quot;lr (fc)&quot;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="citation">
<dt class="label" id="smith17"><span class="brackets"><a class="fn-backref" href="#id1">Smith17</a></span></dt>
<dd><p>Smith, Leslie N. ‚ÄúCyclical learning rates for training neural networks.‚Äù
Applications of Computer Vision (WACV), 2017 IEEE Winter Conference on. IEEE, 2017</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.CosineAnnealingScheduler.get_param">
<span class="sig-name descname"><span class="pre">get_param</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#CosineAnnealingScheduler.get_param"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.CosineAnnealingScheduler.get_param" title="Permalink to this definition">#</a></dt>
<dd><p>Method to get current optimizer‚Äôs parameter value</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.CyclicalScheduler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.param_scheduler.</span></span><span class="sig-name descname"><span class="pre">CyclicalScheduler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">start_value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">end_value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cycle_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cycle_mult</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">start_value_mult</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">end_value_mult</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_history</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_group_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#CyclicalScheduler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.CyclicalScheduler" title="Permalink to this definition">#</a></dt>
<dd><p>An abstract class for updating an optimizer‚Äôs parameter value over a
cycle of some size.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch v2.9)"><em>torch.optim.Optimizer</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.14)"><em>object</em></a>) ‚Äì torch optimizer or any object with attribute <code class="docutils literal notranslate"><span class="pre">param_groups</span></code>
as a sequence.</p></li>
<li><p><strong>param_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) ‚Äì name of optimizer‚Äôs parameter to update.</p></li>
<li><p><strong>start_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a>) ‚Äì value at start of cycle.</p></li>
<li><p><strong>end_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a>) ‚Äì value at the middle of the cycle.</p></li>
<li><p><strong>cycle_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a>) ‚Äì length of cycle, value should be larger than 1.</p></li>
<li><p><strong>cycle_mult</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>optional</em>) ‚Äì ratio by which to change the cycle_size.
at the end of each cycle (default=1.0).</p></li>
<li><p><strong>start_value_mult</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>optional</em>) ‚Äì ratio by which to change the start value at the
end of each cycle (default=1.0).</p></li>
<li><p><strong>end_value_mult</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>optional</em>) ‚Äì ratio by which to change the end value at the
end of each cycle (default=1.0).</p></li>
<li><p><strong>save_history</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) ‚Äì whether to log the parameter values to
<cite>engine.state.param_history</cite>, (default=False).</p></li>
<li><p><strong>param_group_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><em>optional</em>) ‚Äì optimizer‚Äôs parameters group to use.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If the scheduler is bound to an ‚ÄòITERATION_*‚Äô event, ‚Äòcycle_size‚Äô should
usually be the number of batches in an epoch.</p>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.LRScheduler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.param_scheduler.</span></span><span class="sig-name descname"><span class="pre">LRScheduler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lr_scheduler</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_history</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#LRScheduler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.LRScheduler" title="Permalink to this definition">#</a></dt>
<dd><p>A wrapper class to call <cite>torch.optim.lr_scheduler</cite> objects as <cite>ignite</cite> handlers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lr_scheduler</strong> (subclass of <cite>torch.optim.lr_scheduler._LRScheduler</cite>) ‚Äì lr_scheduler object to wrap.</p></li>
<li><p><strong>save_history</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) ‚Äì whether to log the parameter values to
<cite>engine.state.param_history</cite>, (default=False).</p></li>
</ul>
</dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.param_scheduler</span><span class="w"> </span><span class="kn">import</span> <span class="n">LRScheduler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim.lr_scheduler</span><span class="w"> </span><span class="kn">import</span> <span class="n">StepLR</span>

<span class="n">step_scheduler</span> <span class="o">=</span> <span class="n">StepLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">scheduler</span> <span class="o">=</span> <span class="n">LRScheduler</span><span class="p">(</span><span class="n">step_scheduler</span><span class="p">)</span>

<span class="c1"># In this example, we assume to have installed PyTorch&gt;=1.1.0</span>
<span class="c1"># (with new `torch.optim.lr_scheduler` behaviour) and</span>
<span class="c1"># we attach scheduler to Events.ITERATION_COMPLETED</span>
<span class="c1"># instead of Events.ITERATION_STARTED to make sure to use</span>
<span class="c1"># the first lr value from the optimizer, otherwise it is will be skipped:</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">add_event_handler</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.LRScheduler.get_param">
<span class="sig-name descname"><span class="pre">get_param</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#LRScheduler.get_param"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.LRScheduler.get_param" title="Permalink to this definition">#</a></dt>
<dd><p>Method to get current optimizer‚Äôs parameter value</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.14)"><em>Union</em></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)">float</a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.14)"><em>List</em></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)">float</a>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.LRScheduler.simulate_values">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">simulate_values</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_events</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr_scheduler</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#LRScheduler.simulate_values"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.LRScheduler.simulate_values" title="Permalink to this definition">#</a></dt>
<dd><p>Method to simulate scheduled values during num_events events.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_events</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a>) ‚Äì number of events during the simulation.</p></li>
<li><p><strong>lr_scheduler</strong> (subclass of <cite>torch.optim.lr_scheduler._LRScheduler</cite>) ‚Äì lr_scheduler object to wrap.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>[event_index, value]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.14)">list</a> of pairs</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.LinearCyclicalScheduler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.param_scheduler.</span></span><span class="sig-name descname"><span class="pre">LinearCyclicalScheduler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">start_value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">end_value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cycle_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cycle_mult</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">start_value_mult</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">end_value_mult</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_history</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_group_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#LinearCyclicalScheduler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.LinearCyclicalScheduler" title="Permalink to this definition">#</a></dt>
<dd><p>Linearly adjusts param value to ‚Äòend_value‚Äô for a half-cycle, then linearly
adjusts it back to ‚Äòstart_value‚Äô for a half-cycle.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch v2.9)"><em>torch.optim.Optimizer</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.14)"><em>object</em></a>) ‚Äì torch optimizer or any object with attribute <code class="docutils literal notranslate"><span class="pre">param_groups</span></code>
as a sequence.</p></li>
<li><p><strong>param_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) ‚Äì name of optimizer‚Äôs parameter to update.</p></li>
<li><p><strong>start_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a>) ‚Äì value at start of cycle.</p></li>
<li><p><strong>end_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a>) ‚Äì value at the middle of the cycle.</p></li>
<li><p><strong>cycle_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a>) ‚Äì length of cycle.</p></li>
<li><p><strong>cycle_mult</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>optional</em>) ‚Äì ratio by which to change the cycle_size
at the end of each cycle (default=1).</p></li>
<li><p><strong>start_value_mult</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>optional</em>) ‚Äì ratio by which to change the start value at the
end of each cycle (default=1.0).</p></li>
<li><p><strong>end_value_mult</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>optional</em>) ‚Äì ratio by which to change the end value at the
end of each cycle (default=1.0).</p></li>
<li><p><strong>save_history</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) ‚Äì whether to log the parameter values to
<cite>engine.state.param_history</cite>, (default=False).</p></li>
<li><p><strong>param_group_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><em>optional</em>) ‚Äì optimizer‚Äôs parameters group to use.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If the scheduler is bound to an ‚ÄòITERATION_*‚Äô event, ‚Äòcycle_size‚Äô should
usually be the number of batches in an epoch.</p>
</div>
<p>Examples:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.param_scheduler</span><span class="w"> </span><span class="kn">import</span> <span class="n">LinearCyclicalScheduler</span>

<span class="n">scheduler</span> <span class="o">=</span> <span class="n">LinearCyclicalScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="mf">1e-1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">))</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">add_event_handler</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">)</span>
<span class="c1">#</span>
<span class="c1"># Linearly increases the learning rate from 1e-3 to 1e-1 and back to 1e-3</span>
<span class="c1"># over the course of 1 epoch</span>
<span class="c1">#</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.LinearCyclicalScheduler.get_param">
<span class="sig-name descname"><span class="pre">get_param</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#LinearCyclicalScheduler.get_param"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.LinearCyclicalScheduler.get_param" title="Permalink to this definition">#</a></dt>
<dd><p>Method to get current optimizer‚Äôs parameter values</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>list of params, or scalar param</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.ParamGroupScheduler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.param_scheduler.</span></span><span class="sig-name descname"><span class="pre">ParamGroupScheduler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">schedulers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_history</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#ParamGroupScheduler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.ParamGroupScheduler" title="Permalink to this definition">#</a></dt>
<dd><p>Scheduler helper to group multiple schedulers into one.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>schedulers</strong> (<em>list/tuple</em><em> of </em><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ParamScheduler" title="ignite.contrib.handlers.param_scheduler.ParamScheduler"><em>ParamScheduler</em></a>) ‚Äì list/tuple of parameter schedulers.</p></li>
<li><p><strong>names</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.14)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) ‚Äì list of names of schedulers.</p></li>
</ul>
</dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">{</span><span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">base</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">),</span>
        <span class="p">{</span><span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">),</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="n">scheduler1</span> <span class="o">=</span> <span class="n">LinearCyclicalScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="mf">1e-7</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">),</span> <span class="n">param_group_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">scheduler2</span> <span class="o">=</span> <span class="n">CosineAnnealingScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">),</span> <span class="n">param_group_index</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">lr_schedulers</span> <span class="o">=</span> <span class="p">[</span><span class="n">scheduler1</span><span class="p">,</span> <span class="n">scheduler2</span><span class="p">]</span>
<span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;lr (base)&quot;</span><span class="p">,</span> <span class="s2">&quot;lr (fc)&quot;</span><span class="p">]</span>

<span class="n">scheduler</span> <span class="o">=</span> <span class="n">ParamGroupScheduler</span><span class="p">(</span><span class="n">schedulers</span><span class="o">=</span><span class="n">lr_schedulers</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="n">names</span><span class="p">)</span>
<span class="c1"># Attach single scheduler to the trainer</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">add_event_handler</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.ParamGroupScheduler.load_state_dict">
<span class="sig-name descname"><span class="pre">load_state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_dict</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#ParamGroupScheduler.load_state_dict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.ParamGroupScheduler.load_state_dict" title="Permalink to this definition">#</a></dt>
<dd><p>Copies parameters from <a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ParamGroupScheduler.state_dict" title="ignite.contrib.handlers.param_scheduler.ParamGroupScheduler.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> into this ParamScheduler.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>state_dict</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.14)"><em>dict</em></a>) ‚Äì a dict containing parameters.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.ParamGroupScheduler.simulate_values">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">simulate_values</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_events</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">schedulers</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#ParamGroupScheduler.simulate_values"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.ParamGroupScheduler.simulate_values" title="Permalink to this definition">#</a></dt>
<dd><p>Method to simulate scheduled values during num_events events.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_events</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a>) ‚Äì number of events during the simulation.</p></li>
<li><p><strong>lr_schedulers</strong> (subclass of <cite>torch.optim.lr_scheduler._LRScheduler</cite>) ‚Äì lr_scheduler object to wrap.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>[event_index, value]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.14)">list</a> of pairs</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.ParamGroupScheduler.state_dict">
<span class="sig-name descname"><span class="pre">state_dict</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#ParamGroupScheduler.state_dict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.ParamGroupScheduler.state_dict" title="Permalink to this definition">#</a></dt>
<dd><p>Returns a dictionary containing a whole state of ParamGroupScheduler.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a dictionary containing a whole state of ParamGroupScheduler</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.14)">dict</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.ParamScheduler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.param_scheduler.</span></span><span class="sig-name descname"><span class="pre">ParamScheduler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_history</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_group_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#ParamScheduler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.ParamScheduler" title="Permalink to this definition">#</a></dt>
<dd><p>An abstract class for updating an optimizer‚Äôs parameter value during
training.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch v2.9)"><em>torch.optim.Optimizer</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.14)"><em>object</em></a>) ‚Äì torch optimizer or any object with attribute <code class="docutils literal notranslate"><span class="pre">param_groups</span></code>
as a sequence.</p></li>
<li><p><strong>param_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) ‚Äì name of optimizer‚Äôs parameter to update.</p></li>
<li><p><strong>save_history</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) ‚Äì whether to log the parameter values to
<cite>engine.state.param_history</cite>, (default=False).</p></li>
<li><p><strong>param_group_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><em>optional</em>) ‚Äì optimizer‚Äôs parameters group to use</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Parameter scheduler works independently of the internal state of the attached optimizer.
More precisely, whatever the state of the optimizer (newly created or used by another scheduler) the scheduler
sets defined absolute values.</p>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.ParamScheduler.get_param">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_param</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#ParamScheduler.get_param"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.ParamScheduler.get_param" title="Permalink to this definition">#</a></dt>
<dd><p>Method to get current optimizer‚Äôs parameter values</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>list of params, or scalar param</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.14)"><em>Union</em></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.14)"><em>List</em></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)">float</a>], <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)">float</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.ParamScheduler.load_state_dict">
<span class="sig-name descname"><span class="pre">load_state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_dict</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#ParamScheduler.load_state_dict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.ParamScheduler.load_state_dict" title="Permalink to this definition">#</a></dt>
<dd><p>Copies parameters from <a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ParamScheduler.state_dict" title="ignite.contrib.handlers.param_scheduler.ParamScheduler.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> into this ParamScheduler.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>state_dict</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.14)"><em>dict</em></a>) ‚Äì a dict containing parameters.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.ParamScheduler.plot_values">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">plot_values</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_events</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">scheduler_kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#ParamScheduler.plot_values"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.ParamScheduler.plot_values" title="Permalink to this definition">#</a></dt>
<dd><p>Method to plot simulated scheduled values during <cite>num_events</cite> events.</p>
<p>This class requires <a class="reference external" href="https://matplotlib.org/">matplotlib package</a> to be installed:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>matplotlib
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_events</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a>) ‚Äì number of events during the simulation.</p></li>
<li><p><strong>**scheduler_kwargs</strong> ‚Äì parameter scheduler configuration kwargs.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>matplotlib.lines.Line2D</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pylab</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="n">LinearCyclicalScheduler</span><span class="o">.</span><span class="n">plot_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">param_name</span><span class="o">=</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span>
                                    <span class="n">start_value</span><span class="o">=</span><span class="mf">1e-1</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">cycle_size</span><span class="o">=</span><span class="mi">10</span><span class="p">))</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.ParamScheduler.simulate_values">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">simulate_values</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_events</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">scheduler_kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#ParamScheduler.simulate_values"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.ParamScheduler.simulate_values" title="Permalink to this definition">#</a></dt>
<dd><p>Method to simulate scheduled values during <cite>num_events</cite> events.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_events</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a>) ‚Äì number of events during the simulation.</p></li>
<li><p><strong>**scheduler_kwargs</strong> ‚Äì parameter scheduler configuration kwargs.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>[event_index, value]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.14)">list</a> of pairs</p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">lr_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">LinearCyclicalScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">param_name</span><span class="o">=</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span>
                                                             <span class="n">start_value</span><span class="o">=</span><span class="mf">1e-1</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
                                                             <span class="n">cycle_size</span><span class="o">=</span><span class="mi">10</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.ParamScheduler.state_dict">
<span class="sig-name descname"><span class="pre">state_dict</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#ParamScheduler.state_dict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.ParamScheduler.state_dict" title="Permalink to this definition">#</a></dt>
<dd><p>Returns a dictionary containing a whole state of ParamScheduler.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a dictionary containing a whole state of ParamScheduler</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.14)">dict</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.PiecewiseLinear">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.param_scheduler.</span></span><span class="sig-name descname"><span class="pre">PiecewiseLinear</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">milestones_values</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_history</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_group_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#PiecewiseLinear"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.PiecewiseLinear" title="Permalink to this definition">#</a></dt>
<dd><p>Piecewise linear parameter scheduler</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch v2.9)"><em>torch.optim.Optimizer</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.14)"><em>object</em></a>) ‚Äì torch optimizer or any object with attribute <code class="docutils literal notranslate"><span class="pre">param_groups</span></code>
as a sequence.</p></li>
<li><p><strong>param_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) ‚Äì name of optimizer‚Äôs parameter to update.</p></li>
<li><p><strong>milestones_values</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.14)"><em>list</em></a><em> of </em><em>tuples</em><em> (</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>)</em>) ‚Äì list of tuples (event index, parameter value)
represents milestones and parameter. Milestones should be increasing integers.</p></li>
<li><p><strong>save_history</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) ‚Äì whether to log the parameter values to
<cite>engine.state.param_history</cite>, (default=False).</p></li>
<li><p><strong>param_group_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><em>optional</em>) ‚Äì optimizer‚Äôs parameters group to use.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>piecewise linear scheduler</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.PiecewiseLinear" title="ignite.contrib.handlers.param_scheduler.PiecewiseLinear">PiecewiseLinear</a></p>
</dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">PiecewiseLinear</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s2">&quot;lr&quot;</span><span class="p">,</span>
                            <span class="n">milestones_values</span><span class="o">=</span><span class="p">[(</span><span class="mi">10</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mf">0.45</span><span class="p">),</span> <span class="p">(</span><span class="mi">21</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">),</span> <span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">),</span> <span class="p">(</span><span class="mi">40</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)])</span>
<span class="c1"># Attach to the trainer</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">add_event_handler</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">)</span>
<span class="c1">#</span>
<span class="c1"># Sets the learning rate to 0.5 over the first 10 iterations, then decreases linearly from 0.5 to 0.45 between</span>
<span class="c1"># 10th and 20th iterations. Next there is a jump to 0.3 at the 21st iteration and LR decreases linearly</span>
<span class="c1"># from 0.3 to 0.1 between 21st and 30th iterations and remains 0.1 until the end of the iterations.</span>
<span class="c1">#</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.PiecewiseLinear.get_param">
<span class="sig-name descname"><span class="pre">get_param</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#PiecewiseLinear.get_param"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.PiecewiseLinear.get_param" title="Permalink to this definition">#</a></dt>
<dd><p>Method to get current optimizer‚Äôs parameter values</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>list of params, or scalar param</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.create_lr_scheduler_with_warmup">
<span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.param_scheduler.</span></span><span class="sig-name descname"><span class="pre">create_lr_scheduler_with_warmup</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lr_scheduler</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warmup_start_value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warmup_duration</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warmup_end_value</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_history</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_simulated_values</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#create_lr_scheduler_with_warmup"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.create_lr_scheduler_with_warmup" title="Permalink to this definition">#</a></dt>
<dd><p>Helper method to create a learning rate scheduler with a linear warm-up.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lr_scheduler</strong> (ParamScheduler or subclass of <cite>torch.optim.lr_scheduler._LRScheduler</cite>) ‚Äì learning rate scheduler
after the warm-up.</p></li>
<li><p><strong>warmup_start_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a>) ‚Äì learning rate start value of the warm-up phase.</p></li>
<li><p><strong>warmup_duration</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a>) ‚Äì warm-up phase duration, number of events.</p></li>
<li><p><strong>warmup_end_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a>) ‚Äì learning rate end value of the warm-up phase, (default=None). If None,
warmup_end_value is set to optimizer initial lr.</p></li>
<li><p><strong>save_history</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) ‚Äì whether to log the parameter values to
<cite>engine.state.param_history</cite>, (default=False).</p></li>
<li><p><strong>output_simulated_values</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.14)"><em>list</em></a><em>, </em><em>optional</em>) ‚Äì optional output of simulated learning rate values.
If output_simulated_values is a list of None, e.g. <cite>[None] * 100</cite>, after the execution it will be filled
by 100 simulated learning rate values.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>learning rate scheduler with linear warm-up.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ConcatScheduler" title="ignite.contrib.handlers.param_scheduler.ConcatScheduler">ConcatScheduler</a></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If the first learning rate value provided by <cite>lr_scheduler</cite> is different from <cite>warmup_end_value</cite>, an additional
event is added after the warm-up phase such that the warm-up ends with <cite>warmup_end_value</cite> value and then
<cite>lr_scheduler</cite> provides its learning rate values as normally.</p>
</div>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">torch_lr_scheduler</span> <span class="o">=</span> <span class="n">ExponentialLR</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.98</span><span class="p">)</span>
<span class="n">lr_values</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span>
<span class="n">scheduler</span> <span class="o">=</span> <span class="n">create_lr_scheduler_with_warmup</span><span class="p">(</span><span class="n">torch_lr_scheduler</span><span class="p">,</span>
                                            <span class="n">warmup_start_value</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                                            <span class="n">warmup_end_value</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                                            <span class="n">warmup_duration</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                                            <span class="n">output_simulated_values</span><span class="o">=</span><span class="n">lr_values</span><span class="p">)</span>
<span class="n">lr_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">lr_values</span><span class="p">)</span>
<span class="c1"># Plot simulated values</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>

<span class="c1"># Attach to the trainer</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">add_event_handler</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="module-ignite.contrib.handlers.lr_finder">
<span id="lr-finder"></span><h2>lr_finder<a class="headerlink" href="#module-ignite.contrib.handlers.lr_finder" title="Permalink to this heading">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.lr_finder.FastaiLRFinder">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.lr_finder.</span></span><span class="sig-name descname"><span class="pre">FastaiLRFinder</span></span><a class="reference internal" href="../_modules/ignite/contrib/handlers/lr_finder.html#FastaiLRFinder"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.lr_finder.FastaiLRFinder" title="Permalink to this definition">#</a></dt>
<dd><p>Learning rate finder handler for supervised trainers.</p>
<p>While attached, the handler increases the learning rate in between two
boundaries in a linear or exponential manner. It provides valuable
information on how well the network can be trained over a range of learning
rates and what can be an optimal learning rate.</p>
<p>Examples:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers</span><span class="w"> </span><span class="kn">import</span> <span class="n">FastaiLRFinder</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">model</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="o">...</span>

<span class="n">lr_finder</span> <span class="o">=</span> <span class="n">FastaiLRFinder</span><span class="p">()</span>
<span class="n">to_save</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="n">model</span><span class="p">,</span> <span class="s2">&quot;optimizer&quot;</span><span class="p">:</span> <span class="n">optimizer</span><span class="p">}</span>

<span class="k">with</span> <span class="n">lr_finder</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">to_save</span><span class="o">=</span><span class="n">to_save</span><span class="p">)</span> <span class="k">as</span> <span class="n">trainer_with_lr_finder</span><span class="p">:</span>
    <span class="n">trainer_with_lr_finder</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span>

<span class="c1"># Get lr_finder results</span>
<span class="n">lr_finder</span><span class="o">.</span><span class="n">get_results</span><span class="p">()</span>

<span class="c1"># Plot lr_finder results (requires matplotlib)</span>
<span class="n">lr_finder</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>

<span class="c1"># get lr_finder suggestion for lr</span>
<span class="n">lr_finder</span><span class="o">.</span><span class="n">lr_suggestion</span><span class="p">()</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When context manager is exited all LR finder‚Äôs handlers are removed.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please, also keep in mind that all other handlers attached the trainer will be executed during LR finder‚Äôs run.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This class may require <cite>matplotlib</cite> package to be installed to plot learning rate range test:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>matplotlib
</pre></div>
</div>
</div>
<p class="rubric">References</p>
<p>Cyclical Learning Rates for Training Neural Networks:
<a class="reference external" href="https://arxiv.org/abs/1506.01186">https://arxiv.org/abs/1506.01186</a></p>
<p>fastai/lr_find: <a class="reference external" href="https://github.com/fastai/fastai">https://github.com/fastai/fastai</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.lr_finder.FastaiLRFinder.attach">
<span class="sig-name descname"><span class="pre">attach</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">trainer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">to_save</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_transform=&lt;function</span> <span class="pre">FastaiLRFinder.&lt;lambda&gt;&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_iter=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">end_lr=10.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">step_mode='exp'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">smooth_f=0.05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">diverge_th=5.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/lr_finder.html#FastaiLRFinder.attach"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.lr_finder.FastaiLRFinder.attach" title="Permalink to this definition">#</a></dt>
<dd><p>Attaches lr_finder to a given trainer. It also resets model and optimizer at the end of the run.</p>
<p>Usage:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>to_save = {&quot;model&quot;: model, &quot;optimizer&quot;: optimizer}
with lr_finder.attach(trainer, to_save=to_save) as trainer_with_lr_finder:
    trainer_with_lr_finder.run(dataloader)`
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>trainer</strong> (<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine" title="ignite.engine.engine.Engine"><em>Engine</em></a>) ‚Äì lr_finder is attached to this trainer. Please, keep in mind that all attached handlers
will be executed.</p></li>
<li><p><strong>to_save</strong> (<em>Mapping</em>) ‚Äì dictionary with optimizer and other objects that needs to be restored after running
the LR finder. For example, <cite>to_save={‚Äòoptimizer‚Äô: optimizer, ‚Äòmodel‚Äô: model}</cite>. All objects should
implement <cite>state_dict</cite> and <cite>load_state_dict</cite> methods.</p></li>
<li><p><strong>output_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) ‚Äì function that transforms the trainer‚Äôs <cite>state.output</cite> after each
iteration. It must return the loss of that iteration.</p></li>
<li><p><strong>num_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><em>optional</em>) ‚Äì number of iterations for lr schedule between base lr and end_lr. Default, it will
run for <cite>trainer.state.epoch_length * trainer.state.max_epochs</cite>.</p></li>
<li><p><strong>end_lr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>optional</em>) ‚Äì upper bound for lr search. Default, 10.0.</p></li>
<li><p><strong>step_mode</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) ‚Äì ‚Äúexp‚Äù or ‚Äúlinear‚Äù, which way should the lr be increased from optimizer‚Äôs initial
lr to <cite>end_lr</cite>. Default, ‚Äúexp‚Äù.</p></li>
<li><p><strong>smooth_f</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>optional</em>) ‚Äì loss smoothing factor in range <cite>[0, 1)</cite>. Default, 0.05</p></li>
<li><p><strong>diverge_th</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>optional</em>) ‚Äì Used for stopping the search when <cite>current loss &gt; diverge_th * best_loss</cite>.
Default, 5.0.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>lr_finder cannot be attached to more than one trainer at a time</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>trainer used for finding the lr</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>trainer_with_lr_finder</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.lr_finder.FastaiLRFinder.get_results">
<span class="sig-name descname"><span class="pre">get_results</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/lr_finder.html#FastaiLRFinder.get_results"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.lr_finder.FastaiLRFinder.get_results" title="Permalink to this definition">#</a></dt>
<dd><p>Returns: dictionary with loss and lr logs fromm the previous run</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.lr_finder.FastaiLRFinder.lr_suggestion">
<span class="sig-name descname"><span class="pre">lr_suggestion</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/lr_finder.html#FastaiLRFinder.lr_suggestion"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.lr_finder.FastaiLRFinder.lr_suggestion" title="Permalink to this definition">#</a></dt>
<dd><p>Returns: learning rate at the minimum numerical gradient</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.lr_finder.FastaiLRFinder.plot">
<span class="sig-name descname"><span class="pre">plot</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">skip_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_end</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_lr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/lr_finder.html#FastaiLRFinder.plot"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.lr_finder.FastaiLRFinder.plot" title="Permalink to this definition">#</a></dt>
<dd><p>Plots the learning rate range test.</p>
<p>This method requires <cite>matplotlib</cite> package to be installed:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>matplotlib
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>skip_start</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><em>optional</em>) ‚Äì number of batches to trim from the start.
Default: 10.</p></li>
<li><p><strong>skip_end</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><em>optional</em>) ‚Äì number of batches to trim from the start.
Default: 5.</p></li>
<li><p><strong>log_lr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) ‚Äì True to plot the learning rate in a logarithmic
scale; otherwise, plotted in a linear scale. Default: True.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-ignite.contrib.handlers.time_profilers">
<span id="time-profilers"></span><h2>time_profilers<a class="headerlink" href="#module-ignite.contrib.handlers.time_profilers" title="Permalink to this heading">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.time_profilers.BasicTimeProfiler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.time_profilers.</span></span><span class="sig-name descname"><span class="pre">BasicTimeProfiler</span></span><a class="reference internal" href="../_modules/ignite/contrib/handlers/time_profilers.html#BasicTimeProfiler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.time_profilers.BasicTimeProfiler" title="Permalink to this definition">#</a></dt>
<dd><p>BasicTimeProfiler can be used to profile the handlers,
events, data loading and data processing times.</p>
<p>Examples:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers</span><span class="w"> </span><span class="kn">import</span> <span class="n">BasicTimeProfiler</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">Engine</span><span class="p">(</span><span class="n">train_updater</span><span class="p">)</span>

<span class="c1"># Create an object of the profiler and attach an engine to it</span>
<span class="n">profiler</span> <span class="o">=</span> <span class="n">BasicTimeProfiler</span><span class="p">()</span>
<span class="n">profiler</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>

<span class="nd">@trainer</span><span class="o">.</span><span class="n">on</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">log_intermediate_results</span><span class="p">():</span>
    <span class="n">profiler</span><span class="o">.</span><span class="n">print_results</span><span class="p">(</span><span class="n">profiler</span><span class="o">.</span><span class="n">get_results</span><span class="p">())</span>

<span class="n">trainer</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="n">profiler</span><span class="o">.</span><span class="n">write_results</span><span class="p">(</span><span class="s1">&#39;path_to_dir/time_profiling.csv&#39;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.time_profilers.BasicTimeProfiler.get_results">
<span class="sig-name descname"><span class="pre">get_results</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/time_profilers.html#BasicTimeProfiler.get_results"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.time_profilers.BasicTimeProfiler.get_results" title="Permalink to this definition">#</a></dt>
<dd><p>Method to fetch the aggregated profiler results after the engine is run</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">results</span> <span class="o">=</span> <span class="n">profiler</span><span class="o">.</span><span class="n">get_results</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.time_profilers.BasicTimeProfiler.print_results">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">print_results</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">results</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/time_profilers.html#BasicTimeProfiler.print_results"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.time_profilers.BasicTimeProfiler.print_results" title="Permalink to this definition">#</a></dt>
<dd><p>Method to print the aggregated results from the profiler</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">profiler</span><span class="o">.</span><span class="n">print_results</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</pre></div>
</div>
<p>Example output:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span> ----------------------------------------------------
| Time profiling stats (in seconds):                 |
 ----------------------------------------------------
total  |  min/index  |  max/index  |  mean  |  std

Processing function:
157.46292 | 0.01452/1501 | 0.26905/0 | 0.07730 | 0.01258

Dataflow:
6.11384 | 0.00008/1935 | 0.28461/1551 | 0.00300 | 0.02693

Event handlers:
2.82721

- Events.STARTED: []
0.00000

- Events.EPOCH_STARTED: []
0.00006 | 0.00000/0 | 0.00000/17 | 0.00000 | 0.00000

- Events.ITERATION_STARTED: [&#39;PiecewiseLinear&#39;]
0.03482 | 0.00001/188 | 0.00018/679 | 0.00002 | 0.00001

- Events.ITERATION_COMPLETED: [&#39;TerminateOnNan&#39;]
0.20037 | 0.00006/866 | 0.00089/1943 | 0.00010 | 0.00003

- Events.EPOCH_COMPLETED: [&#39;empty_cuda_cache&#39;, &#39;training.&lt;locals&gt;.log_elapsed_time&#39;, ]
2.57860 | 0.11529/0 | 0.14977/13 | 0.12893 | 0.00790

- Events.COMPLETED: []
not yet triggered
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.time_profilers.BasicTimeProfiler.write_results">
<span class="sig-name descname"><span class="pre">write_results</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_path</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/time_profilers.html#BasicTimeProfiler.write_results"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.time_profilers.BasicTimeProfiler.write_results" title="Permalink to this definition">#</a></dt>
<dd><p>Method to store the unaggregated profiling results to a csv file</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">profiler</span><span class="o">.</span><span class="n">write_results</span><span class="p">(</span><span class="s1">&#39;path_to_dir/awesome_filename.csv&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Example output:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>-----------------------------------------------------------------
epoch iteration processing_stats dataflow_stats Event_STARTED ...
1.0     1.0        0.00003         0.252387        0.125676
1.0     2.0        0.00029         0.252342        0.125123
</pre></div>
</div>
</dd></dl>

</dd></dl>

</section>
<section id="tensorboard-logger">
<h2>tensorboard_logger<a class="headerlink" href="#tensorboard-logger" title="Permalink to this heading">#</a></h2>
<p>See <a class="reference external" href="https://github.com/pytorch/ignite/blob/master/examples/contrib/mnist/mnist_with_tensorboard_logger.py">tensorboardX mnist example</a>
and <a class="reference external" href="https://github.com/pytorch/ignite/tree/master/examples/notebooks">CycleGAN and EfficientNet notebooks</a> for detailed usage.</p>
<span class="target" id="module-ignite.contrib.handlers.tensorboard_logger"></span><dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.tensorboard_logger.GradsHistHandler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.tensorboard_logger.</span></span><span class="sig-name descname"><span class="pre">GradsHistHandler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tag</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/tensorboard_logger.html#GradsHistHandler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.tensorboard_logger.GradsHistHandler" title="Permalink to this definition">#</a></dt>
<dd><p>Helper handler to log model‚Äôs gradients as histograms.</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.tensorboard_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">tb_logger</span> <span class="o">=</span> <span class="n">TensorboardLogger</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;experiments/tb_logs&quot;</span><span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log model&#39;s weights norm after each iteration</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">,</span>
    <span class="n">log_handler</span><span class="o">=</span><span class="n">GradsHistHandler</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.9)"><em>torch.nn.Module</em></a>) ‚Äì model to log weights</p></li>
<li><p><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) ‚Äì common title for all produced plots. For example, ‚Äúgenerator‚Äù</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.tensorboard_logger.GradsScalarHandler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.tensorboard_logger.</span></span><span class="sig-name descname"><span class="pre">GradsScalarHandler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction=&lt;function</span> <span class="pre">norm&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tag=None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/tensorboard_logger.html#GradsScalarHandler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.tensorboard_logger.GradsScalarHandler" title="Permalink to this definition">#</a></dt>
<dd><p>Helper handler to log model‚Äôs gradients as scalars.
Handler iterates over the gradients of named parameters of the model, applies reduction function to each parameter
produce a scalar and then logs the scalar.</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.tensorboard_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">tb_logger</span> <span class="o">=</span> <span class="n">TensorboardLogger</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;experiments/tb_logs&quot;</span><span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log model&#39;s weights norm after each iteration</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">,</span>
    <span class="n">log_handler</span><span class="o">=</span><span class="n">GradsScalarHandler</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.9)"><em>torch.nn.Module</em></a>) ‚Äì model to log weights</p></li>
<li><p><strong>reduction</strong> (<em>callable</em>) ‚Äì function to reduce parameters into scalar</p></li>
<li><p><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) ‚Äì common title for all produced plots. For example, ‚Äúgenerator‚Äù</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.tensorboard_logger.OptimizerParamsHandler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.tensorboard_logger.</span></span><span class="sig-name descname"><span class="pre">OptimizerParamsHandler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'lr'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tag</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/tensorboard_logger.html#OptimizerParamsHandler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.tensorboard_logger.OptimizerParamsHandler" title="Permalink to this definition">#</a></dt>
<dd><p>Helper handler to log optimizer parameters</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.tensorboard_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">tb_logger</span> <span class="o">=</span> <span class="n">TensorboardLogger</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;experiments/tb_logs&quot;</span><span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log optimizer&#39;s parameters, e.g. learning rate at each iteration</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">log_handler</span><span class="o">=</span><span class="n">OptimizerParamsHandler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">),</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span>
<span class="p">)</span>
<span class="c1"># or equivalently</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach_opt_params_handler</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch v2.9)"><em>torch.optim.Optimizer</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.14)"><em>object</em></a>) ‚Äì torch optimizer or any object with attribute <code class="docutils literal notranslate"><span class="pre">param_groups</span></code>
as a sequence.</p></li>
<li><p><strong>param_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) ‚Äì parameter name</p></li>
<li><p><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) ‚Äì common title for all produced plots. For example, ‚Äúgenerator‚Äù</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.tensorboard_logger.OutputHandler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.tensorboard_logger.</span></span><span class="sig-name descname"><span class="pre">OutputHandler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tag</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">global_step_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/tensorboard_logger.html#OutputHandler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.tensorboard_logger.OutputHandler" title="Permalink to this definition">#</a></dt>
<dd><p>Helper handler to log engine‚Äôs output and/or metrics</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.tensorboard_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">tb_logger</span> <span class="o">=</span> <span class="n">TensorboardLogger</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;experiments/tb_logs&quot;</span><span class="p">)</span>

<span class="c1"># Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="c1"># each epoch. We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch</span>
<span class="c1"># of the `trainer`:</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span>
    <span class="n">evaluator</span><span class="p">,</span>
    <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span>
        <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
        <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
        <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>
    <span class="p">),</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span>
<span class="p">)</span>
<span class="c1"># or equivalently</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach_output_handler</span><span class="p">(</span>
    <span class="n">evaluator</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">,</span>
    <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
    <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Another example, where model is evaluated every 500 iterations:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.tensorboard_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="nd">@trainer</span><span class="o">.</span><span class="n">on</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">(</span><span class="n">every</span><span class="o">=</span><span class="mi">500</span><span class="p">))</span>
<span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span><span class="n">engine</span><span class="p">):</span>
    <span class="n">evaluator</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">validation_set</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">tb_logger</span> <span class="o">=</span> <span class="n">TensorboardLogger</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;experiments/tb_logs&quot;</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">global_step_transform</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">trainer</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">iteration</span>

<span class="c1"># Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="c1"># every 500 iterations. Since evaluator engine does not have access to the training iteration, we</span>
<span class="c1"># provide a global_step_transform to return the trainer.state.iteration for the global_step, each time</span>
<span class="c1"># evaluator metrics are plotted on Tensorboard.</span>

<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach_output_handler</span><span class="p">(</span>
    <span class="n">evaluator</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">,</span>
    <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
    <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_transform</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) ‚Äì common title for all produced plots. For example, ‚Äútraining‚Äù</p></li>
<li><p><strong>metric_names</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.14)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) ‚Äì list of metric names to plot or a string ‚Äúall‚Äù to plot all available
metrics.</p></li>
<li><p><strong>output_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) ‚Äì output transform function to prepare <cite>engine.state.output</cite> as a number.
For example, <cite>output_transform = lambda output: output</cite>
This function can also return a dictionary, e.g <cite>{‚Äúloss‚Äù: loss1, ‚Äúanother_loss‚Äù: loss2}</cite> to label the plot
with corresponding keys.</p></li>
<li><p><strong>global_step_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) ‚Äì global step transform function to output a desired global step.
Input of the function is <cite>(engine, event_name)</cite>. Output of function should be an integer.
Default is None, global_step based on attached engine. If provided,
uses function output as global_step. To setup global step from another engine, please use
<a class="reference internal" href="#ignite.contrib.handlers.tensorboard_logger.global_step_from_engine" title="ignite.contrib.handlers.tensorboard_logger.global_step_from_engine"><code class="xref py py-meth docutils literal notranslate"><span class="pre">global_step_from_engine()</span></code></a>.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Example of <cite>global_step_transform</cite>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">global_step_transform</span><span class="p">(</span><span class="n">engine</span><span class="p">,</span> <span class="n">event_name</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">get_event_attrib_value</span><span class="p">(</span><span class="n">event_name</span><span class="p">)</span>
</pre></div>
</div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.tensorboard_logger.TensorboardLogger">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.tensorboard_logger.</span></span><span class="sig-name descname"><span class="pre">TensorboardLogger</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/tensorboard_logger.html#TensorboardLogger"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.tensorboard_logger.TensorboardLogger" title="Permalink to this definition">#</a></dt>
<dd><p>TensorBoard handler to log metrics, model/optimizer parameters, gradients during the training and validation.</p>
<p>By default, this class favors <a class="reference external" href="https://github.com/lanpa/tensorboardX">tensorboardX</a> package if installed:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>tensorboardX
</pre></div>
</div>
<p>otherwise, it falls back to using
<a class="reference external" href="https://pytorch.org/docs/stable/tensorboard.html">PyTorch‚Äôs SummaryWriter</a>
(&gt;=v1.2.0).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>*args</strong> ‚Äì Positional arguments accepted from
<a class="reference external" href="https://pytorch.org/docs/stable/tensorboard.html">SummaryWriter</a>.</p></li>
<li><p><strong>**kwargs</strong> ‚Äì <p>Keyword arguments accepted from
<a class="reference external" href="https://pytorch.org/docs/stable/tensorboard.html">SummaryWriter</a>.
For example, <cite>log_dir</cite> to setup path to the directory where to log.</p>
</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.tensorboard_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">tb_logger</span> <span class="o">=</span> <span class="n">TensorboardLogger</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;experiments/tb_logs&quot;</span><span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log training loss at each iteration</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach_output_handler</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">,</span>
    <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;training&quot;</span><span class="p">,</span>
    <span class="n">output_transform</span><span class="o">=</span><span class="k">lambda</span> <span class="n">loss</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="n">loss</span><span class="p">}</span>
<span class="p">)</span>

<span class="c1"># Attach the logger to the evaluator on the training dataset and log NLL, Accuracy metrics after each epoch</span>
<span class="c1"># We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch</span>
<span class="c1"># of the `trainer` instead of `train_evaluator`.</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach_output_handler</span><span class="p">(</span>
    <span class="n">train_evaluator</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">,</span>
    <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;training&quot;</span><span class="p">,</span>
    <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
    <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">),</span>
<span class="p">)</span>

<span class="c1"># Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="c1"># each epoch. We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch of the</span>
<span class="c1"># `trainer` instead of `evaluator`.</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach_output_handler</span><span class="p">(</span>
    <span class="n">evaluator</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">,</span>
    <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
    <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">)),</span>
<span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log optimizer&#39;s parameters, e.g. learning rate at each iteration</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach_opt_params_handler</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
    <span class="n">param_name</span><span class="o">=</span><span class="s1">&#39;lr&#39;</span>  <span class="c1"># optional</span>
<span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log model&#39;s weights norm after each iteration</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">,</span>
    <span class="n">log_handler</span><span class="o">=</span><span class="n">WeightsScalarHandler</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log model&#39;s weights as a histogram after each epoch</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">,</span>
    <span class="n">log_handler</span><span class="o">=</span><span class="n">WeightsHistHandler</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log model&#39;s gradients norm after each iteration</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">,</span>
    <span class="n">log_handler</span><span class="o">=</span><span class="n">GradsScalarHandler</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log model&#39;s gradients as a histogram after each epoch</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">,</span>
    <span class="n">log_handler</span><span class="o">=</span><span class="n">GradsHistHandler</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># We need to close the logger with we are done</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
<p>It is also possible to use the logger as context manager:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.tensorboard_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="k">with</span> <span class="n">TensorboardLogger</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;experiments/tb_logs&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">tb_logger</span><span class="p">:</span>

    <span class="n">trainer</span> <span class="o">=</span> <span class="n">Engine</span><span class="p">(</span><span class="n">update_fn</span><span class="p">)</span>
    <span class="c1"># Attach the logger to the trainer to log training loss at each iteration</span>
    <span class="n">tb_logger</span><span class="o">.</span><span class="n">attach_output_handler</span><span class="p">(</span>
        <span class="n">trainer</span><span class="p">,</span>
        <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">,</span>
        <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;training&quot;</span><span class="p">,</span>
        <span class="n">output_transform</span><span class="o">=</span><span class="k">lambda</span> <span class="n">loss</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="n">loss</span><span class="p">}</span>
    <span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.tensorboard_logger.TensorboardLogger.attach">
<span class="sig-name descname"><span class="pre">attach</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">engine</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_handler</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">event_name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ignite.contrib.handlers.tensorboard_logger.TensorboardLogger.attach" title="Permalink to this definition">#</a></dt>
<dd><p>Attach the logger to the engine and execute <cite>log_handler</cite> function at <cite>event_name</cite> events.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine" title="ignite.engine.engine.Engine"><em>Engine</em></a>) ‚Äì engine object.</p></li>
<li><p><strong>log_handler</strong> (<em>callable</em>) ‚Äì a logging handler to execute</p></li>
<li><p><strong>event_name</strong> ‚Äì event to attach the logging handler to. Valid events are from
<a class="reference internal" href="../engine.html#ignite.engine.events.Events" title="ignite.engine.events.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a> or any <cite>event_name</cite> added by
<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine.register_events" title="ignite.engine.engine.Engine.register_events"><code class="xref py py-meth docutils literal notranslate"><span class="pre">register_events()</span></code></a>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">RemovableEventHandle</span></code>, which can be used to remove the handler.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.tensorboard_logger.TensorboardLogger.attach_opt_params_handler">
<span class="sig-name descname"><span class="pre">attach_opt_params_handler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">engine</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">event_name</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ignite.contrib.handlers.tensorboard_logger.TensorboardLogger.attach_opt_params_handler" title="Permalink to this definition">#</a></dt>
<dd><p>Shortcut method to attach <cite>OptimizerParamsHandler</cite> to the logger.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine" title="ignite.engine.engine.Engine"><em>Engine</em></a>) ‚Äì engine object.</p></li>
<li><p><strong>event_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.14)"><em>Any</em></a>) ‚Äì event to attach the logging handler to. Valid events are from
<a class="reference internal" href="../engine.html#ignite.engine.events.Events" title="ignite.engine.events.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a> or any <cite>event_name</cite> added by
<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine.register_events" title="ignite.engine.engine.Engine.register_events"><code class="xref py py-meth docutils literal notranslate"><span class="pre">register_events()</span></code></a>.</p></li>
<li><p><strong>*args</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.14)"><em>Any</em></a>) ‚Äì args to initialize <cite>OptimizerParamsHandler</cite></p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Mapping" title="(in Python v3.14)"><em>Mapping</em></a>) ‚Äì kwargs to initialize <cite>OptimizerParamsHandler</cite></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">RemovableEventHandle</span></code>, which can be used to remove the handler.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.tensorboard_logger.TensorboardLogger.attach_output_handler">
<span class="sig-name descname"><span class="pre">attach_output_handler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">engine</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">event_name</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ignite.contrib.handlers.tensorboard_logger.TensorboardLogger.attach_output_handler" title="Permalink to this definition">#</a></dt>
<dd><p>Shortcut method to attach <cite>OutputHandler</cite> to the logger.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine" title="ignite.engine.engine.Engine"><em>Engine</em></a>) ‚Äì engine object.</p></li>
<li><p><strong>event_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.14)"><em>Any</em></a>) ‚Äì event to attach the logging handler to. Valid events are from
<a class="reference internal" href="../engine.html#ignite.engine.events.Events" title="ignite.engine.events.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a> or any <cite>event_name</cite> added by
<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine.register_events" title="ignite.engine.engine.Engine.register_events"><code class="xref py py-meth docutils literal notranslate"><span class="pre">register_events()</span></code></a>.</p></li>
<li><p><strong>*args</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.14)"><em>Any</em></a>) ‚Äì args to initialize <cite>OutputHandler</cite></p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Mapping" title="(in Python v3.14)"><em>Mapping</em></a>) ‚Äì kwargs to initialize <cite>OutputHandler</cite></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">RemovableEventHandle</span></code>, which can be used to remove the handler.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.tensorboard_logger.WeightsHistHandler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.tensorboard_logger.</span></span><span class="sig-name descname"><span class="pre">WeightsHistHandler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tag</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/tensorboard_logger.html#WeightsHistHandler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.tensorboard_logger.WeightsHistHandler" title="Permalink to this definition">#</a></dt>
<dd><p>Helper handler to log model‚Äôs weights as histograms.</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.tensorboard_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">tb_logger</span> <span class="o">=</span> <span class="n">TensorboardLogger</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;experiments/tb_logs&quot;</span><span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log model&#39;s weights norm after each iteration</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">,</span>
    <span class="n">log_handler</span><span class="o">=</span><span class="n">WeightsHistHandler</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.9)"><em>torch.nn.Module</em></a>) ‚Äì model to log weights</p></li>
<li><p><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) ‚Äì common title for all produced plots. For example, ‚Äúgenerator‚Äù</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.tensorboard_logger.WeightsScalarHandler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.tensorboard_logger.</span></span><span class="sig-name descname"><span class="pre">WeightsScalarHandler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction=&lt;function</span> <span class="pre">norm&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tag=None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/tensorboard_logger.html#WeightsScalarHandler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.tensorboard_logger.WeightsScalarHandler" title="Permalink to this definition">#</a></dt>
<dd><p>Helper handler to log model‚Äôs weights as scalars.
Handler iterates over named parameters of the model, applies reduction function to each parameter
produce a scalar and then logs the scalar.</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.tensorboard_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">tb_logger</span> <span class="o">=</span> <span class="n">TensorboardLogger</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;experiments/tb_logs&quot;</span><span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log model&#39;s weights norm after each iteration</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">,</span>
    <span class="n">log_handler</span><span class="o">=</span><span class="n">WeightsScalarHandler</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.9)"><em>torch.nn.Module</em></a>) ‚Äì model to log weights</p></li>
<li><p><strong>reduction</strong> (<em>callable</em>) ‚Äì function to reduce parameters into scalar</p></li>
<li><p><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) ‚Äì common title for all produced plots. For example, ‚Äúgenerator‚Äù</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ignite.contrib.handlers.tensorboard_logger.global_step_from_engine">
<span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.tensorboard_logger.</span></span><span class="sig-name descname"><span class="pre">global_step_from_engine</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">engine</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_event_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/handlers.html#global_step_from_engine"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.tensorboard_logger.global_step_from_engine" title="Permalink to this definition">#</a></dt>
<dd><p>Helper method to setup <cite>global_step_transform</cite> function using another engine.
This can be helpful for logging trainer epoch/iteration while output handler is attached to an evaluator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine" title="ignite.engine.engine.Engine"><em>Engine</em></a>) ‚Äì engine which state is used to provide the global step</p></li>
<li><p><strong>custom_event_name</strong> (<em>optional</em>) ‚Äì registered event name. Optional argument, event name to use.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>global step</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Callable" title="(in Python v3.14)"><em>Callable</em></a></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="visdom-logger">
<h2>visdom_logger<a class="headerlink" href="#visdom-logger" title="Permalink to this heading">#</a></h2>
<p>See <a class="reference external" href="https://github.com/pytorch/ignite/blob/master/examples/contrib/mnist/mnist_with_visdom_logger.py">visdom mnist example</a>
for detailed usage.</p>
<span class="target" id="module-ignite.contrib.handlers.visdom_logger"></span><dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.visdom_logger.GradsScalarHandler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.visdom_logger.</span></span><span class="sig-name descname"><span class="pre">GradsScalarHandler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction=&lt;function</span> <span class="pre">norm&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tag=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_legend=False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/visdom_logger.html#GradsScalarHandler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.visdom_logger.GradsScalarHandler" title="Permalink to this definition">#</a></dt>
<dd><p>Helper handler to log model‚Äôs gradients as scalars.
Handler iterates over the gradients of named parameters of the model, applies reduction function to each parameter
produce a scalar and then logs the scalar.</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.visdom_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">vd_logger</span> <span class="o">=</span> <span class="n">VisdomLogger</span><span class="p">()</span>

<span class="c1"># Attach the logger to the trainer to log model&#39;s weights norm after each iteration</span>
<span class="n">vd_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">,</span>
    <span class="n">log_handler</span><span class="o">=</span><span class="n">GradsScalarHandler</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.9)"><em>torch.nn.Module</em></a>) ‚Äì model to log weights</p></li>
<li><p><strong>reduction</strong> (<em>callable</em>) ‚Äì function to reduce parameters into scalar</p></li>
<li><p><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) ‚Äì common title for all produced plots. For example, ‚Äúgenerator‚Äù</p></li>
<li><p><strong>show_legend</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) ‚Äì flag to show legend in the window</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.visdom_logger.GradsScalarHandler.add_scalar">
<span class="sig-name descname"><span class="pre">add_scalar</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">logger</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">event_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">global_step</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ignite.contrib.handlers.visdom_logger.GradsScalarHandler.add_scalar" title="Permalink to this definition">#</a></dt>
<dd><p>Helper method to log a scalar with VisdomLogger.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>logger</strong> (<a class="reference internal" href="#ignite.contrib.handlers.visdom_logger.VisdomLogger" title="ignite.contrib.handlers.visdom_logger.VisdomLogger"><em>VisdomLogger</em></a>) ‚Äì visdom logger</p></li>
<li><p><strong>k</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) ‚Äì scalar name which is used to set window title and y-axis label</p></li>
<li><p><strong>v</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a>) ‚Äì scalar value, y-axis value</p></li>
<li><p><strong>event_name</strong> ‚Äì Event name which is used to setup x-axis label. Valid events are from
<a class="reference internal" href="../engine.html#ignite.engine.events.Events" title="ignite.engine.events.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a> or any <cite>event_name</cite> added by
<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine.register_events" title="ignite.engine.engine.Engine.register_events"><code class="xref py py-meth docutils literal notranslate"><span class="pre">register_events()</span></code></a>.</p></li>
<li><p><strong>global_step</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a>) ‚Äì global step, x-axis value</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.visdom_logger.OptimizerParamsHandler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.visdom_logger.</span></span><span class="sig-name descname"><span class="pre">OptimizerParamsHandler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'lr'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tag</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_legend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/visdom_logger.html#OptimizerParamsHandler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.visdom_logger.OptimizerParamsHandler" title="Permalink to this definition">#</a></dt>
<dd><p>Helper handler to log optimizer parameters</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.visdom_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">vb_logger</span> <span class="o">=</span> <span class="n">VisdomLogger</span><span class="p">()</span>

<span class="c1"># Attach the logger to the trainer to log optimizer&#39;s parameters, e.g. learning rate at each iteration</span>
<span class="n">vd_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">log_handler</span><span class="o">=</span><span class="n">OptimizerParamsHandler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">),</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span>
<span class="p">)</span>
<span class="c1"># or equivalently</span>
<span class="n">vd_logger</span><span class="o">.</span><span class="n">attach_opt_params_handler</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch v2.9)"><em>torch.optim.Optimizer</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.14)"><em>object</em></a>) ‚Äì torch optimizer or any object with attribute <code class="docutils literal notranslate"><span class="pre">param_groups</span></code>
as a sequence.</p></li>
<li><p><strong>param_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) ‚Äì parameter name</p></li>
<li><p><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) ‚Äì common title for all produced plots. For example, ‚Äúgenerator‚Äù</p></li>
<li><p><strong>show_legend</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) ‚Äì flag to show legend in the window</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.visdom_logger.OptimizerParamsHandler.add_scalar">
<span class="sig-name descname"><span class="pre">add_scalar</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">logger</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">event_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">global_step</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ignite.contrib.handlers.visdom_logger.OptimizerParamsHandler.add_scalar" title="Permalink to this definition">#</a></dt>
<dd><p>Helper method to log a scalar with VisdomLogger.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>logger</strong> (<a class="reference internal" href="#ignite.contrib.handlers.visdom_logger.VisdomLogger" title="ignite.contrib.handlers.visdom_logger.VisdomLogger"><em>VisdomLogger</em></a>) ‚Äì visdom logger</p></li>
<li><p><strong>k</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) ‚Äì scalar name which is used to set window title and y-axis label</p></li>
<li><p><strong>v</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a>) ‚Äì scalar value, y-axis value</p></li>
<li><p><strong>event_name</strong> ‚Äì Event name which is used to setup x-axis label. Valid events are from
<a class="reference internal" href="../engine.html#ignite.engine.events.Events" title="ignite.engine.events.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a> or any <cite>event_name</cite> added by
<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine.register_events" title="ignite.engine.engine.Engine.register_events"><code class="xref py py-meth docutils literal notranslate"><span class="pre">register_events()</span></code></a>.</p></li>
<li><p><strong>global_step</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a>) ‚Äì global step, x-axis value</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.visdom_logger.OutputHandler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.visdom_logger.</span></span><span class="sig-name descname"><span class="pre">OutputHandler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tag</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">global_step_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_legend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/visdom_logger.html#OutputHandler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.visdom_logger.OutputHandler" title="Permalink to this definition">#</a></dt>
<dd><p>Helper handler to log engine‚Äôs output and/or metrics</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.visdom_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">vd_logger</span> <span class="o">=</span> <span class="n">VisdomLogger</span><span class="p">()</span>

<span class="c1"># Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="c1"># each epoch. We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch</span>
<span class="c1"># of the `trainer`:</span>
<span class="n">vd_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span>
    <span class="n">evaluator</span><span class="p">,</span>
    <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span>
        <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
        <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
        <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>
    <span class="p">),</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span>
<span class="p">)</span>
<span class="c1"># or equivalently</span>
<span class="n">vd_logger</span><span class="o">.</span><span class="n">attach_output_handler</span><span class="p">(</span>
    <span class="n">evaluator</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">,</span>
    <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
    <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Another example, where model is evaluated every 500 iterations:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.visdom_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="nd">@trainer</span><span class="o">.</span><span class="n">on</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">(</span><span class="n">every</span><span class="o">=</span><span class="mi">500</span><span class="p">))</span>
<span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span><span class="n">engine</span><span class="p">):</span>
    <span class="n">evaluator</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">validation_set</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">vd_logger</span> <span class="o">=</span> <span class="n">VisdomLogger</span><span class="p">()</span>

<span class="k">def</span><span class="w"> </span><span class="nf">global_step_transform</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">trainer</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">iteration</span>

<span class="c1"># Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="c1"># every 500 iterations. Since evaluator engine does not have access to the training iteration, we</span>
<span class="c1"># provide a global_step_transform to return the trainer.state.iteration for the global_step, each time</span>
<span class="c1"># evaluator metrics are plotted on Visdom.</span>

<span class="n">vd_logger</span><span class="o">.</span><span class="n">attach_output_handler</span><span class="p">(</span>
    <span class="n">evaluator</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">,</span>
    <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
    <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_transform</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) ‚Äì common title for all produced plots. For example, ‚Äútraining‚Äù</p></li>
<li><p><strong>metric_names</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.14)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) ‚Äì list of metric names to plot or a string ‚Äúall‚Äù to plot all available
metrics.</p></li>
<li><p><strong>output_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) ‚Äì output transform function to prepare <cite>engine.state.output</cite> as a number.
For example, <cite>output_transform = lambda output: output</cite>
This function can also return a dictionary, e.g <cite>{‚Äúloss‚Äù: loss1, ‚Äúanother_loss‚Äù: loss2}</cite> to label the plot
with corresponding keys.</p></li>
<li><p><strong>global_step_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) ‚Äì global step transform function to output a desired global step.
Input of the function is <cite>(engine, event_name)</cite>. Output of function should be an integer.
Default is None, global_step based on attached engine. If provided,
uses function output as global_step. To setup global step from another engine, please use
<a class="reference internal" href="#ignite.contrib.handlers.visdom_logger.global_step_from_engine" title="ignite.contrib.handlers.visdom_logger.global_step_from_engine"><code class="xref py py-meth docutils literal notranslate"><span class="pre">global_step_from_engine()</span></code></a>.</p></li>
<li><p><strong>show_legend</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) ‚Äì flag to show legend in the window</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Example of <cite>global_step_transform</cite>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">global_step_transform</span><span class="p">(</span><span class="n">engine</span><span class="p">,</span> <span class="n">event_name</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">get_event_attrib_value</span><span class="p">(</span><span class="n">event_name</span><span class="p">)</span>
</pre></div>
</div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.visdom_logger.OutputHandler.add_scalar">
<span class="sig-name descname"><span class="pre">add_scalar</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">logger</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">event_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">global_step</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ignite.contrib.handlers.visdom_logger.OutputHandler.add_scalar" title="Permalink to this definition">#</a></dt>
<dd><p>Helper method to log a scalar with VisdomLogger.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>logger</strong> (<a class="reference internal" href="#ignite.contrib.handlers.visdom_logger.VisdomLogger" title="ignite.contrib.handlers.visdom_logger.VisdomLogger"><em>VisdomLogger</em></a>) ‚Äì visdom logger</p></li>
<li><p><strong>k</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) ‚Äì scalar name which is used to set window title and y-axis label</p></li>
<li><p><strong>v</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a>) ‚Äì scalar value, y-axis value</p></li>
<li><p><strong>event_name</strong> ‚Äì Event name which is used to setup x-axis label. Valid events are from
<a class="reference internal" href="../engine.html#ignite.engine.events.Events" title="ignite.engine.events.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a> or any <cite>event_name</cite> added by
<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine.register_events" title="ignite.engine.engine.Engine.register_events"><code class="xref py py-meth docutils literal notranslate"><span class="pre">register_events()</span></code></a>.</p></li>
<li><p><strong>global_step</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a>) ‚Äì global step, x-axis value</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.visdom_logger.VisdomLogger">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.visdom_logger.</span></span><span class="sig-name descname"><span class="pre">VisdomLogger</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">server</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">port</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_workers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raise_exceptions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/visdom_logger.html#VisdomLogger"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.visdom_logger.VisdomLogger" title="Permalink to this definition">#</a></dt>
<dd><p>VisdomLogger handler to log metrics, model/optimizer parameters, gradients during the training and validation.</p>
<p>This class requires <a class="reference external" href="https://github.com/facebookresearch/visdom/">visdom</a> package to be installed:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>git+https://github.com/facebookresearch/visdom.git
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>server</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) ‚Äì visdom server URL. It can be also specified by environment variable <cite>VISDOM_SERVER_URL</cite></p></li>
<li><p><strong>port</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><em>optional</em>) ‚Äì visdom server‚Äôs port. It can be also specified by environment variable <cite>VISDOM_PORT</cite></p></li>
<li><p><strong>num_workers</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><em>optional</em>) ‚Äì number of workers to use in <cite>concurrent.futures.ThreadPoolExecutor</cite> to post data to
visdom server. Default, <cite>num_workers=1</cite>. If <cite>num_workers=0</cite> and logger uses the main thread. If using
Python 2.7 and <cite>num_workers&gt;0</cite> the package <cite>futures</cite> should be installed: <cite>pip install futures</cite></p></li>
<li><p><strong>**kwargs</strong> ‚Äì kwargs to pass into
<a class="reference external" href="https://github.com/facebookresearch/visdom#visdom-arguments-python-only">visdom.Visdom</a>.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We can also specify username/password using environment variables: VISDOM_USERNAME, VISDOM_PASSWORD</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Frequent logging, e.g. when logger is attached to <cite>Events.ITERATION_COMPLETED</cite>, can slow down the run if the
main thread is used to send the data to visdom server (<cite>num_workers=0</cite>). To avoid this situation we can either
log less frequently or set <cite>num_workers=1</cite>.</p>
</div>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.visdom_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">vd_logger</span> <span class="o">=</span> <span class="n">VisdomLogger</span><span class="p">()</span>

<span class="c1"># Attach the logger to the trainer to log training loss at each iteration</span>
<span class="n">vd_logger</span><span class="o">.</span><span class="n">attach_output_handler</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">,</span>
    <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;training&quot;</span><span class="p">,</span>
    <span class="n">output_transform</span><span class="o">=</span><span class="k">lambda</span> <span class="n">loss</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="n">loss</span><span class="p">}</span>
<span class="p">)</span>

<span class="c1"># Attach the logger to the evaluator on the training dataset and log NLL, Accuracy metrics after each epoch</span>
<span class="c1"># We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch</span>
<span class="c1"># of the `trainer` instead of `train_evaluator`.</span>
<span class="n">vd_logger</span><span class="o">.</span><span class="n">attach_output_handler</span><span class="p">(</span>
    <span class="n">train_evaluator</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">,</span>
    <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;training&quot;</span><span class="p">,</span>
    <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
    <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">),</span>
<span class="p">)</span>

<span class="c1"># Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="c1"># each epoch. We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch of the</span>
<span class="c1"># `trainer` instead of `evaluator`.</span>
<span class="n">vd_logger</span><span class="o">.</span><span class="n">attach_output_handler</span><span class="p">(</span>
    <span class="n">evaluator</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">,</span>
    <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
    <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">)),</span>
<span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log optimizer&#39;s parameters, e.g. learning rate at each iteration</span>
<span class="n">vd_logger</span><span class="o">.</span><span class="n">attach_opt_params_handler</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
    <span class="n">param_name</span><span class="o">=</span><span class="s1">&#39;lr&#39;</span>  <span class="c1"># optional</span>
<span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log model&#39;s weights norm after each iteration</span>
<span class="n">vd_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">,</span>
    <span class="n">log_handler</span><span class="o">=</span><span class="n">WeightsScalarHandler</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log model&#39;s gradients norm after each iteration</span>
<span class="n">vd_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">,</span>
    <span class="n">log_handler</span><span class="o">=</span><span class="n">GradsScalarHandler</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># We need to close the logger with we are done</span>
<span class="n">vd_logger</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
<p>It is also possible to use the logger as context manager:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.visdom_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="k">with</span> <span class="n">VisdomLogger</span><span class="p">()</span> <span class="k">as</span> <span class="n">vd_logger</span><span class="p">:</span>

    <span class="n">trainer</span> <span class="o">=</span> <span class="n">Engine</span><span class="p">(</span><span class="n">update_fn</span><span class="p">)</span>
    <span class="c1"># Attach the logger to the trainer to log training loss at each iteration</span>
    <span class="n">vd_logger</span><span class="o">.</span><span class="n">attach_output_handler</span><span class="p">(</span>
        <span class="n">trainer</span><span class="p">,</span>
        <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">,</span>
        <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;training&quot;</span><span class="p">,</span>
        <span class="n">output_transform</span><span class="o">=</span><span class="k">lambda</span> <span class="n">loss</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="n">loss</span><span class="p">}</span>
    <span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.visdom_logger.VisdomLogger.attach">
<span class="sig-name descname"><span class="pre">attach</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">engine</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_handler</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">event_name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ignite.contrib.handlers.visdom_logger.VisdomLogger.attach" title="Permalink to this definition">#</a></dt>
<dd><p>Attach the logger to the engine and execute <cite>log_handler</cite> function at <cite>event_name</cite> events.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine" title="ignite.engine.engine.Engine"><em>Engine</em></a>) ‚Äì engine object.</p></li>
<li><p><strong>log_handler</strong> (<em>callable</em>) ‚Äì a logging handler to execute</p></li>
<li><p><strong>event_name</strong> ‚Äì event to attach the logging handler to. Valid events are from
<a class="reference internal" href="../engine.html#ignite.engine.events.Events" title="ignite.engine.events.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a> or any <cite>event_name</cite> added by
<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine.register_events" title="ignite.engine.engine.Engine.register_events"><code class="xref py py-meth docutils literal notranslate"><span class="pre">register_events()</span></code></a>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">RemovableEventHandle</span></code>, which can be used to remove the handler.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.visdom_logger.VisdomLogger.attach_opt_params_handler">
<span class="sig-name descname"><span class="pre">attach_opt_params_handler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">engine</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">event_name</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ignite.contrib.handlers.visdom_logger.VisdomLogger.attach_opt_params_handler" title="Permalink to this definition">#</a></dt>
<dd><p>Shortcut method to attach <cite>OptimizerParamsHandler</cite> to the logger.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine" title="ignite.engine.engine.Engine"><em>Engine</em></a>) ‚Äì engine object.</p></li>
<li><p><strong>event_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.14)"><em>Any</em></a>) ‚Äì event to attach the logging handler to. Valid events are from
<a class="reference internal" href="../engine.html#ignite.engine.events.Events" title="ignite.engine.events.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a> or any <cite>event_name</cite> added by
<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine.register_events" title="ignite.engine.engine.Engine.register_events"><code class="xref py py-meth docutils literal notranslate"><span class="pre">register_events()</span></code></a>.</p></li>
<li><p><strong>*args</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.14)"><em>Any</em></a>) ‚Äì args to initialize <cite>OptimizerParamsHandler</cite></p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Mapping" title="(in Python v3.14)"><em>Mapping</em></a>) ‚Äì kwargs to initialize <cite>OptimizerParamsHandler</cite></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">RemovableEventHandle</span></code>, which can be used to remove the handler.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.visdom_logger.VisdomLogger.attach_output_handler">
<span class="sig-name descname"><span class="pre">attach_output_handler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">engine</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">event_name</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ignite.contrib.handlers.visdom_logger.VisdomLogger.attach_output_handler" title="Permalink to this definition">#</a></dt>
<dd><p>Shortcut method to attach <cite>OutputHandler</cite> to the logger.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine" title="ignite.engine.engine.Engine"><em>Engine</em></a>) ‚Äì engine object.</p></li>
<li><p><strong>event_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.14)"><em>Any</em></a>) ‚Äì event to attach the logging handler to. Valid events are from
<a class="reference internal" href="../engine.html#ignite.engine.events.Events" title="ignite.engine.events.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a> or any <cite>event_name</cite> added by
<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine.register_events" title="ignite.engine.engine.Engine.register_events"><code class="xref py py-meth docutils literal notranslate"><span class="pre">register_events()</span></code></a>.</p></li>
<li><p><strong>*args</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.14)"><em>Any</em></a>) ‚Äì args to initialize <cite>OutputHandler</cite></p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Mapping" title="(in Python v3.14)"><em>Mapping</em></a>) ‚Äì kwargs to initialize <cite>OutputHandler</cite></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">RemovableEventHandle</span></code>, which can be used to remove the handler.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.visdom_logger.WeightsScalarHandler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.visdom_logger.</span></span><span class="sig-name descname"><span class="pre">WeightsScalarHandler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction=&lt;function</span> <span class="pre">norm&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tag=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_legend=False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/visdom_logger.html#WeightsScalarHandler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.visdom_logger.WeightsScalarHandler" title="Permalink to this definition">#</a></dt>
<dd><p>Helper handler to log model‚Äôs weights as scalars.
Handler iterates over named parameters of the model, applies reduction function to each parameter
produce a scalar and then logs the scalar.</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.visdom_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">vd_logger</span> <span class="o">=</span> <span class="n">VisdomLogger</span><span class="p">()</span>

<span class="c1"># Attach the logger to the trainer to log model&#39;s weights norm after each iteration</span>
<span class="n">vd_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">,</span>
    <span class="n">log_handler</span><span class="o">=</span><span class="n">WeightsScalarHandler</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.9)"><em>torch.nn.Module</em></a>) ‚Äì model to log weights</p></li>
<li><p><strong>reduction</strong> (<em>callable</em>) ‚Äì function to reduce parameters into scalar</p></li>
<li><p><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) ‚Äì common title for all produced plots. For example, ‚Äúgenerator‚Äù</p></li>
<li><p><strong>show_legend</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) ‚Äì flag to show legend in the window</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.visdom_logger.WeightsScalarHandler.add_scalar">
<span class="sig-name descname"><span class="pre">add_scalar</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">logger</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">event_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">global_step</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ignite.contrib.handlers.visdom_logger.WeightsScalarHandler.add_scalar" title="Permalink to this definition">#</a></dt>
<dd><p>Helper method to log a scalar with VisdomLogger.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>logger</strong> (<a class="reference internal" href="#ignite.contrib.handlers.visdom_logger.VisdomLogger" title="ignite.contrib.handlers.visdom_logger.VisdomLogger"><em>VisdomLogger</em></a>) ‚Äì visdom logger</p></li>
<li><p><strong>k</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) ‚Äì scalar name which is used to set window title and y-axis label</p></li>
<li><p><strong>v</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a>) ‚Äì scalar value, y-axis value</p></li>
<li><p><strong>event_name</strong> ‚Äì Event name which is used to setup x-axis label. Valid events are from
<a class="reference internal" href="../engine.html#ignite.engine.events.Events" title="ignite.engine.events.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a> or any <cite>event_name</cite> added by
<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine.register_events" title="ignite.engine.engine.Engine.register_events"><code class="xref py py-meth docutils literal notranslate"><span class="pre">register_events()</span></code></a>.</p></li>
<li><p><strong>global_step</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a>) ‚Äì global step, x-axis value</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ignite.contrib.handlers.visdom_logger.global_step_from_engine">
<span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.visdom_logger.</span></span><span class="sig-name descname"><span class="pre">global_step_from_engine</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">engine</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_event_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/handlers.html#global_step_from_engine"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.visdom_logger.global_step_from_engine" title="Permalink to this definition">#</a></dt>
<dd><p>Helper method to setup <cite>global_step_transform</cite> function using another engine.
This can be helpful for logging trainer epoch/iteration while output handler is attached to an evaluator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine" title="ignite.engine.engine.Engine"><em>Engine</em></a>) ‚Äì engine which state is used to provide the global step</p></li>
<li><p><strong>custom_event_name</strong> (<em>optional</em>) ‚Äì registered event name. Optional argument, event name to use.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>global step</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Callable" title="(in Python v3.14)"><em>Callable</em></a></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="neptune-logger">
<h2>neptune_logger<a class="headerlink" href="#neptune-logger" title="Permalink to this heading">#</a></h2>
<p>See <a class="reference external" href="https://github.com/pytorch/ignite/blob/master/examples/contrib/mnist/mnist_with_neptune_logger.py">neptune mnist example</a>
for detailed usage.</p>
<span class="target" id="module-ignite.contrib.handlers.neptune_logger"></span><dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.neptune_logger.GradsScalarHandler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.neptune_logger.</span></span><span class="sig-name descname"><span class="pre">GradsScalarHandler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction=&lt;function</span> <span class="pre">norm&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tag=None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/neptune_logger.html#GradsScalarHandler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.neptune_logger.GradsScalarHandler" title="Permalink to this definition">#</a></dt>
<dd><p>Helper handler to log model‚Äôs gradients as scalars.
Handler iterates over the gradients of named parameters of the model, applies reduction function to each parameter
produce a scalar and then logs the scalar.</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.neptune_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="c1"># We are using the api_token for the anonymous user neptuner but you can use your own.</span>

<span class="n">npt_logger</span> <span class="o">=</span> <span class="n">NeptuneLogger</span><span class="p">(</span>
    <span class="n">api_token</span><span class="o">=</span><span class="s2">&quot;ANONYMOUS&quot;</span><span class="p">,</span>
    <span class="n">project_name</span><span class="o">=</span><span class="s2">&quot;shared/pytorch-ignite-integration&quot;</span><span class="p">,</span>
    <span class="n">experiment_name</span><span class="o">=</span><span class="s2">&quot;cnn-mnist&quot;</span><span class="p">,</span> <span class="c1"># Optional,</span>
    <span class="n">params</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;max_epochs&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">},</span> <span class="c1"># Optional,</span>
    <span class="n">tags</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;pytorch-ignite&quot;</span><span class="p">,</span><span class="s2">&quot;minst&quot;</span><span class="p">]</span> <span class="c1"># Optional</span>
<span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log model&#39;s weights norm after each iteration</span>
<span class="n">npt_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">,</span>
    <span class="n">log_handler</span><span class="o">=</span><span class="n">GradsScalarHandler</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.9)"><em>torch.nn.Module</em></a>) ‚Äì model to log weights</p></li>
<li><p><strong>reduction</strong> (<em>callable</em>) ‚Äì function to reduce parameters into scalar</p></li>
<li><p><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) ‚Äì common title for all produced plots. For example, ‚Äúgenerator‚Äù</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.neptune_logger.NeptuneLogger">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.neptune_logger.</span></span><span class="sig-name descname"><span class="pre">NeptuneLogger</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/neptune_logger.html#NeptuneLogger"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.neptune_logger.NeptuneLogger" title="Permalink to this definition">#</a></dt>
<dd><p><a class="reference external" href="https://neptune.ai/">Neptune</a> handler to log metrics, model/optimizer parameters, gradients during the training
and validation. It can also log model checkpoints to Neptune server.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>neptune-client
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>api_token</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em> | </em><em>None</em>) ‚Äì Required in online mode. Neputne API token, found on <a class="reference external" href="https://neptune.ai">https://neptune.ai</a>.
Read how to get your API key
<a class="reference external" href="https://docs.neptune.ai/python-api/tutorials/get-started.html#copy-api-token">https://docs.neptune.ai/python-api/tutorials/get-started.html#copy-api-token</a>.</p></li>
<li><p><strong>project_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) ‚Äì Required in online mode. Qualified name of a project in a form of
‚Äúnamespace/project_name‚Äù for example ‚Äútom/minst-classification‚Äù.
If None, the value of NEPTUNE_PROJECT environment variable will be taken.
You need to create the project in <a class="reference external" href="https://neptune.ai">https://neptune.ai</a> first.</p></li>
<li><p><strong>offline_mode</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a>) ‚Äì Optional default False. If offline_mode=True no logs will be send to neptune.
Usually used for debug purposes.</p></li>
<li><p><strong>experiment_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) ‚Äì Optional. Editable name of the experiment.
Name is displayed in the experiment‚Äôs Details (Metadata section) and in experiments view as a column.</p></li>
<li><p><strong>upload_source_files</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.14)"><em>list</em></a><em>, </em><em>optional</em>) ‚Äì Optional. List of source files to be uploaded.
Must be list of str or single str. Uploaded sources are displayed in the experiment‚Äôs Source code tab.
If None is passed, Python file from which experiment was created will be uploaded.
Pass empty list (<cite>[]</cite>) to upload no files. Unix style pathname pattern expansion is supported.
For example, you can pass <cite>*.py</cite> to upload all python source files from the current directory.
For recursion lookup use <cite>**/*.py</cite> (for Python 3.5 and later). For more information see glob library.</p></li>
<li><p><strong>params</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.14)"><em>dict</em></a><em>, </em><em>optional</em>) ‚Äì Optional. Parameters of the experiment. After experiment creation params are read-only.
Parameters are displayed in the experiment‚Äôs Parameters section and each key-value pair can be
viewed in experiments view as a column.</p></li>
<li><p><strong>properties</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.14)"><em>dict</em></a><em>, </em><em>optional</em>) ‚Äì Optional default is <cite>{}</cite>. Properties of the experiment.
They are editable after experiment is created. Properties are displayed in the experiment‚Äôs Details and
each key-value pair can be viewed in experiments view as a column.</p></li>
<li><p><strong>tags</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.14)"><em>list</em></a><em>, </em><em>optional</em>) ‚Äì Optional default <cite>[]</cite>. Must be list of str. Tags of the experiment.
Tags are displayed in the experiment‚Äôs Details and can be viewed in experiments view as a column.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.neptune_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="c1"># We are using the api_token for the anonymous user neptuner but you can use your own.</span>

<span class="n">npt_logger</span> <span class="o">=</span> <span class="n">NeptuneLogger</span><span class="p">(</span>
    <span class="n">api_token</span><span class="o">=</span><span class="s2">&quot;ANONYMOUS&quot;</span><span class="p">,</span>
    <span class="n">project_name</span><span class="o">=</span><span class="s2">&quot;shared/pytorch-ignite-integration&quot;</span><span class="p">,</span>
    <span class="n">experiment_name</span><span class="o">=</span><span class="s2">&quot;cnn-mnist&quot;</span><span class="p">,</span> <span class="c1"># Optional,</span>
    <span class="n">params</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;max_epochs&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">},</span> <span class="c1"># Optional,</span>
    <span class="n">tags</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;pytorch-ignite&quot;</span><span class="p">,</span><span class="s2">&quot;minst&quot;</span><span class="p">]</span> <span class="c1"># Optional</span>
<span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log training loss at each iteration</span>
<span class="n">npt_logger</span><span class="o">.</span><span class="n">attach_output_handler</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">,</span>
    <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;training&quot;</span><span class="p">,</span>
    <span class="n">output_transform</span><span class="o">=</span><span class="k">lambda</span> <span class="n">loss</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">}</span>
<span class="p">)</span>

<span class="c1"># Attach the logger to the evaluator on the training dataset and log NLL, Accuracy metrics after each epoch</span>
<span class="c1"># We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch</span>
<span class="c1"># of the `trainer` instead of `train_evaluator`.</span>
<span class="n">npt_logger</span><span class="o">.</span><span class="n">attach_output_handler</span><span class="p">(</span>
    <span class="n">train_evaluator</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">,</span>
    <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;training&quot;</span><span class="p">,</span>
    <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
    <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">),</span>
<span class="p">)</span>

<span class="c1"># Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="c1"># each epoch. We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch of the</span>
<span class="c1"># `trainer` instead of `evaluator`.</span>
<span class="n">npt_logger</span><span class="o">.</span><span class="n">attach_output_handler</span><span class="p">(</span>
    <span class="n">evaluator</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">,</span>
    <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
    <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">)),</span>
<span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log optimizer&#39;s parameters, e.g. learning rate at each iteration</span>
<span class="n">npt_logger</span><span class="o">.</span><span class="n">attach_opt_params_handler</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
    <span class="n">param_name</span><span class="o">=</span><span class="s1">&#39;lr&#39;</span>  <span class="c1"># optional</span>
<span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log model&#39;s weights norm after each iteration</span>
<span class="n">npt_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">,</span>
    <span class="n">log_handler</span><span class="o">=</span><span class="n">WeightsScalarHandler</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Explore an experiment with neptune tracking here:
<a class="reference external" href="https://ui.neptune.ai/o/shared/org/pytorch-ignite-integration/e/PYTOR1-18/charts">https://ui.neptune.ai/o/shared/org/pytorch-ignite-integration/e/PYTOR1-18/charts</a>
You can save model checkpoints to a Neptune server:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.handlers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Checkpoint</span>

<span class="k">def</span><span class="w"> </span><span class="nf">score_function</span><span class="p">(</span><span class="n">engine</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">metrics</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">]</span>

<span class="n">to_save</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="n">model</span><span class="p">}</span>
<span class="n">handler</span> <span class="o">=</span> <span class="n">Checkpoint</span><span class="p">(</span>
    <span class="n">to_save</span><span class="p">,</span>
    <span class="n">NeptuneSaver</span><span class="p">(</span><span class="n">npt_logger</span><span class="p">),</span> <span class="n">n_saved</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">filename_prefix</span><span class="o">=</span><span class="s2">&quot;best&quot;</span><span class="p">,</span>
    <span class="n">score_function</span><span class="o">=</span><span class="n">score_function</span><span class="p">,</span>
    <span class="n">score_name</span><span class="o">=</span><span class="s2">&quot;validation_accuracy&quot;</span><span class="p">,</span>
    <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">validation_evaluator</span><span class="o">.</span><span class="n">add_event_handler</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">COMPLETED</span><span class="p">,</span> <span class="n">handler</span><span class="p">)</span>
</pre></div>
</div>
<p>It is also possible to use the logger as context manager:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.neptune_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># We are using the api_token for the anonymous user neptuner but you can use your own.</span>

<span class="k">with</span> <span class="n">NeptuneLogger</span><span class="p">(</span><span class="n">api_token</span><span class="o">=</span><span class="s2">&quot;ANONYMOUS&quot;</span><span class="p">,</span>
                   <span class="n">project_name</span><span class="o">=</span><span class="s2">&quot;shared/pytorch-ignite-integration&quot;</span><span class="p">,</span>
                   <span class="n">experiment_name</span><span class="o">=</span><span class="s2">&quot;cnn-mnist&quot;</span><span class="p">,</span> <span class="c1"># Optional,</span>
                   <span class="n">params</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;max_epochs&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">},</span> <span class="c1"># Optional,</span>
                   <span class="n">tags</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;pytorch-ignite&quot;</span><span class="p">,</span><span class="s2">&quot;minst&quot;</span><span class="p">]</span> <span class="c1"># Optional</span>
                   <span class="p">)</span> <span class="k">as</span> <span class="n">npt_logger</span><span class="p">:</span>

    <span class="n">trainer</span> <span class="o">=</span> <span class="n">Engine</span><span class="p">(</span><span class="n">update_fn</span><span class="p">)</span>
    <span class="c1"># Attach the logger to the trainer to log training loss at each iteration</span>
    <span class="n">npt_logger</span><span class="o">.</span><span class="n">attach_output_handler</span><span class="p">(</span>
        <span class="n">trainer</span><span class="p">,</span>
        <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">,</span>
        <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;training&quot;</span><span class="p">,</span>
        <span class="n">output_transform</span><span class="o">=</span><span class="k">lambda</span> <span class="n">loss</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="n">loss</span><span class="p">}</span>
    <span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.neptune_logger.NeptuneLogger.attach">
<span class="sig-name descname"><span class="pre">attach</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">engine</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_handler</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">event_name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ignite.contrib.handlers.neptune_logger.NeptuneLogger.attach" title="Permalink to this definition">#</a></dt>
<dd><p>Attach the logger to the engine and execute <cite>log_handler</cite> function at <cite>event_name</cite> events.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine" title="ignite.engine.engine.Engine"><em>Engine</em></a>) ‚Äì engine object.</p></li>
<li><p><strong>log_handler</strong> (<em>callable</em>) ‚Äì a logging handler to execute</p></li>
<li><p><strong>event_name</strong> ‚Äì event to attach the logging handler to. Valid events are from
<a class="reference internal" href="../engine.html#ignite.engine.events.Events" title="ignite.engine.events.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a> or any <cite>event_name</cite> added by
<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine.register_events" title="ignite.engine.engine.Engine.register_events"><code class="xref py py-meth docutils literal notranslate"><span class="pre">register_events()</span></code></a>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">RemovableEventHandle</span></code>, which can be used to remove the handler.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.neptune_logger.NeptuneLogger.attach_opt_params_handler">
<span class="sig-name descname"><span class="pre">attach_opt_params_handler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">engine</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">event_name</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ignite.contrib.handlers.neptune_logger.NeptuneLogger.attach_opt_params_handler" title="Permalink to this definition">#</a></dt>
<dd><p>Shortcut method to attach <cite>OptimizerParamsHandler</cite> to the logger.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine" title="ignite.engine.engine.Engine"><em>Engine</em></a>) ‚Äì engine object.</p></li>
<li><p><strong>event_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.14)"><em>Any</em></a>) ‚Äì event to attach the logging handler to. Valid events are from
<a class="reference internal" href="../engine.html#ignite.engine.events.Events" title="ignite.engine.events.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a> or any <cite>event_name</cite> added by
<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine.register_events" title="ignite.engine.engine.Engine.register_events"><code class="xref py py-meth docutils literal notranslate"><span class="pre">register_events()</span></code></a>.</p></li>
<li><p><strong>*args</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.14)"><em>Any</em></a>) ‚Äì args to initialize <cite>OptimizerParamsHandler</cite></p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Mapping" title="(in Python v3.14)"><em>Mapping</em></a>) ‚Äì kwargs to initialize <cite>OptimizerParamsHandler</cite></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">RemovableEventHandle</span></code>, which can be used to remove the handler.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.neptune_logger.NeptuneLogger.attach_output_handler">
<span class="sig-name descname"><span class="pre">attach_output_handler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">engine</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">event_name</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ignite.contrib.handlers.neptune_logger.NeptuneLogger.attach_output_handler" title="Permalink to this definition">#</a></dt>
<dd><p>Shortcut method to attach <cite>OutputHandler</cite> to the logger.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine" title="ignite.engine.engine.Engine"><em>Engine</em></a>) ‚Äì engine object.</p></li>
<li><p><strong>event_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.14)"><em>Any</em></a>) ‚Äì event to attach the logging handler to. Valid events are from
<a class="reference internal" href="../engine.html#ignite.engine.events.Events" title="ignite.engine.events.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a> or any <cite>event_name</cite> added by
<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine.register_events" title="ignite.engine.engine.Engine.register_events"><code class="xref py py-meth docutils literal notranslate"><span class="pre">register_events()</span></code></a>.</p></li>
<li><p><strong>*args</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.14)"><em>Any</em></a>) ‚Äì args to initialize <cite>OutputHandler</cite></p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Mapping" title="(in Python v3.14)"><em>Mapping</em></a>) ‚Äì kwargs to initialize <cite>OutputHandler</cite></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">RemovableEventHandle</span></code>, which can be used to remove the handler.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.neptune_logger.NeptuneSaver">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.neptune_logger.</span></span><span class="sig-name descname"><span class="pre">NeptuneSaver</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">neptune_logger</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/neptune_logger.html#NeptuneSaver"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.neptune_logger.NeptuneSaver" title="Permalink to this definition">#</a></dt>
<dd><p>Handler that saves input checkpoint to the Neptune server.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>neptune_logger</strong> (<a class="reference internal" href="#ignite.contrib.handlers.neptune_logger.NeptuneLogger" title="ignite.contrib.handlers.neptune_logger.NeptuneLogger"><em>ignite.contrib.handlers.neptune_logger.NeptuneLogger</em></a>) ‚Äì an instance of
NeptuneLogger class.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.neptune_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="c1"># We are using the api_token for the anonymous user neptuner but you can use your own.</span>

<span class="n">npt_logger</span> <span class="o">=</span> <span class="n">NeptuneLogger</span><span class="p">(</span>
    <span class="n">api_token</span><span class="o">=</span><span class="s2">&quot;ANONYMOUS&quot;</span><span class="p">,</span>
    <span class="n">project_name</span><span class="o">=</span><span class="s2">&quot;shared/pytorch-ignite-integration&quot;</span><span class="p">,</span>
    <span class="n">experiment_name</span><span class="o">=</span><span class="s2">&quot;cnn-mnist&quot;</span><span class="p">,</span> <span class="c1"># Optional,</span>
    <span class="n">params</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;max_epochs&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">},</span> <span class="c1"># Optional,</span>
    <span class="n">tags</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;pytorch-ignite&quot;</span><span class="p">,</span><span class="s2">&quot;minst&quot;</span><span class="p">]</span> <span class="c1"># Optional</span>
<span class="p">)</span>

<span class="o">...</span>
<span class="n">evaluator</span> <span class="o">=</span> <span class="n">create_supervised_evaluator</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
<span class="o">...</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">ignite.handlers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Checkpoint</span>

<span class="k">def</span><span class="w"> </span><span class="nf">score_function</span><span class="p">(</span><span class="n">engine</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">metrics</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">]</span>

<span class="n">to_save</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="n">model</span><span class="p">}</span>

<span class="c1"># pass neptune logger to NeptuneServer</span>

<span class="n">handler</span> <span class="o">=</span> <span class="n">Checkpoint</span><span class="p">(</span>
    <span class="n">to_save</span><span class="p">,</span>
    <span class="n">NeptuneSaver</span><span class="p">(</span><span class="n">npt_logger</span><span class="p">),</span> <span class="n">n_saved</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">filename_prefix</span><span class="o">=</span><span class="s2">&quot;best&quot;</span><span class="p">,</span> <span class="n">score_function</span><span class="o">=</span><span class="n">score_function</span><span class="p">,</span>
    <span class="n">score_name</span><span class="o">=</span><span class="s2">&quot;validation_accuracy&quot;</span><span class="p">,</span>
    <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">evaluator</span><span class="o">.</span><span class="n">add_event_handler</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">COMPLETED</span><span class="p">,</span> <span class="n">handler</span><span class="p">)</span>
</pre></div>
</div>
<dl class="simple">
<dt># We need to close the logger when we are done</dt><dd><p>npt_logger.close()</p>
</dd>
</dl>
<p>For example, you can access model checkpoints and download them from here:
<a class="reference external" href="https://ui.neptune.ai/o/shared/org/pytorch-ignite-integration/e/PYTOR1-18/charts">https://ui.neptune.ai/o/shared/org/pytorch-ignite-integration/e/PYTOR1-18/charts</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.neptune_logger.NeptuneSaver.remove">
<span class="sig-name descname"><span class="pre">remove</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">filename</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/neptune_logger.html#NeptuneSaver.remove"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.neptune_logger.NeptuneSaver.remove" title="Permalink to this definition">#</a></dt>
<dd><p>Method to remove saved checkpoint.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>filename</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) ‚Äì filename associated with checkpoint.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.neptune_logger.OptimizerParamsHandler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.neptune_logger.</span></span><span class="sig-name descname"><span class="pre">OptimizerParamsHandler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'lr'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tag</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/neptune_logger.html#OptimizerParamsHandler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.neptune_logger.OptimizerParamsHandler" title="Permalink to this definition">#</a></dt>
<dd><p>Helper handler to log optimizer parameters</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.neptune_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="c1"># We are using the api_token for the anonymous user neptuner but you can use your own.</span>

<span class="n">npt_logger</span> <span class="o">=</span> <span class="n">NeptuneLogger</span><span class="p">(</span>
    <span class="n">api_token</span><span class="o">=</span><span class="s2">&quot;ANONYMOUS&quot;</span><span class="p">,</span>
    <span class="n">project_name</span><span class="o">=</span><span class="s2">&quot;shared/pytorch-ignite-integration&quot;</span><span class="p">,</span>
    <span class="n">experiment_name</span><span class="o">=</span><span class="s2">&quot;cnn-mnist&quot;</span><span class="p">,</span> <span class="c1"># Optional,</span>
    <span class="n">params</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;max_epochs&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">},</span> <span class="c1"># Optional,</span>
    <span class="n">tags</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;pytorch-ignite&quot;</span><span class="p">,</span><span class="s2">&quot;minst&quot;</span><span class="p">]</span> <span class="c1"># Optional</span>
<span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log optimizer&#39;s parameters, e.g. learning rate at each iteration</span>
<span class="n">npt_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">log_handler</span><span class="o">=</span><span class="n">OptimizerParamsHandler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">),</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span>
<span class="p">)</span>
<span class="c1"># or equivalently</span>
<span class="n">npt_logger</span><span class="o">.</span><span class="n">attach_opt_params_handler</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch v2.9)"><em>torch.optim.Optimizer</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.14)"><em>object</em></a>) ‚Äì torch optimizer or any object with attribute <code class="docutils literal notranslate"><span class="pre">param_groups</span></code>
as a sequence.</p></li>
<li><p><strong>param_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) ‚Äì parameter name</p></li>
<li><p><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) ‚Äì common title for all produced plots. For example, ‚Äúgenerator‚Äù</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.neptune_logger.OutputHandler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.neptune_logger.</span></span><span class="sig-name descname"><span class="pre">OutputHandler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tag</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">global_step_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/neptune_logger.html#OutputHandler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.neptune_logger.OutputHandler" title="Permalink to this definition">#</a></dt>
<dd><p>Helper handler to log engine‚Äôs output and/or metrics</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.neptune_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="c1"># We are using the api_token for the anonymous user neptuner but you can use your own.</span>

<span class="n">npt_logger</span> <span class="o">=</span> <span class="n">NeptuneLogger</span><span class="p">(</span>
    <span class="n">api_token</span><span class="o">=</span><span class="s2">&quot;ANONYMOUS&quot;</span><span class="p">,</span>
    <span class="n">project_name</span><span class="o">=</span><span class="s2">&quot;shared/pytorch-ignite-integration&quot;</span><span class="p">,</span>
    <span class="n">experiment_name</span><span class="o">=</span><span class="s2">&quot;cnn-mnist&quot;</span><span class="p">,</span> <span class="c1"># Optional,</span>
    <span class="n">params</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;max_epochs&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">},</span> <span class="c1"># Optional,</span>
    <span class="n">tags</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;pytorch-ignite&quot;</span><span class="p">,</span><span class="s2">&quot;minst&quot;</span><span class="p">]</span> <span class="c1"># Optional</span>
<span class="p">)</span>

<span class="c1"># Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="c1"># each epoch. We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch</span>
<span class="c1"># of the `trainer`:</span>
<span class="n">npt_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span>
    <span class="n">evaluator</span><span class="p">,</span>
    <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span>
        <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
        <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
        <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>
    <span class="p">),</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span>
<span class="p">)</span>
<span class="c1"># or equivalently</span>
<span class="n">npt_logger</span><span class="o">.</span><span class="n">attach_output_handler</span><span class="p">(</span>
    <span class="n">evaluator</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">,</span>
    <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
    <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Another example, where model is evaluated every 500 iterations:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.neptune_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="nd">@trainer</span><span class="o">.</span><span class="n">on</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">(</span><span class="n">every</span><span class="o">=</span><span class="mi">500</span><span class="p">))</span>
<span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span><span class="n">engine</span><span class="p">):</span>
    <span class="n">evaluator</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">validation_set</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># We are using the api_token for the anonymous user neptuner but you can use your own.</span>

<span class="n">npt_logger</span> <span class="o">=</span> <span class="n">NeptuneLogger</span><span class="p">(</span>
    <span class="n">api_token</span><span class="o">=</span><span class="s2">&quot;ANONYMOUS&quot;</span><span class="p">,</span>
    <span class="n">project_name</span><span class="o">=</span><span class="s2">&quot;shared/pytorch-ignite-integration&quot;</span><span class="p">,</span>
    <span class="n">experiment_name</span><span class="o">=</span><span class="s2">&quot;cnn-mnist&quot;</span><span class="p">,</span> <span class="c1"># Optional,</span>
    <span class="n">params</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;max_epochs&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">},</span> <span class="c1"># Optional,</span>
    <span class="n">tags</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;pytorch-ignite&quot;</span><span class="p">,</span> <span class="s2">&quot;minst&quot;</span><span class="p">]</span> <span class="c1"># Optional</span>
<span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">global_step_transform</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">trainer</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">iteration</span>

<span class="c1"># Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="c1"># every 500 iterations. Since evaluator engine does not have access to the training iteration, we</span>
<span class="c1"># provide a global_step_transform to return the trainer.state.iteration for the global_step, each time</span>
<span class="c1"># evaluator metrics are plotted on NeptuneML.</span>

<span class="n">npt_logger</span><span class="o">.</span><span class="n">attach_output_handler</span><span class="p">(</span>
    <span class="n">evaluator</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">,</span>
    <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
    <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_transform</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) ‚Äì common title for all produced plots. For example, ‚Äútraining‚Äù</p></li>
<li><p><strong>metric_names</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.14)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) ‚Äì list of metric names to plot or a string ‚Äúall‚Äù to plot all available
metrics.</p></li>
<li><p><strong>output_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) ‚Äì output transform function to prepare <cite>engine.state.output</cite> as a number.
For example, <cite>output_transform = lambda output: output</cite>
This function can also return a dictionary, e.g <cite>{‚Äúloss‚Äù: loss1, ‚Äúanother_loss‚Äù: loss2}</cite> to label the plot
with corresponding keys.</p></li>
<li><p><strong>global_step_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) ‚Äì global step transform function to output a desired global step.
Input of the function is <cite>(engine, event_name)</cite>. Output of function should be an integer.
Default is None, global_step based on attached engine. If provided,
uses function output as global_step. To setup global step from another engine, please use
<a class="reference internal" href="#ignite.contrib.handlers.neptune_logger.global_step_from_engine" title="ignite.contrib.handlers.neptune_logger.global_step_from_engine"><code class="xref py py-meth docutils literal notranslate"><span class="pre">global_step_from_engine()</span></code></a>.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Example of <cite>global_step_transform</cite>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">global_step_transform</span><span class="p">(</span><span class="n">engine</span><span class="p">,</span> <span class="n">event_name</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">get_event_attrib_value</span><span class="p">(</span><span class="n">event_name</span><span class="p">)</span>
</pre></div>
</div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.neptune_logger.WeightsScalarHandler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.neptune_logger.</span></span><span class="sig-name descname"><span class="pre">WeightsScalarHandler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction=&lt;function</span> <span class="pre">norm&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tag=None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/neptune_logger.html#WeightsScalarHandler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.neptune_logger.WeightsScalarHandler" title="Permalink to this definition">#</a></dt>
<dd><p>Helper handler to log model‚Äôs weights as scalars.
Handler iterates over named parameters of the model, applies reduction function to each parameter
produce a scalar and then logs the scalar.</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.neptune_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="c1"># We are using the api_token for the anonymous user neptuner but you can use your own.</span>

<span class="n">npt_logger</span> <span class="o">=</span> <span class="n">NeptuneLogger</span><span class="p">(</span>
    <span class="n">api_token</span><span class="o">=</span><span class="s2">&quot;ANONYMOUS&quot;</span><span class="p">,</span>
    <span class="n">project_name</span><span class="o">=</span><span class="s2">&quot;shared/pytorch-ignite-integration&quot;</span><span class="p">,</span>
    <span class="n">experiment_name</span><span class="o">=</span><span class="s2">&quot;cnn-mnist&quot;</span><span class="p">,</span> <span class="c1"># Optional,</span>
    <span class="n">params</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;max_epochs&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">},</span> <span class="c1"># Optional,</span>
    <span class="n">tags</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;pytorch-ignite&quot;</span><span class="p">,</span><span class="s2">&quot;minst&quot;</span><span class="p">]</span> <span class="c1"># Optional</span>
<span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log model&#39;s weights norm after each iteration</span>
<span class="n">npt_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">,</span>
    <span class="n">log_handler</span><span class="o">=</span><span class="n">WeightsScalarHandler</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.9)"><em>torch.nn.Module</em></a>) ‚Äì model to log weights</p></li>
<li><p><strong>reduction</strong> (<em>callable</em>) ‚Äì function to reduce parameters into scalar</p></li>
<li><p><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) ‚Äì common title for all produced plots. For example, ‚Äúgenerator‚Äù</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ignite.contrib.handlers.neptune_logger.global_step_from_engine">
<span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.neptune_logger.</span></span><span class="sig-name descname"><span class="pre">global_step_from_engine</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">engine</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_event_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/handlers.html#global_step_from_engine"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.neptune_logger.global_step_from_engine" title="Permalink to this definition">#</a></dt>
<dd><p>Helper method to setup <cite>global_step_transform</cite> function using another engine.
This can be helpful for logging trainer epoch/iteration while output handler is attached to an evaluator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine" title="ignite.engine.engine.Engine"><em>Engine</em></a>) ‚Äì engine which state is used to provide the global step</p></li>
<li><p><strong>custom_event_name</strong> (<em>optional</em>) ‚Äì registered event name. Optional argument, event name to use.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>global step</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Callable" title="(in Python v3.14)"><em>Callable</em></a></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-ignite.contrib.handlers.mlflow_logger">
<span id="mlflow-logger"></span><h2>mlflow_logger<a class="headerlink" href="#module-ignite.contrib.handlers.mlflow_logger" title="Permalink to this heading">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.mlflow_logger.MLflowLogger">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.mlflow_logger.</span></span><span class="sig-name descname"><span class="pre">MLflowLogger</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tracking_uri</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/mlflow_logger.html#MLflowLogger"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.mlflow_logger.MLflowLogger" title="Permalink to this definition">#</a></dt>
<dd><p><a class="reference external" href="https://mlflow.org">MLflow</a> tracking client handler to log parameters and metrics during the training
and validation.</p>
<p>This class requires <a class="reference external" href="https://github.com/mlflow/mlflow/">mlflow package</a> to be installed:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>mlflow
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tracking_uri</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) ‚Äì MLflow tracking uri. See MLflow docs for more details</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.mlflow_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">mlflow_logger</span> <span class="o">=</span> <span class="n">MLflowLogger</span><span class="p">()</span>

<span class="c1"># Log experiment parameters:</span>
<span class="n">mlflow_logger</span><span class="o">.</span><span class="n">log_params</span><span class="p">({</span>
    <span class="s2">&quot;seed&quot;</span><span class="p">:</span> <span class="n">seed</span><span class="p">,</span>
    <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="n">batch_size</span><span class="p">,</span>
    <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>

    <span class="s2">&quot;pytorch version&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
    <span class="s2">&quot;ignite version&quot;</span><span class="p">:</span> <span class="n">ignite</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
    <span class="s2">&quot;cuda version&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">version</span><span class="o">.</span><span class="n">cuda</span><span class="p">,</span>
    <span class="s2">&quot;device name&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_name</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="p">})</span>

<span class="c1"># Attach the logger to the trainer to log training loss at each iteration</span>
<span class="n">mlflow_logger</span><span class="o">.</span><span class="n">attach_output_handler</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">,</span>
    <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;training&quot;</span><span class="p">,</span>
    <span class="n">output_transform</span><span class="o">=</span><span class="k">lambda</span> <span class="n">loss</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">}</span>
<span class="p">)</span>

<span class="c1"># Attach the logger to the evaluator on the training dataset and log NLL, Accuracy metrics after each epoch</span>
<span class="c1"># We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch</span>
<span class="c1"># of the `trainer` instead of `train_evaluator`.</span>
<span class="n">mlflow_logger</span><span class="o">.</span><span class="n">attach_output_handler</span><span class="p">(</span>
    <span class="n">train_evaluator</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">,</span>
    <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;training&quot;</span><span class="p">,</span>
    <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
    <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">),</span>
<span class="p">)</span>

<span class="c1"># Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="c1"># each epoch. We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch of the</span>
<span class="c1"># `trainer` instead of `evaluator`.</span>
<span class="n">mlflow_logger</span><span class="o">.</span><span class="n">attach_output_handler</span><span class="p">(</span>
    <span class="n">evaluator</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">,</span>
    <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
    <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">)),</span>
<span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log optimizer&#39;s parameters, e.g. learning rate at each iteration</span>
<span class="n">mlflow_logger</span><span class="o">.</span><span class="n">attach_opt_params_handler</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
    <span class="n">param_name</span><span class="o">=</span><span class="s1">&#39;lr&#39;</span>  <span class="c1"># optional</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.mlflow_logger.MLflowLogger.attach">
<span class="sig-name descname"><span class="pre">attach</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">engine</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_handler</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">event_name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ignite.contrib.handlers.mlflow_logger.MLflowLogger.attach" title="Permalink to this definition">#</a></dt>
<dd><p>Attach the logger to the engine and execute <cite>log_handler</cite> function at <cite>event_name</cite> events.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine" title="ignite.engine.engine.Engine"><em>Engine</em></a>) ‚Äì engine object.</p></li>
<li><p><strong>log_handler</strong> (<em>callable</em>) ‚Äì a logging handler to execute</p></li>
<li><p><strong>event_name</strong> ‚Äì event to attach the logging handler to. Valid events are from
<a class="reference internal" href="../engine.html#ignite.engine.events.Events" title="ignite.engine.events.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a> or any <cite>event_name</cite> added by
<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine.register_events" title="ignite.engine.engine.Engine.register_events"><code class="xref py py-meth docutils literal notranslate"><span class="pre">register_events()</span></code></a>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">RemovableEventHandle</span></code>, which can be used to remove the handler.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.mlflow_logger.MLflowLogger.attach_opt_params_handler">
<span class="sig-name descname"><span class="pre">attach_opt_params_handler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">engine</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">event_name</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ignite.contrib.handlers.mlflow_logger.MLflowLogger.attach_opt_params_handler" title="Permalink to this definition">#</a></dt>
<dd><p>Shortcut method to attach <cite>OptimizerParamsHandler</cite> to the logger.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine" title="ignite.engine.engine.Engine"><em>Engine</em></a>) ‚Äì engine object.</p></li>
<li><p><strong>event_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.14)"><em>Any</em></a>) ‚Äì event to attach the logging handler to. Valid events are from
<a class="reference internal" href="../engine.html#ignite.engine.events.Events" title="ignite.engine.events.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a> or any <cite>event_name</cite> added by
<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine.register_events" title="ignite.engine.engine.Engine.register_events"><code class="xref py py-meth docutils literal notranslate"><span class="pre">register_events()</span></code></a>.</p></li>
<li><p><strong>*args</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.14)"><em>Any</em></a>) ‚Äì args to initialize <cite>OptimizerParamsHandler</cite></p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Mapping" title="(in Python v3.14)"><em>Mapping</em></a>) ‚Äì kwargs to initialize <cite>OptimizerParamsHandler</cite></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">RemovableEventHandle</span></code>, which can be used to remove the handler.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.mlflow_logger.MLflowLogger.attach_output_handler">
<span class="sig-name descname"><span class="pre">attach_output_handler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">engine</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">event_name</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ignite.contrib.handlers.mlflow_logger.MLflowLogger.attach_output_handler" title="Permalink to this definition">#</a></dt>
<dd><p>Shortcut method to attach <cite>OutputHandler</cite> to the logger.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine" title="ignite.engine.engine.Engine"><em>Engine</em></a>) ‚Äì engine object.</p></li>
<li><p><strong>event_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.14)"><em>Any</em></a>) ‚Äì event to attach the logging handler to. Valid events are from
<a class="reference internal" href="../engine.html#ignite.engine.events.Events" title="ignite.engine.events.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a> or any <cite>event_name</cite> added by
<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine.register_events" title="ignite.engine.engine.Engine.register_events"><code class="xref py py-meth docutils literal notranslate"><span class="pre">register_events()</span></code></a>.</p></li>
<li><p><strong>*args</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.14)"><em>Any</em></a>) ‚Äì args to initialize <cite>OutputHandler</cite></p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Mapping" title="(in Python v3.14)"><em>Mapping</em></a>) ‚Äì kwargs to initialize <cite>OutputHandler</cite></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">RemovableEventHandle</span></code>, which can be used to remove the handler.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.mlflow_logger.OptimizerParamsHandler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.mlflow_logger.</span></span><span class="sig-name descname"><span class="pre">OptimizerParamsHandler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'lr'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tag</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/mlflow_logger.html#OptimizerParamsHandler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.mlflow_logger.OptimizerParamsHandler" title="Permalink to this definition">#</a></dt>
<dd><p>Helper handler to log optimizer parameters</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.mlflow_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">mlflow_logger</span> <span class="o">=</span> <span class="n">MLflowLogger</span><span class="p">()</span>
<span class="c1"># Optionally, user can specify tracking_uri with corresponds to MLFLOW_TRACKING_URI</span>
<span class="c1"># mlflow_logger = MLflowLogger(tracking_uri=&quot;uri&quot;)</span>

<span class="c1"># Attach the logger to the trainer to log optimizer&#39;s parameters, e.g. learning rate at each iteration</span>
<span class="n">mlflow_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">log_handler</span><span class="o">=</span><span class="n">OptimizerParamsHandler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">),</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span>
<span class="p">)</span>
<span class="c1"># or equivalently</span>
<span class="n">mlflow_logger</span><span class="o">.</span><span class="n">attach_opt_params_handler</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch v2.9)"><em>torch.optim.Optimizer</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.14)"><em>object</em></a>) ‚Äì torch optimizer or any object with attribute <code class="docutils literal notranslate"><span class="pre">param_groups</span></code>
as a sequence.</p></li>
<li><p><strong>param_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) ‚Äì parameter name</p></li>
<li><p><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) ‚Äì common title for all produced plots. For example, ‚Äògenerator‚Äô</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.mlflow_logger.OutputHandler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.mlflow_logger.</span></span><span class="sig-name descname"><span class="pre">OutputHandler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tag</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">global_step_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/mlflow_logger.html#OutputHandler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.mlflow_logger.OutputHandler" title="Permalink to this definition">#</a></dt>
<dd><p>Helper handler to log engine‚Äôs output and/or metrics.</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.mlflow_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">mlflow_logger</span> <span class="o">=</span> <span class="n">MLflowLogger</span><span class="p">()</span>

<span class="c1"># Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="c1"># each epoch. We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch</span>
<span class="c1"># of the `trainer`:</span>
<span class="n">mlflow_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span>
    <span class="n">evaluator</span><span class="p">,</span>
    <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span>
        <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
        <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
        <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>
    <span class="p">),</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span>
<span class="p">)</span>
<span class="c1"># or equivalently</span>
<span class="n">mlflow_logger</span><span class="o">.</span><span class="n">attach_output_handler</span><span class="p">(</span>
    <span class="n">evaluator</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">,</span>
    <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
    <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Another example, where model is evaluated every 500 iterations:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.mlflow_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="nd">@trainer</span><span class="o">.</span><span class="n">on</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">(</span><span class="n">every</span><span class="o">=</span><span class="mi">500</span><span class="p">))</span>
<span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span><span class="n">engine</span><span class="p">):</span>
    <span class="n">evaluator</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">validation_set</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">mlflow_logger</span> <span class="o">=</span> <span class="n">MLflowLogger</span><span class="p">()</span>

<span class="k">def</span><span class="w"> </span><span class="nf">global_step_transform</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">trainer</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">iteration</span>

<span class="c1"># Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="c1"># every 500 iterations. Since evaluator engine does not have access to the training iteration, we</span>
<span class="c1"># provide a global_step_transform to return the trainer.state.iteration for the global_step, each time</span>
<span class="c1"># evaluator metrics are plotted on MLflow.</span>

<span class="n">mlflow_logger</span><span class="o">.</span><span class="n">attach_output_handler</span><span class="p">(</span>
    <span class="n">evaluator</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">,</span>
    <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
    <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_transform</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) ‚Äì common title for all produced plots. For example, ‚Äòtraining‚Äô</p></li>
<li><p><strong>metric_names</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.14)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) ‚Äì list of metric names to plot or a string ‚Äúall‚Äù to plot all available
metrics.</p></li>
<li><p><strong>output_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) ‚Äì output transform function to prepare <cite>engine.state.output</cite> as a number.
For example, <cite>output_transform = lambda output: output</cite>
This function can also return a dictionary, e.g <cite>{‚Äòloss‚Äô: loss1, ‚Äòanother_loss‚Äô: loss2}</cite> to label the plot
with corresponding keys.</p></li>
<li><p><strong>global_step_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) ‚Äì global step transform function to output a desired global step.
Input of the function is <cite>(engine, event_name)</cite>. Output of function should be an integer.
Default is None, global_step based on attached engine. If provided,
uses function output as global_step. To setup global step from another engine, please use
<a class="reference internal" href="#ignite.contrib.handlers.mlflow_logger.global_step_from_engine" title="ignite.contrib.handlers.mlflow_logger.global_step_from_engine"><code class="xref py py-meth docutils literal notranslate"><span class="pre">global_step_from_engine()</span></code></a>.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Example of <cite>global_step_transform</cite>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">global_step_transform</span><span class="p">(</span><span class="n">engine</span><span class="p">,</span> <span class="n">event_name</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">get_event_attrib_value</span><span class="p">(</span><span class="n">event_name</span><span class="p">)</span>
</pre></div>
</div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ignite.contrib.handlers.mlflow_logger.global_step_from_engine">
<span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.mlflow_logger.</span></span><span class="sig-name descname"><span class="pre">global_step_from_engine</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">engine</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_event_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/handlers.html#global_step_from_engine"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.mlflow_logger.global_step_from_engine" title="Permalink to this definition">#</a></dt>
<dd><p>Helper method to setup <cite>global_step_transform</cite> function using another engine.
This can be helpful for logging trainer epoch/iteration while output handler is attached to an evaluator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine" title="ignite.engine.engine.Engine"><em>Engine</em></a>) ‚Äì engine which state is used to provide the global step</p></li>
<li><p><strong>custom_event_name</strong> (<em>optional</em>) ‚Äì registered event name. Optional argument, event name to use.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>global step</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Callable" title="(in Python v3.14)"><em>Callable</em></a></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="tqdm-logger">
<h2>tqdm_logger<a class="headerlink" href="#tqdm-logger" title="Permalink to this heading">#</a></h2>
<p>See <a class="reference external" href="https://github.com/pytorch/ignite/blob/master/examples/contrib/mnist/mnist_with_tqdm_logger.py">tqdm mnist example</a>
for detailed usage.</p>
<span class="target" id="module-ignite.contrib.handlers.tqdm_logger"></span><dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.tqdm_logger.ProgressBar">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.tqdm_logger.</span></span><span class="sig-name descname"><span class="pre">ProgressBar</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">persist</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bar_format</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'{desc}[{n_fmt}/{total_fmt}]</span> <span class="pre">{percentage:3.0f}%|{bar}{postfix}</span> <span class="pre">[{elapsed}&lt;{remaining}]'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">tqdm_kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/tqdm_logger.html#ProgressBar"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.tqdm_logger.ProgressBar" title="Permalink to this definition">#</a></dt>
<dd><p>TQDM progress bar handler to log training progress and computed metrics.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>persist</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) ‚Äì set to <code class="docutils literal notranslate"><span class="pre">True</span></code> to persist the progress bar after completion (default = <code class="docutils literal notranslate"><span class="pre">False</span></code>)</p></li>
<li><p><strong>bar_format</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) ‚Äì Specify a custom bar string formatting. May impact performance.
[default: ‚Äò{desc}[{n_fmt}/{total_fmt}] {percentage:3.0f}%|{bar}{postfix} [{elapsed}&lt;{remaining}]‚Äô].
Set to <code class="docutils literal notranslate"><span class="pre">None</span></code> to use <code class="docutils literal notranslate"><span class="pre">tqdm</span></code> default bar formatting: ‚Äò{l_bar}{bar}{r_bar}‚Äô, where
l_bar=‚Äô{desc}: {percentage:3.0f}%|‚Äô and
r_bar=‚Äô| {n_fmt}/{total_fmt} [{elapsed}&lt;{remaining}, {rate_fmt}{postfix}]‚Äô. For more details on the
formatting, see <a class="reference external" href="https://tqdm.github.io/docs/tqdm/">tqdm docs</a>.</p></li>
<li><p><strong>**tqdm_kwargs</strong> ‚Äì kwargs passed to tqdm progress bar.
By default, progress bar description displays ‚ÄúEpoch [5/10]‚Äù where 5 is the current epoch and 10 is the
number of epochs; however, if <code class="docutils literal notranslate"><span class="pre">max_epochs</span></code> are set to 1, the progress bar instead displays
‚ÄúIteration: [5/10]‚Äù. If tqdm_kwargs defines <cite>desc</cite>, e.g. ‚ÄúPredictions‚Äù, than the description is
‚ÄúPredictions [5/10]‚Äù if number of epochs is more than one otherwise it is simply ‚ÄúPredictions‚Äù.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>Simple progress bar</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span> <span class="o">=</span> <span class="n">create_supervised_trainer</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>

<span class="n">pbar</span> <span class="o">=</span> <span class="n">ProgressBar</span><span class="p">()</span>
<span class="n">pbar</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>

<span class="c1"># Progress bar will looks like</span>
<span class="c1"># Epoch [2/50]: [64/128]  50%|‚ñà‚ñà‚ñà‚ñà‚ñà      [06:17&lt;12:34]</span>
</pre></div>
</div>
<p>Log output to a file instead of stderr (tqdm‚Äôs default output)</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span> <span class="o">=</span> <span class="n">create_supervised_trainer</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>

<span class="n">log_file</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;output.log&quot;</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span>
<span class="n">pbar</span> <span class="o">=</span> <span class="n">ProgressBar</span><span class="p">(</span><span class="n">file</span><span class="o">=</span><span class="n">log_file</span><span class="p">)</span>
<span class="n">pbar</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>
</pre></div>
</div>
<p>Attach metrics that already have been computed at <code class="xref py py-attr docutils literal notranslate"><span class="pre">ITERATION_COMPLETED</span></code>
(such as <a class="reference internal" href="../metrics.html#ignite.metrics.RunningAverage" title="ignite.metrics.RunningAverage"><code class="xref py py-class docutils literal notranslate"><span class="pre">RunningAverage</span></code></a>)</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span> <span class="o">=</span> <span class="n">create_supervised_trainer</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>

<span class="n">RunningAverage</span><span class="p">(</span><span class="n">output_transform</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="s1">&#39;loss&#39;</span><span class="p">)</span>

<span class="n">pbar</span> <span class="o">=</span> <span class="n">ProgressBar</span><span class="p">()</span>
<span class="n">pbar</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">])</span>

<span class="c1"># Progress bar will looks like</span>
<span class="c1"># Epoch [2/50]: [64/128]  50%|‚ñà‚ñà‚ñà‚ñà‚ñà      , loss=0.123 [06:17&lt;12:34]</span>
</pre></div>
</div>
<p>Directly attach the engine‚Äôs output</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span> <span class="o">=</span> <span class="n">create_supervised_trainer</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>

<span class="n">pbar</span> <span class="o">=</span> <span class="n">ProgressBar</span><span class="p">()</span>
<span class="n">pbar</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">output_transform</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">x</span><span class="p">})</span>

<span class="c1"># Progress bar will looks like</span>
<span class="c1"># Epoch [2/50]: [64/128]  50%|‚ñà‚ñà‚ñà‚ñà‚ñà      , loss=0.123 [06:17&lt;12:34]</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When adding attaching the progress bar to an engine, it is recommend that you replace
every print operation in the engine‚Äôs handlers triggered every iteration with
<code class="docutils literal notranslate"><span class="pre">pbar.log_message</span></code> to guarantee the correct format of the stdout.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When using inside jupyter notebook, <cite>ProgressBar</cite> automatically uses <cite>tqdm_notebook</cite>. For correct rendering,
please install <a class="reference external" href="https://ipywidgets.readthedocs.io/en/stable/user_install.html#installation">ipywidgets</a>.
Due to <a class="reference external" href="https://github.com/tqdm/tqdm/issues/594">tqdm notebook bugs</a>, bar format may be needed to be set
to an empty string value.</p>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.tqdm_logger.ProgressBar.attach">
<span class="sig-name descname"><span class="pre">attach</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">engine</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">event_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">Events.ITERATION_COMPLETED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">closing_event_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">Events.EPOCH_COMPLETED</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/tqdm_logger.html#ProgressBar.attach"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.tqdm_logger.ProgressBar.attach" title="Permalink to this definition">#</a></dt>
<dd><p>Attaches the progress bar to an engine object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine" title="ignite.engine.engine.Engine"><em>Engine</em></a>) ‚Äì engine object.</p></li>
<li><p><strong>metric_names</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.14)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) ‚Äì list of metric names to plot or a string ‚Äúall‚Äù to plot all available
metrics.</p></li>
<li><p><strong>output_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) ‚Äì a function to select what you want to print from the engine‚Äôs
output. This function may return either a dictionary with entries in the format of <code class="docutils literal notranslate"><span class="pre">{name:</span> <span class="pre">value}</span></code>,
or a single scalar, which will be displayed with the default name <cite>output</cite>.</p></li>
<li><p><strong>event_name</strong> ‚Äì event‚Äôs name on which the progress bar advances. Valid events are from
<a class="reference internal" href="../engine.html#ignite.engine.events.Events" title="ignite.engine.events.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a>.</p></li>
<li><p><strong>closing_event_name</strong> ‚Äì event‚Äôs name on which the progress bar is closed. Valid events are from
<a class="reference internal" href="../engine.html#ignite.engine.events.Events" title="ignite.engine.events.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a>.</p></li>
</ul>
</dd>
</dl>
<p>Note: accepted output value types are numbers, 0d and 1d torch tensors and strings</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.tqdm_logger.ProgressBar.attach_opt_params_handler">
<span class="sig-name descname"><span class="pre">attach_opt_params_handler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">engine</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">event_name</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/tqdm_logger.html#ProgressBar.attach_opt_params_handler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.tqdm_logger.ProgressBar.attach_opt_params_handler" title="Permalink to this definition">#</a></dt>
<dd><p>Intentionally empty</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine" title="ignite.engine.engine.Engine"><em>Engine</em></a>) ‚Äì </p></li>
<li><p><strong>event_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) ‚Äì </p></li>
<li><p><strong>args</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.14)"><em>Any</em></a>) ‚Äì </p></li>
<li><p><strong>kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Mapping" title="(in Python v3.14)"><em>Mapping</em></a>) ‚Äì </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.tqdm_logger.ProgressBar.log_message">
<span class="sig-name descname"><span class="pre">log_message</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">message</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/tqdm_logger.html#ProgressBar.log_message"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.tqdm_logger.ProgressBar.log_message" title="Permalink to this definition">#</a></dt>
<dd><p>Logs a message, preserving the progress bar correct output format.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>message</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) ‚Äì string you wish to log.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-ignite.contrib.handlers.polyaxon_logger">
<span id="polyaxon-logger"></span><h2>polyaxon_logger<a class="headerlink" href="#module-ignite.contrib.handlers.polyaxon_logger" title="Permalink to this heading">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.polyaxon_logger.OptimizerParamsHandler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.polyaxon_logger.</span></span><span class="sig-name descname"><span class="pre">OptimizerParamsHandler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'lr'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tag</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/polyaxon_logger.html#OptimizerParamsHandler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.polyaxon_logger.OptimizerParamsHandler" title="Permalink to this definition">#</a></dt>
<dd><p>Helper handler to log optimizer parameters</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.polyaxon_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">plx_logger</span> <span class="o">=</span> <span class="n">PolyaxonLogger</span><span class="p">()</span>

<span class="c1"># Attach the logger to the trainer to log optimizer&#39;s parameters, e.g. learning rate at each iteration</span>
<span class="n">plx_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">log_handler</span><span class="o">=</span><span class="n">OptimizerParamsHandler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">),</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span>
<span class="p">)</span>
<span class="c1"># or equivalently</span>
<span class="n">plx_logger</span><span class="o">.</span><span class="n">attach_opt_params_handler</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch v2.9)"><em>torch.optim.Optimizer</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.14)"><em>object</em></a>) ‚Äì torch optimizer or any object with attribute <code class="docutils literal notranslate"><span class="pre">param_groups</span></code>
as a sequence.</p></li>
<li><p><strong>param_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) ‚Äì parameter name</p></li>
<li><p><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) ‚Äì common title for all produced plots. For example, ‚Äúgenerator‚Äù</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.polyaxon_logger.OutputHandler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.polyaxon_logger.</span></span><span class="sig-name descname"><span class="pre">OutputHandler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tag</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">global_step_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/polyaxon_logger.html#OutputHandler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.polyaxon_logger.OutputHandler" title="Permalink to this definition">#</a></dt>
<dd><p>Helper handler to log engine‚Äôs output and/or metrics.</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.polyaxon_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">plx_logger</span> <span class="o">=</span> <span class="n">PolyaxonLogger</span><span class="p">()</span>

<span class="c1"># Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="c1"># each epoch. We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch</span>
<span class="c1"># of the `trainer`:</span>
<span class="n">plx_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span>
    <span class="n">evaluator</span><span class="p">,</span>
    <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span>
        <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
        <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
        <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>
    <span class="p">),</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span>
<span class="p">)</span>
<span class="c1"># or equivalently</span>
<span class="n">plx_logger</span><span class="o">.</span><span class="n">attach_output_handler</span><span class="p">(</span>
    <span class="n">evaluator</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">,</span>
    <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
    <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Another example, where model is evaluated every 500 iterations:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.polyaxon_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="nd">@trainer</span><span class="o">.</span><span class="n">on</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">(</span><span class="n">every</span><span class="o">=</span><span class="mi">500</span><span class="p">))</span>
<span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span><span class="n">engine</span><span class="p">):</span>
    <span class="n">evaluator</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">validation_set</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">plx_logger</span> <span class="o">=</span> <span class="n">PolyaxonLogger</span><span class="p">()</span>

<span class="k">def</span><span class="w"> </span><span class="nf">global_step_transform</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">trainer</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">iteration</span>

<span class="c1"># Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="c1"># every 500 iterations. Since evaluator engine does not have access to the training iteration, we</span>
<span class="c1"># provide a global_step_transform to return the trainer.state.iteration for the global_step, each time</span>
<span class="c1"># evaluator metrics are plotted on Polyaxon.</span>

<span class="n">plx_logger</span><span class="o">.</span><span class="n">attach_output_handler</span><span class="p">(</span>
    <span class="n">evaluator</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">,</span>
    <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
    <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_transform</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) ‚Äì common title for all produced plots. For example, ‚Äútraining‚Äù</p></li>
<li><p><strong>metric_names</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.14)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) ‚Äì list of metric names to plot or a string ‚Äúall‚Äù to plot all available
metrics.</p></li>
<li><p><strong>output_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) ‚Äì output transform function to prepare <cite>engine.state.output</cite> as a number.
For example, <cite>output_transform = lambda output: output</cite>
This function can also return a dictionary, e.g <cite>{‚Äúloss‚Äù: loss1, ‚Äúanother_loss‚Äù: loss2}</cite> to label the plot
with corresponding keys.</p></li>
<li><p><strong>global_step_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) ‚Äì global step transform function to output a desired global step.
Input of the function is <cite>(engine, event_name)</cite>. Output of function should be an integer.
Default is None, global_step based on attached engine. If provided,
uses function output as global_step. To setup global step from another engine, please use
<a class="reference internal" href="#ignite.contrib.handlers.polyaxon_logger.global_step_from_engine" title="ignite.contrib.handlers.polyaxon_logger.global_step_from_engine"><code class="xref py py-meth docutils literal notranslate"><span class="pre">global_step_from_engine()</span></code></a>.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Example of <cite>global_step_transform</cite>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">global_step_transform</span><span class="p">(</span><span class="n">engine</span><span class="p">,</span> <span class="n">event_name</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">get_event_attrib_value</span><span class="p">(</span><span class="n">event_name</span><span class="p">)</span>
</pre></div>
</div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.polyaxon_logger.PolyaxonLogger">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.polyaxon_logger.</span></span><span class="sig-name descname"><span class="pre">PolyaxonLogger</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/polyaxon_logger.html#PolyaxonLogger"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.polyaxon_logger.PolyaxonLogger" title="Permalink to this definition">#</a></dt>
<dd><p><a class="reference external" href="https://polyaxon.com/">Polyaxon</a> tracking client handler to log parameters and metrics during the training
and validation.</p>
<p>This class requires <a class="reference external" href="https://github.com/polyaxon/polyaxon-client/">polyaxon-client</a> package to be installed:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>polyaxon-client
</pre></div>
</div>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.polyaxon_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">plx_logger</span> <span class="o">=</span> <span class="n">PolyaxonLogger</span><span class="p">()</span>

<span class="c1"># Log experiment parameters:</span>
<span class="n">plx_logger</span><span class="o">.</span><span class="n">log_params</span><span class="p">(</span><span class="o">**</span><span class="p">{</span>
    <span class="s2">&quot;seed&quot;</span><span class="p">:</span> <span class="n">seed</span><span class="p">,</span>
    <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="n">batch_size</span><span class="p">,</span>
    <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>

    <span class="s2">&quot;pytorch version&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
    <span class="s2">&quot;ignite version&quot;</span><span class="p">:</span> <span class="n">ignite</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
    <span class="s2">&quot;cuda version&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">version</span><span class="o">.</span><span class="n">cuda</span><span class="p">,</span>
    <span class="s2">&quot;device name&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_name</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="p">})</span>

<span class="c1"># Attach the logger to the trainer to log training loss at each iteration</span>
<span class="n">plx_logger</span><span class="o">.</span><span class="n">attach_output_handler</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">,</span>
    <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;training&quot;</span><span class="p">,</span>
    <span class="n">output_transform</span><span class="o">=</span><span class="k">lambda</span> <span class="n">loss</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="n">loss</span><span class="p">}</span>
<span class="p">)</span>

<span class="c1"># Attach the logger to the evaluator on the training dataset and log NLL, Accuracy metrics after each epoch</span>
<span class="c1"># We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch</span>
<span class="c1"># of the `trainer` instead of `train_evaluator`.</span>
<span class="n">plx_logger</span><span class="o">.</span><span class="n">attach_output_handler</span><span class="p">(</span>
    <span class="n">train_evaluator</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">,</span>
    <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;training&quot;</span><span class="p">,</span>
    <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
    <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">),</span>
<span class="p">)</span>

<span class="c1"># Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="c1"># each epoch. We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch of the</span>
<span class="c1"># `trainer` instead of `evaluator`.</span>
<span class="n">plx_logger</span><span class="o">.</span><span class="n">attach_output_handler</span><span class="p">(</span>
    <span class="n">evaluator</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">,</span>
    <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
    <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">)),</span>
<span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log optimizer&#39;s parameters, e.g. learning rate at each iteration</span>
<span class="n">plx_logger</span><span class="o">.</span><span class="n">attach_opt_params_handler</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
    <span class="n">param_name</span><span class="o">=</span><span class="s1">&#39;lr&#39;</span>  <span class="c1"># optional</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>*args</strong> ‚Äì Positional arguments accepted from
<a class="reference external" href="https://docs.polyaxon.com/references/polyaxon-tracking-api/experiments/">Experiment</a>.</p></li>
<li><p><strong>**kwargs</strong> ‚Äì <p>Keyword arguments accepted from
<a class="reference external" href="https://docs.polyaxon.com/references/polyaxon-tracking-api/experiments/">Experiment</a>.</p>
</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.polyaxon_logger.PolyaxonLogger.attach">
<span class="sig-name descname"><span class="pre">attach</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">engine</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_handler</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">event_name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ignite.contrib.handlers.polyaxon_logger.PolyaxonLogger.attach" title="Permalink to this definition">#</a></dt>
<dd><p>Attach the logger to the engine and execute <cite>log_handler</cite> function at <cite>event_name</cite> events.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine" title="ignite.engine.engine.Engine"><em>Engine</em></a>) ‚Äì engine object.</p></li>
<li><p><strong>log_handler</strong> (<em>callable</em>) ‚Äì a logging handler to execute</p></li>
<li><p><strong>event_name</strong> ‚Äì event to attach the logging handler to. Valid events are from
<a class="reference internal" href="../engine.html#ignite.engine.events.Events" title="ignite.engine.events.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a> or any <cite>event_name</cite> added by
<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine.register_events" title="ignite.engine.engine.Engine.register_events"><code class="xref py py-meth docutils literal notranslate"><span class="pre">register_events()</span></code></a>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">RemovableEventHandle</span></code>, which can be used to remove the handler.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.polyaxon_logger.PolyaxonLogger.attach_opt_params_handler">
<span class="sig-name descname"><span class="pre">attach_opt_params_handler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">engine</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">event_name</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ignite.contrib.handlers.polyaxon_logger.PolyaxonLogger.attach_opt_params_handler" title="Permalink to this definition">#</a></dt>
<dd><p>Shortcut method to attach <cite>OptimizerParamsHandler</cite> to the logger.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine" title="ignite.engine.engine.Engine"><em>Engine</em></a>) ‚Äì engine object.</p></li>
<li><p><strong>event_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.14)"><em>Any</em></a>) ‚Äì event to attach the logging handler to. Valid events are from
<a class="reference internal" href="../engine.html#ignite.engine.events.Events" title="ignite.engine.events.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a> or any <cite>event_name</cite> added by
<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine.register_events" title="ignite.engine.engine.Engine.register_events"><code class="xref py py-meth docutils literal notranslate"><span class="pre">register_events()</span></code></a>.</p></li>
<li><p><strong>*args</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.14)"><em>Any</em></a>) ‚Äì args to initialize <cite>OptimizerParamsHandler</cite></p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Mapping" title="(in Python v3.14)"><em>Mapping</em></a>) ‚Äì kwargs to initialize <cite>OptimizerParamsHandler</cite></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">RemovableEventHandle</span></code>, which can be used to remove the handler.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.polyaxon_logger.PolyaxonLogger.attach_output_handler">
<span class="sig-name descname"><span class="pre">attach_output_handler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">engine</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">event_name</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ignite.contrib.handlers.polyaxon_logger.PolyaxonLogger.attach_output_handler" title="Permalink to this definition">#</a></dt>
<dd><p>Shortcut method to attach <cite>OutputHandler</cite> to the logger.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine" title="ignite.engine.engine.Engine"><em>Engine</em></a>) ‚Äì engine object.</p></li>
<li><p><strong>event_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.14)"><em>Any</em></a>) ‚Äì event to attach the logging handler to. Valid events are from
<a class="reference internal" href="../engine.html#ignite.engine.events.Events" title="ignite.engine.events.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a> or any <cite>event_name</cite> added by
<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine.register_events" title="ignite.engine.engine.Engine.register_events"><code class="xref py py-meth docutils literal notranslate"><span class="pre">register_events()</span></code></a>.</p></li>
<li><p><strong>*args</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.14)"><em>Any</em></a>) ‚Äì args to initialize <cite>OutputHandler</cite></p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Mapping" title="(in Python v3.14)"><em>Mapping</em></a>) ‚Äì kwargs to initialize <cite>OutputHandler</cite></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">RemovableEventHandle</span></code>, which can be used to remove the handler.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ignite.contrib.handlers.polyaxon_logger.global_step_from_engine">
<span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.polyaxon_logger.</span></span><span class="sig-name descname"><span class="pre">global_step_from_engine</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">engine</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_event_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/handlers.html#global_step_from_engine"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.polyaxon_logger.global_step_from_engine" title="Permalink to this definition">#</a></dt>
<dd><p>Helper method to setup <cite>global_step_transform</cite> function using another engine.
This can be helpful for logging trainer epoch/iteration while output handler is attached to an evaluator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine" title="ignite.engine.engine.Engine"><em>Engine</em></a>) ‚Äì engine which state is used to provide the global step</p></li>
<li><p><strong>custom_event_name</strong> (<em>optional</em>) ‚Äì registered event name. Optional argument, event name to use.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>global step</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Callable" title="(in Python v3.14)"><em>Callable</em></a></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="wandb-logger">
<h2>wandb_logger<a class="headerlink" href="#wandb-logger" title="Permalink to this heading">#</a></h2>
<p>See <a class="reference external" href="https://github.com/pytorch/ignite/blob/master/examples/contrib/mnist/mnist_with_wandb_logger.py">wandb mnist example</a>
for detailed usage.</p>
<span class="target" id="module-ignite.contrib.handlers.wandb_logger"></span><dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.wandb_logger.OptimizerParamsHandler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.wandb_logger.</span></span><span class="sig-name descname"><span class="pre">OptimizerParamsHandler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'lr'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tag</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sync</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/wandb_logger.html#OptimizerParamsHandler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.wandb_logger.OptimizerParamsHandler" title="Permalink to this definition">#</a></dt>
<dd><p>Helper handler to log optimizer parameters</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.wandb_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger. All parameters are optional. See documentation</span>
<span class="c1"># on wandb.init for details.</span>

<span class="n">wandb_logger</span> <span class="o">=</span> <span class="n">WandBLogger</span><span class="p">(</span>
    <span class="n">entity</span><span class="o">=</span><span class="s2">&quot;shared&quot;</span><span class="p">,</span>
    <span class="n">project</span><span class="o">=</span><span class="s2">&quot;pytorch-ignite-integration&quot;</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;cnn-mnist&quot;</span><span class="p">,</span>
    <span class="n">config</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;max_epochs&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">},</span>
    <span class="n">tags</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;pytorch-ignite&quot;</span><span class="p">,</span> <span class="s2">&quot;minst&quot;</span><span class="p">]</span>
<span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log optimizer&#39;s parameters, e.g. learning rate at each iteration</span>
<span class="n">wandb_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">log_handler</span><span class="o">=</span><span class="n">OptimizerParamsHandler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">),</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span>
<span class="p">)</span>
<span class="c1"># or equivalently</span>
<span class="n">wandb_logger</span><span class="o">.</span><span class="n">attach_opt_params_handler</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch v2.9)"><em>torch.optim.Optimizer</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.14)"><em>object</em></a>) ‚Äì torch optimizer or any object with attribute <code class="docutils literal notranslate"><span class="pre">param_groups</span></code>
as a sequence.</p></li>
<li><p><strong>param_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) ‚Äì parameter name</p></li>
<li><p><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) ‚Äì common title for all produced plots. For example, ‚Äúgenerator‚Äù</p></li>
<li><p><strong>sync</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) ‚Äì If set to False, process calls to log in a seperate thread. Default (None) uses whatever
the default value of wandb.log.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.wandb_logger.OutputHandler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.wandb_logger.</span></span><span class="sig-name descname"><span class="pre">OutputHandler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tag</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">global_step_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sync</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/wandb_logger.html#OutputHandler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.wandb_logger.OutputHandler" title="Permalink to this definition">#</a></dt>
<dd><p>Helper handler to log engine‚Äôs output and/or metrics</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.wandb_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger. All parameters are optional. See documentation</span>
<span class="c1"># on wandb.init for details.</span>

<span class="n">wandb_logger</span> <span class="o">=</span> <span class="n">WandBLogger</span><span class="p">(</span>
    <span class="n">entity</span><span class="o">=</span><span class="s2">&quot;shared&quot;</span><span class="p">,</span>
    <span class="n">project</span><span class="o">=</span><span class="s2">&quot;pytorch-ignite-integration&quot;</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;cnn-mnist&quot;</span><span class="p">,</span>
    <span class="n">config</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;max_epochs&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">},</span>
    <span class="n">tags</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;pytorch-ignite&quot;</span><span class="p">,</span> <span class="s2">&quot;minst&quot;</span><span class="p">]</span>
<span class="p">)</span>

<span class="c1"># Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="c1"># each epoch. We setup `global_step_transform=lambda *_: trainer.state.iteration,` to take iteration value</span>
<span class="c1"># of the `trainer`:</span>
<span class="n">wandb_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span>
    <span class="n">evaluator</span><span class="p">,</span>
    <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span>
        <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
        <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
        <span class="n">global_step_transform</span><span class="o">=</span><span class="k">lambda</span> <span class="o">*</span><span class="n">_</span><span class="p">:</span> <span class="n">trainer</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">iteration</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span>
<span class="p">)</span>
<span class="c1"># or equivalently</span>
<span class="n">wandb_logger</span><span class="o">.</span><span class="n">attach_output_handler</span><span class="p">(</span>
    <span class="n">evaluator</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">,</span>
    <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
    <span class="n">global_step_transform</span><span class="o">=</span><span class="k">lambda</span> <span class="o">*</span><span class="n">_</span><span class="p">:</span> <span class="n">trainer</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">iteration</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Another example, where model is evaluated every 500 iterations:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.wandb_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="nd">@trainer</span><span class="o">.</span><span class="n">on</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">(</span><span class="n">every</span><span class="o">=</span><span class="mi">500</span><span class="p">))</span>
<span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span><span class="n">engine</span><span class="p">):</span>
    <span class="n">evaluator</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">validation_set</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Create a logger. All parameters are optional. See documentation</span>
<span class="c1"># on wandb.init for details.</span>

<span class="n">wandb_logger</span> <span class="o">=</span> <span class="n">WandBLogger</span><span class="p">(</span>
    <span class="n">entity</span><span class="o">=</span><span class="s2">&quot;shared&quot;</span><span class="p">,</span>
    <span class="n">project</span><span class="o">=</span><span class="s2">&quot;pytorch-ignite-integration&quot;</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;cnn-mnist&quot;</span><span class="p">,</span>
    <span class="n">config</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;max_epochs&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">},</span>
    <span class="n">tags</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;pytorch-ignite&quot;</span><span class="p">,</span> <span class="s2">&quot;minst&quot;</span><span class="p">]</span>
<span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">global_step_transform</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">trainer</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">iteration</span>

<span class="c1"># Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="c1"># every 500 iterations. Since evaluator engine does not have access to the training iteration, we</span>
<span class="c1"># provide a global_step_transform to return the trainer.state.iteration for the global_step, each time</span>
<span class="c1"># evaluator metrics are plotted on Weights &amp; Biases.</span>

<span class="n">wandb_logger</span><span class="o">.</span><span class="n">attach_output_handler</span><span class="p">(</span>
    <span class="n">evaluator</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">,</span>
    <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
    <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_transform</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) ‚Äì common title for all produced plots. For example, ‚Äútraining‚Äù</p></li>
<li><p><strong>metric_names</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.14)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) ‚Äì list of metric names to plot or a string ‚Äúall‚Äù to plot all available
metrics.</p></li>
<li><p><strong>output_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) ‚Äì output transform function to prepare <cite>engine.state.output</cite> as a number.
For example, <cite>output_transform = lambda output: output</cite>
This function can also return a dictionary, e.g <cite>{‚Äúloss‚Äù: loss1, ‚Äúanother_loss‚Äù: loss2}</cite> to label the plot
with corresponding keys.</p></li>
<li><p><strong>global_step_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) ‚Äì global step transform function to output a desired global step.
Input of the function is <cite>(engine, event_name)</cite>. Output of function should be an integer.
Default is None, global_step based on attached engine. If provided,
uses function output as global_step. To setup global step from another engine, please use
<a class="reference internal" href="#ignite.contrib.handlers.wandb_logger.global_step_from_engine" title="ignite.contrib.handlers.wandb_logger.global_step_from_engine"><code class="xref py py-meth docutils literal notranslate"><span class="pre">global_step_from_engine()</span></code></a>.</p></li>
<li><p><strong>sync</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) ‚Äì If set to False, process calls to log in a seperate thread. Default (None) uses whatever
the default value of wandb.log.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Example of <cite>global_step_transform</cite>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">global_step_transform</span><span class="p">(</span><span class="n">engine</span><span class="p">,</span> <span class="n">event_name</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">get_event_attrib_value</span><span class="p">(</span><span class="n">event_name</span><span class="p">)</span>
</pre></div>
</div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.wandb_logger.WandBLogger">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.wandb_logger.</span></span><span class="sig-name descname"><span class="pre">WandBLogger</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/wandb_logger.html#WandBLogger"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.wandb_logger.WandBLogger" title="Permalink to this definition">#</a></dt>
<dd><p><a class="reference external" href="https://app.wandb.ai/">Weights &amp; Biases</a> handler to log metrics, model/optimizer parameters, gradients
during training and validation. It can also be used to log model checkpoints to the Weights &amp; Biases cloud.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>wandb
</pre></div>
</div>
<p>This class is also a wrapper for the wandb module. This means that you can call any wandb function using
this wrapper. See examples on how to save model parameters and gradients.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>*args</strong> ‚Äì Positional arguments accepted by <cite>wandb.init</cite>.</p></li>
<li><p><strong>**kwargs</strong> ‚Äì Keyword arguments accepted by <cite>wandb.init</cite>.
Please see <a class="reference external" href="https://docs.wandb.com/library/init">wandb.init</a> for documentation of possible parameters.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.wandb_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger. All parameters are optional. See documentation</span>
<span class="c1"># on wandb.init for details.</span>

<span class="n">wandb_logger</span> <span class="o">=</span> <span class="n">WandBLogger</span><span class="p">(</span>
    <span class="n">entity</span><span class="o">=</span><span class="s2">&quot;shared&quot;</span><span class="p">,</span>
    <span class="n">project</span><span class="o">=</span><span class="s2">&quot;pytorch-ignite-integration&quot;</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;cnn-mnist&quot;</span><span class="p">,</span>
    <span class="n">config</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;max_epochs&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">},</span>
    <span class="n">tags</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;pytorch-ignite&quot;</span><span class="p">,</span> <span class="s2">&quot;minst&quot;</span><span class="p">]</span>
<span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log training loss at each iteration</span>
<span class="n">wandb_logger</span><span class="o">.</span><span class="n">attach_output_handler</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">,</span>
    <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;training&quot;</span><span class="p">,</span>
    <span class="n">output_transform</span><span class="o">=</span><span class="k">lambda</span> <span class="n">loss</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="n">loss</span><span class="p">}</span>
<span class="p">)</span>

<span class="c1"># Attach the logger to the evaluator on the training dataset and log NLL, Accuracy metrics after each epoch</span>
<span class="c1"># We setup `global_step_transform=lambda *_: trainer.state.iteration` to take iteration value</span>
<span class="c1"># of the `trainer`:</span>
<span class="n">wandb_logger</span><span class="o">.</span><span class="n">attach_output_handler</span><span class="p">(</span>
    <span class="n">train_evaluator</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">,</span>
    <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;training&quot;</span><span class="p">,</span>
    <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
    <span class="n">global_step_transform</span><span class="o">=</span><span class="k">lambda</span> <span class="o">*</span><span class="n">_</span><span class="p">:</span> <span class="n">trainer</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">iteration</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="c1"># each epoch. We setup `global_step_transform=lambda *_: trainer.state.iteration` to take iteration value</span>
<span class="c1"># of the `trainer` instead of `evaluator`.</span>
<span class="n">wandb_logger</span><span class="o">.</span><span class="n">attach_output_handler</span><span class="p">(</span>
    <span class="n">evaluator</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">,</span>
    <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
    <span class="n">global_step_transform</span><span class="o">=</span><span class="k">lambda</span> <span class="o">*</span><span class="n">_</span><span class="p">:</span> <span class="n">trainer</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">iteration</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log optimizer&#39;s parameters, e.g. learning rate at each iteration</span>
<span class="n">wandb_logger</span><span class="o">.</span><span class="n">attach_opt_params_handler</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
    <span class="n">param_name</span><span class="o">=</span><span class="s1">&#39;lr&#39;</span>  <span class="c1"># optional</span>
<span class="p">)</span>
</pre></div>
</div>
<p>If you want to log model gradients, the model call graph, etc., use the logger as wrapper of wandb. Refer
to the documentation of wandb.watch for details:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">wandb_logger</span> <span class="o">=</span> <span class="n">WandBLogger</span><span class="p">(</span>
    <span class="n">entity</span><span class="o">=</span><span class="s2">&quot;shared&quot;</span><span class="p">,</span>
    <span class="n">project</span><span class="o">=</span><span class="s2">&quot;pytorch-ignite-integration&quot;</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;cnn-mnist&quot;</span><span class="p">,</span>
    <span class="n">config</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;max_epochs&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">},</span>
    <span class="n">tags</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;pytorch-ignite&quot;</span><span class="p">,</span> <span class="s2">&quot;minst&quot;</span><span class="p">]</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">wandb_logger</span><span class="o">.</span><span class="n">watch</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
<p>For model checkpointing, Weights &amp; Biases creates a local run dir, and automatically synchronizes all
files saved there at the end of the run. You can just use the <cite>wandb_logger.run.dir</cite> as path for the
<cite>ModelCheckpoint</cite>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.handlers</span><span class="w"> </span><span class="kn">import</span> <span class="n">ModelCheckpoint</span>

<span class="k">def</span><span class="w"> </span><span class="nf">score_function</span><span class="p">(</span><span class="n">engine</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span>

<span class="n">model_checkpoint</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span>
    <span class="n">wandb_logger</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">dir</span><span class="p">,</span> <span class="n">n_saved</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">filename_prefix</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">,</span>
    <span class="n">require_empty</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">score_function</span><span class="o">=</span><span class="n">score_function</span><span class="p">,</span>
    <span class="n">score_name</span><span class="o">=</span><span class="s2">&quot;validation_accuracy&quot;</span><span class="p">,</span>
    <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">evaluator</span><span class="o">.</span><span class="n">add_event_handler</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">COMPLETED</span><span class="p">,</span> <span class="n">model_checkpoint</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;model&#39;</span><span class="p">:</span> <span class="n">model</span><span class="p">})</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.wandb_logger.WandBLogger.attach">
<span class="sig-name descname"><span class="pre">attach</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">engine</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_handler</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">event_name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ignite.contrib.handlers.wandb_logger.WandBLogger.attach" title="Permalink to this definition">#</a></dt>
<dd><p>Attach the logger to the engine and execute <cite>log_handler</cite> function at <cite>event_name</cite> events.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine" title="ignite.engine.engine.Engine"><em>Engine</em></a>) ‚Äì engine object.</p></li>
<li><p><strong>log_handler</strong> (<em>callable</em>) ‚Äì a logging handler to execute</p></li>
<li><p><strong>event_name</strong> ‚Äì event to attach the logging handler to. Valid events are from
<a class="reference internal" href="../engine.html#ignite.engine.events.Events" title="ignite.engine.events.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a> or any <cite>event_name</cite> added by
<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine.register_events" title="ignite.engine.engine.Engine.register_events"><code class="xref py py-meth docutils literal notranslate"><span class="pre">register_events()</span></code></a>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">RemovableEventHandle</span></code>, which can be used to remove the handler.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.wandb_logger.WandBLogger.attach_opt_params_handler">
<span class="sig-name descname"><span class="pre">attach_opt_params_handler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">engine</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">event_name</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ignite.contrib.handlers.wandb_logger.WandBLogger.attach_opt_params_handler" title="Permalink to this definition">#</a></dt>
<dd><p>Shortcut method to attach <cite>OptimizerParamsHandler</cite> to the logger.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine" title="ignite.engine.engine.Engine"><em>Engine</em></a>) ‚Äì engine object.</p></li>
<li><p><strong>event_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.14)"><em>Any</em></a>) ‚Äì event to attach the logging handler to. Valid events are from
<a class="reference internal" href="../engine.html#ignite.engine.events.Events" title="ignite.engine.events.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a> or any <cite>event_name</cite> added by
<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine.register_events" title="ignite.engine.engine.Engine.register_events"><code class="xref py py-meth docutils literal notranslate"><span class="pre">register_events()</span></code></a>.</p></li>
<li><p><strong>*args</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.14)"><em>Any</em></a>) ‚Äì args to initialize <cite>OptimizerParamsHandler</cite></p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Mapping" title="(in Python v3.14)"><em>Mapping</em></a>) ‚Äì kwargs to initialize <cite>OptimizerParamsHandler</cite></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">RemovableEventHandle</span></code>, which can be used to remove the handler.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.wandb_logger.WandBLogger.attach_output_handler">
<span class="sig-name descname"><span class="pre">attach_output_handler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">engine</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">event_name</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ignite.contrib.handlers.wandb_logger.WandBLogger.attach_output_handler" title="Permalink to this definition">#</a></dt>
<dd><p>Shortcut method to attach <cite>OutputHandler</cite> to the logger.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine" title="ignite.engine.engine.Engine"><em>Engine</em></a>) ‚Äì engine object.</p></li>
<li><p><strong>event_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.14)"><em>Any</em></a>) ‚Äì event to attach the logging handler to. Valid events are from
<a class="reference internal" href="../engine.html#ignite.engine.events.Events" title="ignite.engine.events.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a> or any <cite>event_name</cite> added by
<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine.register_events" title="ignite.engine.engine.Engine.register_events"><code class="xref py py-meth docutils literal notranslate"><span class="pre">register_events()</span></code></a>.</p></li>
<li><p><strong>*args</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.14)"><em>Any</em></a>) ‚Äì args to initialize <cite>OutputHandler</cite></p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Mapping" title="(in Python v3.14)"><em>Mapping</em></a>) ‚Äì kwargs to initialize <cite>OutputHandler</cite></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">RemovableEventHandle</span></code>, which can be used to remove the handler.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ignite.contrib.handlers.wandb_logger.global_step_from_engine">
<span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.wandb_logger.</span></span><span class="sig-name descname"><span class="pre">global_step_from_engine</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">engine</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_event_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/handlers.html#global_step_from_engine"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.wandb_logger.global_step_from_engine" title="Permalink to this definition">#</a></dt>
<dd><p>Helper method to setup <cite>global_step_transform</cite> function using another engine.
This can be helpful for logging trainer epoch/iteration while output handler is attached to an evaluator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine" title="ignite.engine.engine.Engine"><em>Engine</em></a>) ‚Äì engine which state is used to provide the global step</p></li>
<li><p><strong>custom_event_name</strong> (<em>optional</em>) ‚Äì registered event name. Optional argument, event name to use.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>global step</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Callable" title="(in Python v3.14)"><em>Callable</em></a></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="trains-logger">
<h2>trains_logger<a class="headerlink" href="#trains-logger" title="Permalink to this heading">#</a></h2>
<p>See <a class="reference external" href="https://github.com/pytorch/ignite/blob/master/examples/contrib/mnist/mnist_with_trains_logger.py">trains mnist example</a>
for detailed usage.</p>
<span class="target" id="module-ignite.contrib.handlers.trains_logger"></span><dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.trains_logger.GradsHistHandler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.trains_logger.</span></span><span class="sig-name descname"><span class="pre">GradsHistHandler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tag</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/trains_logger.html#GradsHistHandler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.trains_logger.GradsHistHandler" title="Permalink to this definition">#</a></dt>
<dd><p>Helper handler to log model‚Äôs gradients as histograms.</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.trains_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>

<span class="n">trains_logger</span> <span class="o">=</span> <span class="n">TrainsLogger</span><span class="p">(</span>
    <span class="n">project_name</span><span class="o">=</span><span class="s2">&quot;pytorch-ignite-integration&quot;</span><span class="p">,</span>
    <span class="n">task_name</span><span class="o">=</span><span class="s2">&quot;cnn-mnist&quot;</span>
<span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log model&#39;s weights norm after each iteration</span>
<span class="n">trains_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">,</span>
    <span class="n">log_handler</span><span class="o">=</span><span class="n">GradsHistHandler</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.9)"><em>torch.nn.Module</em></a>) ‚Äì model to log weights</p></li>
<li><p><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) ‚Äì common title for all produced plots. For example, ‚Äògenerator‚Äô</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.trains_logger.GradsScalarHandler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.trains_logger.</span></span><span class="sig-name descname"><span class="pre">GradsScalarHandler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction=&lt;function</span> <span class="pre">norm&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tag=None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/trains_logger.html#GradsScalarHandler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.trains_logger.GradsScalarHandler" title="Permalink to this definition">#</a></dt>
<dd><p>Helper handler to log model‚Äôs gradients as scalars.
Handler iterates over the gradients of named parameters of the model, applies reduction function to each parameter
produce a scalar and then logs the scalar.</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.trains_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>

<span class="n">trains_logger</span> <span class="o">=</span> <span class="n">TrainsLogger</span><span class="p">(</span>
    <span class="n">project_name</span><span class="o">=</span><span class="s2">&quot;pytorch-ignite-integration&quot;</span><span class="p">,</span>
    <span class="n">task_name</span><span class="o">=</span><span class="s2">&quot;cnn-mnist&quot;</span>
<span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log model&#39;s weights norm after each iteration</span>
<span class="n">trains_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">,</span>
    <span class="n">log_handler</span><span class="o">=</span><span class="n">GradsScalarHandler</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.9)"><em>torch.nn.Module</em></a>) ‚Äì model to log weights</p></li>
<li><p><strong>reduction</strong> (<em>callable</em>) ‚Äì function to reduce parameters into scalar</p></li>
<li><p><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) ‚Äì common title for all produced plots. For example, ‚Äúgenerator‚Äù</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.trains_logger.OptimizerParamsHandler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.trains_logger.</span></span><span class="sig-name descname"><span class="pre">OptimizerParamsHandler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'lr'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tag</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/trains_logger.html#OptimizerParamsHandler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.trains_logger.OptimizerParamsHandler" title="Permalink to this definition">#</a></dt>
<dd><p>Helper handler to log optimizer parameters</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.trains_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>

<span class="n">trains_logger</span> <span class="o">=</span> <span class="n">TrainsLogger</span><span class="p">(</span>
    <span class="n">project_name</span><span class="o">=</span><span class="s2">&quot;pytorch-ignite-integration&quot;</span><span class="p">,</span>
    <span class="n">task_name</span><span class="o">=</span><span class="s2">&quot;cnn-mnist&quot;</span>
<span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log optimizer&#39;s parameters, e.g. learning rate at each iteration</span>
<span class="n">trains_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">log_handler</span><span class="o">=</span><span class="n">OptimizerParamsHandler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">),</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span>
<span class="p">)</span>
<span class="c1"># or equivalently</span>
<span class="n">trains_logger</span><span class="o">.</span><span class="n">attach_opt_params_handler</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch v2.9)"><em>torch.optim.Optimizer</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.14)"><em>object</em></a>) ‚Äì torch optimizer or any object with attribute <code class="docutils literal notranslate"><span class="pre">param_groups</span></code>
as a sequence.</p></li>
<li><p><strong>param_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) ‚Äì parameter name</p></li>
<li><p><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) ‚Äì common title for all produced plots. For example, ‚Äúgenerator‚Äù</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.trains_logger.OutputHandler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.trains_logger.</span></span><span class="sig-name descname"><span class="pre">OutputHandler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tag</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">global_step_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/trains_logger.html#OutputHandler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.trains_logger.OutputHandler" title="Permalink to this definition">#</a></dt>
<dd><p>Helper handler to log engine‚Äôs output and/or metrics</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.trains_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>

<span class="n">trains_logger</span> <span class="o">=</span> <span class="n">TrainsLogger</span><span class="p">(</span>
    <span class="n">project_name</span><span class="o">=</span><span class="s2">&quot;pytorch-ignite-integration&quot;</span><span class="p">,</span>
    <span class="n">task_name</span><span class="o">=</span><span class="s2">&quot;cnn-mnist&quot;</span>
<span class="p">)</span>

<span class="c1"># Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="c1"># each epoch. We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch</span>
<span class="c1"># of the `trainer`:</span>
<span class="n">trains_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span>
    <span class="n">evaluator</span><span class="p">,</span>
    <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span>
        <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
        <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
        <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>
    <span class="p">),</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span>
<span class="p">)</span>
<span class="c1"># or equivalently</span>
<span class="n">trains_logger</span><span class="o">.</span><span class="n">attach_output_handler</span><span class="p">(</span>
    <span class="n">evaluator</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">,</span>
    <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
    <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Another example, where model is evaluated every 500 iterations:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.trains_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="nd">@trainer</span><span class="o">.</span><span class="n">on</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">(</span><span class="n">every</span><span class="o">=</span><span class="mi">500</span><span class="p">))</span>
<span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span><span class="n">engine</span><span class="p">):</span>
    <span class="n">evaluator</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">validation_set</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Create a logger</span>

<span class="n">trains_logger</span> <span class="o">=</span> <span class="n">TrainsLogger</span><span class="p">(</span>
    <span class="n">project_name</span><span class="o">=</span><span class="s2">&quot;pytorch-ignite-integration&quot;</span><span class="p">,</span>
    <span class="n">task_name</span><span class="o">=</span><span class="s2">&quot;cnn-mnist&quot;</span>
<span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">global_step_transform</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">trainer</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">iteration</span>

<span class="c1"># Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="c1"># every 500 iterations. Since evaluator engine does not have access to the training iteration, we</span>
<span class="c1"># provide a global_step_transform to return the trainer.state.iteration for the global_step, each time</span>
<span class="c1"># evaluator metrics are plotted on Trains.</span>

<span class="n">trains_logger</span><span class="o">.</span><span class="n">attach_output_handler</span><span class="p">(</span>
    <span class="n">evaluator</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">,</span>
    <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
    <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_transform</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) ‚Äì common title for all produced plots. For example, ‚Äútraining‚Äù</p></li>
<li><p><strong>metric_names</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.14)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) ‚Äì list of metric names to plot or a string ‚Äúall‚Äù to plot all available
metrics.</p></li>
<li><p><strong>output_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) ‚Äì output transform function to prepare <cite>engine.state.output</cite> as a number.
For example, <cite>output_transform = lambda output: output</cite>
This function can also return a dictionary, e.g <cite>{‚Äúloss‚Äù: loss1, ‚Äúanother_loss‚Äù: loss2}</cite> to label the plot
with corresponding keys.</p></li>
<li><p><strong>global_step_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) ‚Äì global step transform function to output a desired global step.
Input of the function is <cite>(engine, event_name)</cite>. Output of function should be an integer.
Default is None, global_step based on attached engine. If provided,
uses function output as global_step. To setup global step from another engine, please use
<a class="reference internal" href="#ignite.contrib.handlers.trains_logger.global_step_from_engine" title="ignite.contrib.handlers.trains_logger.global_step_from_engine"><code class="xref py py-meth docutils literal notranslate"><span class="pre">global_step_from_engine()</span></code></a>.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Example of <cite>global_step_transform</cite>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">global_step_transform</span><span class="p">(</span><span class="n">engine</span><span class="p">,</span> <span class="n">event_name</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">get_event_attrib_value</span><span class="p">(</span><span class="n">event_name</span><span class="p">)</span>
</pre></div>
</div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.trains_logger.TrainsLogger">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.trains_logger.</span></span><span class="sig-name descname"><span class="pre">TrainsLogger</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">_</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/trains_logger.html#TrainsLogger"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.trains_logger.TrainsLogger" title="Permalink to this definition">#</a></dt>
<dd><p><a class="reference external" href="https://github.com/allegroai/trains">Trains</a> handler to log metrics, text, model/optimizer parameters,
plots during training and validation.
Also supports model checkpoints logging and upload to the storage solution of your choice (i.e. Trains File server,
S3 bucket etc.)</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>trains
trains-init
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>project_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) ‚Äì The name of the project in which the experiment will be created. If the project
does not exist, it is created. If <code class="docutils literal notranslate"><span class="pre">project_name</span></code> is <code class="docutils literal notranslate"><span class="pre">None</span></code>, the repository name is used. (Optional)</p></li>
<li><p><strong>task_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) ‚Äì The name of Task (experiment). If <code class="docutils literal notranslate"><span class="pre">task_name</span></code> is <code class="docutils literal notranslate"><span class="pre">None</span></code>, the Python experiment
script‚Äôs file name is used. (Optional)</p></li>
<li><p><strong>task_type</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) ‚Äì Optional. The task type. Valid values are:
- <code class="docutils literal notranslate"><span class="pre">TaskTypes.training</span></code> (Default)
- <code class="docutils literal notranslate"><span class="pre">TaskTypes.train</span></code>
- <code class="docutils literal notranslate"><span class="pre">TaskTypes.testing</span></code>
- <code class="docutils literal notranslate"><span class="pre">TaskTypes.inference</span></code></p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.trains_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>

<span class="n">trains_logger</span> <span class="o">=</span> <span class="n">TrainsLogger</span><span class="p">(</span>
    <span class="n">project_name</span><span class="o">=</span><span class="s2">&quot;pytorch-ignite-integration&quot;</span><span class="p">,</span>
    <span class="n">task_name</span><span class="o">=</span><span class="s2">&quot;cnn-mnist&quot;</span>
<span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log training loss at each iteration</span>
<span class="n">trains_logger</span><span class="o">.</span><span class="n">attach_output_handler</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">,</span>
    <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;training&quot;</span><span class="p">,</span>
    <span class="n">output_transform</span><span class="o">=</span><span class="k">lambda</span> <span class="n">loss</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="n">loss</span><span class="p">}</span>
<span class="p">)</span>

<span class="c1"># Attach the logger to the evaluator on the training dataset and log NLL, Accuracy metrics after each epoch</span>
<span class="c1"># We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch</span>
<span class="c1"># of the `trainer` instead of `train_evaluator`.</span>
<span class="n">trains_logger</span><span class="o">.</span><span class="n">attach_output_handler</span><span class="p">(</span>
    <span class="n">train_evaluator</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">,</span>
    <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;training&quot;</span><span class="p">,</span>
    <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
    <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">),</span>
<span class="p">)</span>

<span class="c1"># Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="c1"># each epoch. We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch of the</span>
<span class="c1"># `trainer` instead of `evaluator`.</span>
<span class="n">trains_logger</span><span class="o">.</span><span class="n">attach_output_handler</span><span class="p">(</span>
    <span class="n">evaluator</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">,</span>
    <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
    <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">)),</span>
<span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log optimizer&#39;s parameters, e.g. learning rate at each iteration</span>
<span class="n">trains_logger</span><span class="o">.</span><span class="n">attach_opt_params_handler</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
    <span class="n">param_name</span><span class="o">=</span><span class="s1">&#39;lr&#39;</span>  <span class="c1"># optional</span>
<span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log model&#39;s weights norm after each iteration</span>
<span class="n">trains_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">,</span>
    <span class="n">log_handler</span><span class="o">=</span><span class="n">WeightsScalarHandler</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.trains_logger.TrainsLogger.attach">
<span class="sig-name descname"><span class="pre">attach</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">engine</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_handler</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">event_name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ignite.contrib.handlers.trains_logger.TrainsLogger.attach" title="Permalink to this definition">#</a></dt>
<dd><p>Attach the logger to the engine and execute <cite>log_handler</cite> function at <cite>event_name</cite> events.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine" title="ignite.engine.engine.Engine"><em>Engine</em></a>) ‚Äì engine object.</p></li>
<li><p><strong>log_handler</strong> (<em>callable</em>) ‚Äì a logging handler to execute</p></li>
<li><p><strong>event_name</strong> ‚Äì event to attach the logging handler to. Valid events are from
<a class="reference internal" href="../engine.html#ignite.engine.events.Events" title="ignite.engine.events.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a> or any <cite>event_name</cite> added by
<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine.register_events" title="ignite.engine.engine.Engine.register_events"><code class="xref py py-meth docutils literal notranslate"><span class="pre">register_events()</span></code></a>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">RemovableEventHandle</span></code>, which can be used to remove the handler.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.trains_logger.TrainsLogger.attach_opt_params_handler">
<span class="sig-name descname"><span class="pre">attach_opt_params_handler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">engine</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">event_name</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ignite.contrib.handlers.trains_logger.TrainsLogger.attach_opt_params_handler" title="Permalink to this definition">#</a></dt>
<dd><p>Shortcut method to attach <cite>OptimizerParamsHandler</cite> to the logger.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine" title="ignite.engine.engine.Engine"><em>Engine</em></a>) ‚Äì engine object.</p></li>
<li><p><strong>event_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.14)"><em>Any</em></a>) ‚Äì event to attach the logging handler to. Valid events are from
<a class="reference internal" href="../engine.html#ignite.engine.events.Events" title="ignite.engine.events.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a> or any <cite>event_name</cite> added by
<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine.register_events" title="ignite.engine.engine.Engine.register_events"><code class="xref py py-meth docutils literal notranslate"><span class="pre">register_events()</span></code></a>.</p></li>
<li><p><strong>*args</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.14)"><em>Any</em></a>) ‚Äì args to initialize <cite>OptimizerParamsHandler</cite></p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Mapping" title="(in Python v3.14)"><em>Mapping</em></a>) ‚Äì kwargs to initialize <cite>OptimizerParamsHandler</cite></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">RemovableEventHandle</span></code>, which can be used to remove the handler.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.trains_logger.TrainsLogger.attach_output_handler">
<span class="sig-name descname"><span class="pre">attach_output_handler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">engine</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">event_name</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ignite.contrib.handlers.trains_logger.TrainsLogger.attach_output_handler" title="Permalink to this definition">#</a></dt>
<dd><p>Shortcut method to attach <cite>OutputHandler</cite> to the logger.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine" title="ignite.engine.engine.Engine"><em>Engine</em></a>) ‚Äì engine object.</p></li>
<li><p><strong>event_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.14)"><em>Any</em></a>) ‚Äì event to attach the logging handler to. Valid events are from
<a class="reference internal" href="../engine.html#ignite.engine.events.Events" title="ignite.engine.events.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a> or any <cite>event_name</cite> added by
<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine.register_events" title="ignite.engine.engine.Engine.register_events"><code class="xref py py-meth docutils literal notranslate"><span class="pre">register_events()</span></code></a>.</p></li>
<li><p><strong>*args</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.14)"><em>Any</em></a>) ‚Äì args to initialize <cite>OutputHandler</cite></p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Mapping" title="(in Python v3.14)"><em>Mapping</em></a>) ‚Äì kwargs to initialize <cite>OutputHandler</cite></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">RemovableEventHandle</span></code>, which can be used to remove the handler.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.trains_logger.TrainsLogger.bypass_mode">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">bypass_mode</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/trains_logger.html#TrainsLogger.bypass_mode"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.trains_logger.TrainsLogger.bypass_mode" title="Permalink to this definition">#</a></dt>
<dd><p>Returns the bypass mode state.
.. note:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>`GITHUB_ACTIONS` env will automatically set bypass_mode to ``True``
unless overridden specifically with ``TrainsLogger.set_bypass_mode(False)``.
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>If True, all outside communication is skipped.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)">bool</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.trains_logger.TrainsLogger.set_bypass_mode">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">set_bypass_mode</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">bypass</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/trains_logger.html#TrainsLogger.set_bypass_mode"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.trains_logger.TrainsLogger.set_bypass_mode" title="Permalink to this definition">#</a></dt>
<dd><p>Will bypass all outside communication, and will drop all logs.
Should only be used in ‚Äústandalone mode‚Äù, when there is no access to the <em>trains-server</em>.
:param bypass: If <code class="docutils literal notranslate"><span class="pre">True</span></code>, all outside communication is skipped.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>bypass</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a>) ‚Äì </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.trains_logger.TrainsSaver">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.trains_logger.</span></span><span class="sig-name descname"><span class="pre">TrainsSaver</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_uri</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dirname</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/trains_logger.html#TrainsSaver"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.trains_logger.TrainsSaver" title="Permalink to this definition">#</a></dt>
<dd><p>Handler that saves input checkpoint as Trains artifacts</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>logger</strong> (<a class="reference internal" href="#ignite.contrib.handlers.trains_logger.TrainsLogger" title="ignite.contrib.handlers.trains_logger.TrainsLogger"><em>TrainsLogger</em></a><em>, </em><em>optional</em>) ‚Äì An instance of <code class="xref py py-class docutils literal notranslate"><span class="pre">TrainsLogger</span></code>, ensuring a valid
Trains <code class="docutils literal notranslate"><span class="pre">Task</span></code> has been initialized. If not provided, and a Trains Task has not been manually initialized,
a runtime error will be raised.</p></li>
<li><p><strong>output_uri</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) ‚Äì The default location for output models and other artifacts uploaded by Trains. For
more information, see <code class="docutils literal notranslate"><span class="pre">trains.Task.init</span></code>.</p></li>
<li><p><strong>dirname</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) ‚Äì Directory path where the checkpoint will be saved. If not provided, a temporary
directory will be created.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.trains_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ignite.handlers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Checkpoint</span>

<span class="n">trains_logger</span> <span class="o">=</span> <span class="n">TrainsLogger</span><span class="p">(</span>
    <span class="n">project_name</span><span class="o">=</span><span class="s2">&quot;pytorch-ignite-integration&quot;</span><span class="p">,</span>
    <span class="n">task_name</span><span class="o">=</span><span class="s2">&quot;cnn-mnist&quot;</span>
<span class="p">)</span>

<span class="n">to_save</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="n">model</span><span class="p">}</span>

<span class="n">handler</span> <span class="o">=</span> <span class="n">Checkpoint</span><span class="p">(</span>
    <span class="n">to_save</span><span class="p">,</span>
    <span class="n">TrainsSaver</span><span class="p">(),</span>
    <span class="n">n_saved</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">score_function</span><span class="o">=</span><span class="k">lambda</span> <span class="n">e</span><span class="p">:</span> <span class="mi">123</span><span class="p">,</span>
    <span class="n">score_name</span><span class="o">=</span><span class="s2">&quot;acc&quot;</span><span class="p">,</span>
    <span class="n">filename_prefix</span><span class="o">=</span><span class="s2">&quot;best&quot;</span><span class="p">,</span>
    <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">validation_evaluator</span><span class="o">.</span><span class="n">add_event_handler</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">EVENT_COMPLETED</span><span class="p">,</span> <span class="n">handler</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.trains_logger.TrainsSaver.get_local_copy">
<span class="sig-name descname"><span class="pre">get_local_copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">filename</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/trains_logger.html#TrainsSaver.get_local_copy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.trains_logger.TrainsSaver.get_local_copy" title="Permalink to this definition">#</a></dt>
<dd><p>Get artifact local copy.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>In distributed configuration this method should be called on rank 0 process.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>filename</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) ‚Äì artifact name.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a local path to a downloaded copy of the artifact</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.14)"><em>Optional</em></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)">str</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.trains_logger.TrainsSaver.remove">
<span class="sig-name descname"><span class="pre">remove</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">filename</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/trains_logger.html#TrainsSaver.remove"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.trains_logger.TrainsSaver.remove" title="Permalink to this definition">#</a></dt>
<dd><p>Method to remove saved checkpoint.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>filename</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) ‚Äì filename associated with checkpoint.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.trains_logger.WeightsHistHandler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.trains_logger.</span></span><span class="sig-name descname"><span class="pre">WeightsHistHandler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tag</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/trains_logger.html#WeightsHistHandler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.trains_logger.WeightsHistHandler" title="Permalink to this definition">#</a></dt>
<dd><p>Helper handler to log model‚Äôs weights as histograms.</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.trains_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>

<span class="n">trains_logger</span> <span class="o">=</span> <span class="n">TrainsLogger</span><span class="p">(</span>
    <span class="n">project_name</span><span class="o">=</span><span class="s2">&quot;pytorch-ignite-integration&quot;</span><span class="p">,</span>
    <span class="n">task_name</span><span class="o">=</span><span class="s2">&quot;cnn-mnist&quot;</span>
<span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log model&#39;s weights norm after each iteration</span>
<span class="n">trains_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">,</span>
    <span class="n">log_handler</span><span class="o">=</span><span class="n">WeightsHistHandler</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.9)"><em>torch.nn.Module</em></a>) ‚Äì model to log weights</p></li>
<li><p><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) ‚Äì common title for all produced plots. For example, ‚Äògenerator‚Äô</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.trains_logger.WeightsScalarHandler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.trains_logger.</span></span><span class="sig-name descname"><span class="pre">WeightsScalarHandler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction=&lt;function</span> <span class="pre">norm&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tag=None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/trains_logger.html#WeightsScalarHandler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.trains_logger.WeightsScalarHandler" title="Permalink to this definition">#</a></dt>
<dd><p>Helper handler to log model‚Äôs weights as scalars.
Handler iterates over named parameters of the model, applies reduction function to each parameter
produce a scalar and then logs the scalar.</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.trains_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>

<span class="n">trains_logger</span> <span class="o">=</span> <span class="n">TrainsLogger</span><span class="p">(</span>
    <span class="n">project_name</span><span class="o">=</span><span class="s2">&quot;pytorch-ignite-integration&quot;</span><span class="p">,</span>
    <span class="n">task_name</span><span class="o">=</span><span class="s2">&quot;cnn-mnist&quot;</span>
<span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log model&#39;s weights norm after each iteration</span>
<span class="n">trains_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">,</span>
    <span class="n">log_handler</span><span class="o">=</span><span class="n">WeightsScalarHandler</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.9)"><em>torch.nn.Module</em></a>) ‚Äì model to log weights</p></li>
<li><p><strong>reduction</strong> (<em>callable</em>) ‚Äì function to reduce parameters into scalar</p></li>
<li><p><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) ‚Äì common title for all produced plots. For example, ‚Äúgenerator‚Äù</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ignite.contrib.handlers.trains_logger.global_step_from_engine">
<span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.trains_logger.</span></span><span class="sig-name descname"><span class="pre">global_step_from_engine</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">engine</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_event_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/handlers.html#global_step_from_engine"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.trains_logger.global_step_from_engine" title="Permalink to this definition">#</a></dt>
<dd><p>Helper method to setup <cite>global_step_transform</cite> function using another engine.
This can be helpful for logging trainer epoch/iteration while output handler is attached to an evaluator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.engine.Engine" title="ignite.engine.engine.Engine"><em>Engine</em></a>) ‚Äì engine which state is used to provide the global step</p></li>
<li><p><strong>custom_event_name</strong> (<em>optional</em>) ‚Äì registered event name. Optional argument, event name to use.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>global step</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Callable" title="(in Python v3.14)"><em>Callable</em></a></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="more-on-parameter-scheduling">
<h2>More on parameter scheduling<a class="headerlink" href="#more-on-parameter-scheduling" title="Permalink to this heading">#</a></h2>
<p>In this section there are visual examples of various parameter schedulings that can be achieved.</p>
<section id="example-with-ignite-contrib-handlers-cosineannealingscheduler">
<h3>Example with <code class="xref py py-class docutils literal notranslate"><span class="pre">ignite.contrib.handlers.CosineAnnealingScheduler</span></code><a class="headerlink" href="#example-with-ignite-contrib-handlers-cosineannealingscheduler" title="Permalink to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pylab</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers</span><span class="w"> </span><span class="kn">import</span> <span class="n">CosineAnnealingScheduler</span>

<span class="n">lr_values_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">CosineAnnealingScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">75</span><span class="p">,</span> <span class="n">param_name</span><span class="o">=</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span>
                                                            <span class="n">start_value</span><span class="o">=</span><span class="mf">1e-1</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">2e-2</span><span class="p">,</span> <span class="n">cycle_size</span><span class="o">=</span><span class="mi">20</span><span class="p">))</span>

<span class="n">lr_values_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">CosineAnnealingScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">75</span><span class="p">,</span> <span class="n">param_name</span><span class="o">=</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span>
                                                                <span class="n">start_value</span><span class="o">=</span><span class="mf">1e-1</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">2e-2</span><span class="p">,</span> <span class="n">cycle_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">cycle_mult</span><span class="o">=</span><span class="mf">1.3</span><span class="p">))</span>

<span class="n">lr_values_3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">CosineAnnealingScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">75</span><span class="p">,</span> <span class="n">param_name</span><span class="o">=</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span>
                                                                <span class="n">start_value</span><span class="o">=</span><span class="mf">1e-1</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">2e-2</span><span class="p">,</span>
                                                                <span class="n">cycle_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">start_value_mult</span><span class="o">=</span><span class="mf">0.7</span><span class="p">))</span>

<span class="n">lr_values_4</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">CosineAnnealingScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">75</span><span class="p">,</span> <span class="n">param_name</span><span class="o">=</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span>
                                                                <span class="n">start_value</span><span class="o">=</span><span class="mf">1e-1</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">2e-2</span><span class="p">,</span>
                                                                <span class="n">cycle_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">end_value_mult</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))</span>


<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">141</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Cosine annealing&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.12</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">142</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Cosine annealing with cycle_mult=1.3&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.12</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">143</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Cosine annealing with start_value_mult=0.7&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_3</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_3</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.12</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">144</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Cosine annealing with end_value_mult=0.1&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_4</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_4</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.12</span><span class="p">])</span>
</pre></div>
</div>
<img alt="../_images/cosine_annealing_example.png" src="../_images/cosine_annealing_example.png" />
</section>
<section id="example-with-ignite-contrib-handlers-linearcyclicalscheduler">
<h3>Example with <code class="xref py py-class docutils literal notranslate"><span class="pre">ignite.contrib.handlers.LinearCyclicalScheduler</span></code><a class="headerlink" href="#example-with-ignite-contrib-handlers-linearcyclicalscheduler" title="Permalink to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pylab</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers</span><span class="w"> </span><span class="kn">import</span> <span class="n">LinearCyclicalScheduler</span>

<span class="n">lr_values_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">LinearCyclicalScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">75</span><span class="p">,</span> <span class="n">param_name</span><span class="o">=</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span>
                                                                <span class="n">start_value</span><span class="o">=</span><span class="mf">1e-1</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">2e-2</span><span class="p">,</span> <span class="n">cycle_size</span><span class="o">=</span><span class="mi">20</span><span class="p">))</span>

<span class="n">lr_values_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">LinearCyclicalScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">75</span><span class="p">,</span> <span class="n">param_name</span><span class="o">=</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span>
                                                                <span class="n">start_value</span><span class="o">=</span><span class="mf">1e-1</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">2e-2</span><span class="p">,</span> <span class="n">cycle_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">cycle_mult</span><span class="o">=</span><span class="mf">1.3</span><span class="p">))</span>

<span class="n">lr_values_3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">LinearCyclicalScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">75</span><span class="p">,</span> <span class="n">param_name</span><span class="o">=</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span>
                                                                <span class="n">start_value</span><span class="o">=</span><span class="mf">1e-1</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">2e-2</span><span class="p">,</span>
                                                                <span class="n">cycle_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">start_value_mult</span><span class="o">=</span><span class="mf">0.7</span><span class="p">))</span>

<span class="n">lr_values_4</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">LinearCyclicalScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">75</span><span class="p">,</span> <span class="n">param_name</span><span class="o">=</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span>
                                                                <span class="n">start_value</span><span class="o">=</span><span class="mf">1e-1</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">2e-2</span><span class="p">,</span>
                                                                <span class="n">cycle_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">end_value_mult</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))</span>


<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">141</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Linear cyclical scheduler&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.12</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">142</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Linear cyclical scheduler with cycle_mult=1.3&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.12</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">143</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Linear cyclical scheduler with start_value_mult=0.7&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_3</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_3</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.12</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">144</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Linear cyclical scheduler with end_value_mult=0.1&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_4</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_4</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.12</span><span class="p">])</span>
</pre></div>
</div>
<img alt="../_images/linear_cyclical_example.png" src="../_images/linear_cyclical_example.png" />
</section>
<section id="example-with-ignite-contrib-handlers-concatscheduler">
<h3>Example with <code class="xref py py-class docutils literal notranslate"><span class="pre">ignite.contrib.handlers.ConcatScheduler</span></code><a class="headerlink" href="#example-with-ignite-contrib-handlers-concatscheduler" title="Permalink to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pylab</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers</span><span class="w"> </span><span class="kn">import</span> <span class="n">LinearCyclicalScheduler</span><span class="p">,</span> <span class="n">CosineAnnealingScheduler</span><span class="p">,</span> <span class="n">ConcatScheduler</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="n">t1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">([</span><span class="n">t1</span><span class="p">],</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>


<span class="n">scheduler_1</span> <span class="o">=</span> <span class="n">LinearCyclicalScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="n">start_value</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">cycle_size</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">scheduler_2</span> <span class="o">=</span> <span class="n">CosineAnnealingScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="n">start_value</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">cycle_size</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="n">durations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">15</span><span class="p">,</span> <span class="p">]</span>

<span class="n">lr_values_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">ConcatScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">schedulers</span><span class="o">=</span><span class="p">[</span><span class="n">scheduler_1</span><span class="p">,</span> <span class="n">scheduler_2</span><span class="p">],</span> <span class="n">durations</span><span class="o">=</span><span class="n">durations</span><span class="p">))</span>


<span class="n">t1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">([</span><span class="n">t1</span><span class="p">],</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

<span class="n">scheduler_1</span> <span class="o">=</span> <span class="n">LinearCyclicalScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="n">start_value</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">cycle_size</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">scheduler_2</span> <span class="o">=</span> <span class="n">CosineAnnealingScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s2">&quot;momentum&quot;</span><span class="p">,</span> <span class="n">start_value</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">cycle_size</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="n">durations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">15</span><span class="p">,</span> <span class="p">]</span>

<span class="n">lr_values_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">ConcatScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">schedulers</span><span class="o">=</span><span class="p">[</span><span class="n">scheduler_1</span><span class="p">,</span> <span class="n">scheduler_2</span><span class="p">],</span> <span class="n">durations</span><span class="o">=</span><span class="n">durations</span><span class="p">,</span>
                                                        <span class="n">param_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="s2">&quot;momentum&quot;</span><span class="p">]))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">131</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Concat scheduler of linear + cosine annealing&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">132</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Concat scheduler of linear LR scheduler</span><span class="se">\n</span><span class="s2"> and cosine annealing on momentum&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">133</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Concat scheduler of linear LR scheduler</span><span class="se">\n</span><span class="s2"> and cosine annealing on momentum&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_2</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;momentum&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
<img alt="../_images/concat_example.png" src="../_images/concat_example.png" />
<section id="piecewise-linear-scheduler">
<h4>Piecewise linear scheduler<a class="headerlink" href="#piecewise-linear-scheduler" title="Permalink to this heading">#</a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pylab</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers</span><span class="w"> </span><span class="kn">import</span> <span class="n">LinearCyclicalScheduler</span><span class="p">,</span> <span class="n">ConcatScheduler</span>

<span class="n">scheduler_1</span> <span class="o">=</span> <span class="n">LinearCyclicalScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="n">start_value</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">cycle_size</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="n">scheduler_2</span> <span class="o">=</span> <span class="n">LinearCyclicalScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="n">start_value</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">cycle_size</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
<span class="n">durations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">25</span><span class="p">,</span> <span class="p">]</span>

<span class="n">lr_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">ConcatScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">schedulers</span><span class="o">=</span><span class="p">[</span><span class="n">scheduler_1</span><span class="p">,</span> <span class="n">scheduler_2</span><span class="p">],</span> <span class="n">durations</span><span class="o">=</span><span class="n">durations</span><span class="p">))</span>


<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Piecewise linear scheduler&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
<img alt="../_images/piecewise_linear.png" src="../_images/piecewise_linear.png" />
</section>
</section>
<section id="example-with-ignite-contrib-handlers-lrscheduler">
<h3>Example with <code class="xref py py-class docutils literal notranslate"><span class="pre">ignite.contrib.handlers.LRScheduler</span></code><a class="headerlink" href="#example-with-ignite-contrib-handlers-lrscheduler" title="Permalink to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pylab</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers</span><span class="w"> </span><span class="kn">import</span> <span class="n">LRScheduler</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim.lr_scheduler</span><span class="w"> </span><span class="kn">import</span> <span class="n">ExponentialLR</span><span class="p">,</span> <span class="n">StepLR</span><span class="p">,</span> <span class="n">CosineAnnealingLR</span>

<span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">([</span><span class="n">tensor</span><span class="p">],</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

<span class="n">lr_scheduler_1</span> <span class="o">=</span> <span class="n">StepLR</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.77</span><span class="p">)</span>
<span class="n">lr_scheduler_2</span> <span class="o">=</span> <span class="n">ExponentialLR</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.98</span><span class="p">)</span>
<span class="n">lr_scheduler_3</span> <span class="o">=</span> <span class="n">CosineAnnealingLR</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">T_max</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">eta_min</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

<span class="n">lr_values_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">LRScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">lr_scheduler</span><span class="o">=</span><span class="n">lr_scheduler_1</span><span class="p">))</span>
<span class="n">lr_values_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">LRScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">lr_scheduler</span><span class="o">=</span><span class="n">lr_scheduler_2</span><span class="p">))</span>
<span class="n">lr_values_3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">LRScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">lr_scheduler</span><span class="o">=</span><span class="n">lr_scheduler_3</span><span class="p">))</span>


<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">131</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Torch LR scheduler wrapping StepLR&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">132</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Torch LR scheduler wrapping ExponentialLR&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">133</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Torch LR scheduler wrapping CosineAnnealingLR&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_3</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_3</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
<img alt="../_images/lr_scheduler.png" src="../_images/lr_scheduler.png" />
<section id="concatenate-with-torch-schedulers">
<h4>Concatenate with torch schedulers<a class="headerlink" href="#concatenate-with-torch-schedulers" title="Permalink to this heading">#</a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pylab</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers</span><span class="w"> </span><span class="kn">import</span> <span class="n">LRScheduler</span><span class="p">,</span> <span class="n">ConcatScheduler</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim.lr_scheduler</span><span class="w"> </span><span class="kn">import</span> <span class="n">ExponentialLR</span><span class="p">,</span> <span class="n">StepLR</span>

<span class="n">t1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">([</span><span class="n">t1</span><span class="p">],</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

<span class="n">scheduler_1</span> <span class="o">=</span> <span class="n">LinearCyclicalScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="n">start_value</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">cycle_size</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">ExponentialLR</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">scheduler_2</span> <span class="o">=</span> <span class="n">LRScheduler</span><span class="p">(</span><span class="n">lr_scheduler</span><span class="o">=</span><span class="n">lr_scheduler</span><span class="p">)</span>
<span class="n">durations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">15</span><span class="p">,</span> <span class="p">]</span>
<span class="n">lr_values_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">ConcatScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">schedulers</span><span class="o">=</span><span class="p">[</span><span class="n">scheduler_1</span><span class="p">,</span> <span class="n">scheduler_2</span><span class="p">],</span> <span class="n">durations</span><span class="o">=</span><span class="n">durations</span><span class="p">))</span>


<span class="n">scheduler_1</span> <span class="o">=</span> <span class="n">LinearCyclicalScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="n">start_value</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">cycle_size</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">StepLR</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">scheduler_2</span> <span class="o">=</span> <span class="n">LRScheduler</span><span class="p">(</span><span class="n">lr_scheduler</span><span class="o">=</span><span class="n">lr_scheduler</span><span class="p">)</span>
<span class="n">durations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">15</span><span class="p">,</span> <span class="p">]</span>
<span class="n">lr_values_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">ConcatScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">75</span><span class="p">,</span> <span class="n">schedulers</span><span class="o">=</span><span class="p">[</span><span class="n">scheduler_1</span><span class="p">,</span> <span class="n">scheduler_2</span><span class="p">],</span> <span class="n">durations</span><span class="o">=</span><span class="n">durations</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Concat scheduler of linear + ExponentialLR&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Concat scheduler of linear + StepLR&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
<img alt="../_images/concat_linear_exp_step_lr.png" src="../_images/concat_linear_exp_step_lr.png" />
</section>
</section>
</section>
</section>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../about.html" class="btn btn-neutral float-right" title="About us" accesskey="n" rel="next">Next
          <img src="../_static/images/chevron-right-orange.svg" alt="right arrow" class="next-page">
        </a>
      
      
        <a href="metrics.html" class="btn btn-neutral" title="ignite.contrib.metrics" accesskey="p" rel="prev">
          <img src="../_static/images/chevron-right-orange.svg" alt="left arrow" class="previous-page"> Previous
        </a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <table>
      <tr>
        <td>
            <p>
                &copy; Copyright 2025, PyTorch-Ignite Contributors.
              Last updated on 09/16/2020, 1:26:37‚ÄØPM.
            </p>
            
              <div>
                Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
              </div>
          
        </td>
        <td>
            
              <div>
                <a href="https://www.netlify.com" target="_blank" rel="noopener noreferrer">
                  <img
                  src="_static/img/netlify-light.svg"
                  alt="Deploys by Netlify"
                  width=114
                  height=51 />
                </a>
              </div>
            
        </td>
      </tr>
    </table>
  </div> 

</footer>
          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">ignite.contrib.handlers</a><ul>
<li><a class="reference internal" href="#module-ignite.contrib.handlers.custom_events">custom_events</a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.custom_events.CustomPeriodicEvent"><code class="docutils literal notranslate"><span class="pre">CustomPeriodicEvent</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#module-ignite.contrib.handlers.param_scheduler">param_scheduler</a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ConcatScheduler"><code class="docutils literal notranslate"><span class="pre">ConcatScheduler</span></code></a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ConcatScheduler.get_param"><code class="docutils literal notranslate"><span class="pre">ConcatScheduler.get_param()</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ConcatScheduler.load_state_dict"><code class="docutils literal notranslate"><span class="pre">ConcatScheduler.load_state_dict()</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ConcatScheduler.simulate_values"><code class="docutils literal notranslate"><span class="pre">ConcatScheduler.simulate_values()</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ConcatScheduler.state_dict"><code class="docutils literal notranslate"><span class="pre">ConcatScheduler.state_dict()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.CosineAnnealingScheduler"><code class="docutils literal notranslate"><span class="pre">CosineAnnealingScheduler</span></code></a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.CosineAnnealingScheduler.get_param"><code class="docutils literal notranslate"><span class="pre">CosineAnnealingScheduler.get_param()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.CyclicalScheduler"><code class="docutils literal notranslate"><span class="pre">CyclicalScheduler</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.LRScheduler"><code class="docutils literal notranslate"><span class="pre">LRScheduler</span></code></a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.LRScheduler.get_param"><code class="docutils literal notranslate"><span class="pre">LRScheduler.get_param()</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.LRScheduler.simulate_values"><code class="docutils literal notranslate"><span class="pre">LRScheduler.simulate_values()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.LinearCyclicalScheduler"><code class="docutils literal notranslate"><span class="pre">LinearCyclicalScheduler</span></code></a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.LinearCyclicalScheduler.get_param"><code class="docutils literal notranslate"><span class="pre">LinearCyclicalScheduler.get_param()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ParamGroupScheduler"><code class="docutils literal notranslate"><span class="pre">ParamGroupScheduler</span></code></a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ParamGroupScheduler.load_state_dict"><code class="docutils literal notranslate"><span class="pre">ParamGroupScheduler.load_state_dict()</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ParamGroupScheduler.simulate_values"><code class="docutils literal notranslate"><span class="pre">ParamGroupScheduler.simulate_values()</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ParamGroupScheduler.state_dict"><code class="docutils literal notranslate"><span class="pre">ParamGroupScheduler.state_dict()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ParamScheduler"><code class="docutils literal notranslate"><span class="pre">ParamScheduler</span></code></a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ParamScheduler.get_param"><code class="docutils literal notranslate"><span class="pre">ParamScheduler.get_param()</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ParamScheduler.load_state_dict"><code class="docutils literal notranslate"><span class="pre">ParamScheduler.load_state_dict()</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ParamScheduler.plot_values"><code class="docutils literal notranslate"><span class="pre">ParamScheduler.plot_values()</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ParamScheduler.simulate_values"><code class="docutils literal notranslate"><span class="pre">ParamScheduler.simulate_values()</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ParamScheduler.state_dict"><code class="docutils literal notranslate"><span class="pre">ParamScheduler.state_dict()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.PiecewiseLinear"><code class="docutils literal notranslate"><span class="pre">PiecewiseLinear</span></code></a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.PiecewiseLinear.get_param"><code class="docutils literal notranslate"><span class="pre">PiecewiseLinear.get_param()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.create_lr_scheduler_with_warmup"><code class="docutils literal notranslate"><span class="pre">create_lr_scheduler_with_warmup()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#module-ignite.contrib.handlers.lr_finder">lr_finder</a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.lr_finder.FastaiLRFinder"><code class="docutils literal notranslate"><span class="pre">FastaiLRFinder</span></code></a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.lr_finder.FastaiLRFinder.attach"><code class="docutils literal notranslate"><span class="pre">FastaiLRFinder.attach()</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.lr_finder.FastaiLRFinder.get_results"><code class="docutils literal notranslate"><span class="pre">FastaiLRFinder.get_results()</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.lr_finder.FastaiLRFinder.lr_suggestion"><code class="docutils literal notranslate"><span class="pre">FastaiLRFinder.lr_suggestion()</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.lr_finder.FastaiLRFinder.plot"><code class="docutils literal notranslate"><span class="pre">FastaiLRFinder.plot()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#module-ignite.contrib.handlers.time_profilers">time_profilers</a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.time_profilers.BasicTimeProfiler"><code class="docutils literal notranslate"><span class="pre">BasicTimeProfiler</span></code></a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.time_profilers.BasicTimeProfiler.get_results"><code class="docutils literal notranslate"><span class="pre">BasicTimeProfiler.get_results()</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.time_profilers.BasicTimeProfiler.print_results"><code class="docutils literal notranslate"><span class="pre">BasicTimeProfiler.print_results()</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.time_profilers.BasicTimeProfiler.write_results"><code class="docutils literal notranslate"><span class="pre">BasicTimeProfiler.write_results()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#tensorboard-logger">tensorboard_logger</a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.tensorboard_logger.GradsHistHandler"><code class="docutils literal notranslate"><span class="pre">GradsHistHandler</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.tensorboard_logger.GradsScalarHandler"><code class="docutils literal notranslate"><span class="pre">GradsScalarHandler</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.tensorboard_logger.OptimizerParamsHandler"><code class="docutils literal notranslate"><span class="pre">OptimizerParamsHandler</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.tensorboard_logger.OutputHandler"><code class="docutils literal notranslate"><span class="pre">OutputHandler</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.tensorboard_logger.TensorboardLogger"><code class="docutils literal notranslate"><span class="pre">TensorboardLogger</span></code></a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.tensorboard_logger.TensorboardLogger.attach"><code class="docutils literal notranslate"><span class="pre">TensorboardLogger.attach()</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.tensorboard_logger.TensorboardLogger.attach_opt_params_handler"><code class="docutils literal notranslate"><span class="pre">TensorboardLogger.attach_opt_params_handler()</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.tensorboard_logger.TensorboardLogger.attach_output_handler"><code class="docutils literal notranslate"><span class="pre">TensorboardLogger.attach_output_handler()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#ignite.contrib.handlers.tensorboard_logger.WeightsHistHandler"><code class="docutils literal notranslate"><span class="pre">WeightsHistHandler</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.tensorboard_logger.WeightsScalarHandler"><code class="docutils literal notranslate"><span class="pre">WeightsScalarHandler</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.tensorboard_logger.global_step_from_engine"><code class="docutils literal notranslate"><span class="pre">global_step_from_engine()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#visdom-logger">visdom_logger</a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.visdom_logger.GradsScalarHandler"><code class="docutils literal notranslate"><span class="pre">GradsScalarHandler</span></code></a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.visdom_logger.GradsScalarHandler.add_scalar"><code class="docutils literal notranslate"><span class="pre">GradsScalarHandler.add_scalar()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#ignite.contrib.handlers.visdom_logger.OptimizerParamsHandler"><code class="docutils literal notranslate"><span class="pre">OptimizerParamsHandler</span></code></a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.visdom_logger.OptimizerParamsHandler.add_scalar"><code class="docutils literal notranslate"><span class="pre">OptimizerParamsHandler.add_scalar()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#ignite.contrib.handlers.visdom_logger.OutputHandler"><code class="docutils literal notranslate"><span class="pre">OutputHandler</span></code></a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.visdom_logger.OutputHandler.add_scalar"><code class="docutils literal notranslate"><span class="pre">OutputHandler.add_scalar()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#ignite.contrib.handlers.visdom_logger.VisdomLogger"><code class="docutils literal notranslate"><span class="pre">VisdomLogger</span></code></a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.visdom_logger.VisdomLogger.attach"><code class="docutils literal notranslate"><span class="pre">VisdomLogger.attach()</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.visdom_logger.VisdomLogger.attach_opt_params_handler"><code class="docutils literal notranslate"><span class="pre">VisdomLogger.attach_opt_params_handler()</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.visdom_logger.VisdomLogger.attach_output_handler"><code class="docutils literal notranslate"><span class="pre">VisdomLogger.attach_output_handler()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#ignite.contrib.handlers.visdom_logger.WeightsScalarHandler"><code class="docutils literal notranslate"><span class="pre">WeightsScalarHandler</span></code></a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.visdom_logger.WeightsScalarHandler.add_scalar"><code class="docutils literal notranslate"><span class="pre">WeightsScalarHandler.add_scalar()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#ignite.contrib.handlers.visdom_logger.global_step_from_engine"><code class="docutils literal notranslate"><span class="pre">global_step_from_engine()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#neptune-logger">neptune_logger</a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.neptune_logger.GradsScalarHandler"><code class="docutils literal notranslate"><span class="pre">GradsScalarHandler</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.neptune_logger.NeptuneLogger"><code class="docutils literal notranslate"><span class="pre">NeptuneLogger</span></code></a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.neptune_logger.NeptuneLogger.attach"><code class="docutils literal notranslate"><span class="pre">NeptuneLogger.attach()</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.neptune_logger.NeptuneLogger.attach_opt_params_handler"><code class="docutils literal notranslate"><span class="pre">NeptuneLogger.attach_opt_params_handler()</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.neptune_logger.NeptuneLogger.attach_output_handler"><code class="docutils literal notranslate"><span class="pre">NeptuneLogger.attach_output_handler()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#ignite.contrib.handlers.neptune_logger.NeptuneSaver"><code class="docutils literal notranslate"><span class="pre">NeptuneSaver</span></code></a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.neptune_logger.NeptuneSaver.remove"><code class="docutils literal notranslate"><span class="pre">NeptuneSaver.remove()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#ignite.contrib.handlers.neptune_logger.OptimizerParamsHandler"><code class="docutils literal notranslate"><span class="pre">OptimizerParamsHandler</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.neptune_logger.OutputHandler"><code class="docutils literal notranslate"><span class="pre">OutputHandler</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.neptune_logger.WeightsScalarHandler"><code class="docutils literal notranslate"><span class="pre">WeightsScalarHandler</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.neptune_logger.global_step_from_engine"><code class="docutils literal notranslate"><span class="pre">global_step_from_engine()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#module-ignite.contrib.handlers.mlflow_logger">mlflow_logger</a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.mlflow_logger.MLflowLogger"><code class="docutils literal notranslate"><span class="pre">MLflowLogger</span></code></a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.mlflow_logger.MLflowLogger.attach"><code class="docutils literal notranslate"><span class="pre">MLflowLogger.attach()</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.mlflow_logger.MLflowLogger.attach_opt_params_handler"><code class="docutils literal notranslate"><span class="pre">MLflowLogger.attach_opt_params_handler()</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.mlflow_logger.MLflowLogger.attach_output_handler"><code class="docutils literal notranslate"><span class="pre">MLflowLogger.attach_output_handler()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#ignite.contrib.handlers.mlflow_logger.OptimizerParamsHandler"><code class="docutils literal notranslate"><span class="pre">OptimizerParamsHandler</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.mlflow_logger.OutputHandler"><code class="docutils literal notranslate"><span class="pre">OutputHandler</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.mlflow_logger.global_step_from_engine"><code class="docutils literal notranslate"><span class="pre">global_step_from_engine()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#tqdm-logger">tqdm_logger</a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.tqdm_logger.ProgressBar"><code class="docutils literal notranslate"><span class="pre">ProgressBar</span></code></a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.tqdm_logger.ProgressBar.attach"><code class="docutils literal notranslate"><span class="pre">ProgressBar.attach()</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.tqdm_logger.ProgressBar.attach_opt_params_handler"><code class="docutils literal notranslate"><span class="pre">ProgressBar.attach_opt_params_handler()</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.tqdm_logger.ProgressBar.log_message"><code class="docutils literal notranslate"><span class="pre">ProgressBar.log_message()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#module-ignite.contrib.handlers.polyaxon_logger">polyaxon_logger</a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.polyaxon_logger.OptimizerParamsHandler"><code class="docutils literal notranslate"><span class="pre">OptimizerParamsHandler</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.polyaxon_logger.OutputHandler"><code class="docutils literal notranslate"><span class="pre">OutputHandler</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.polyaxon_logger.PolyaxonLogger"><code class="docutils literal notranslate"><span class="pre">PolyaxonLogger</span></code></a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.polyaxon_logger.PolyaxonLogger.attach"><code class="docutils literal notranslate"><span class="pre">PolyaxonLogger.attach()</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.polyaxon_logger.PolyaxonLogger.attach_opt_params_handler"><code class="docutils literal notranslate"><span class="pre">PolyaxonLogger.attach_opt_params_handler()</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.polyaxon_logger.PolyaxonLogger.attach_output_handler"><code class="docutils literal notranslate"><span class="pre">PolyaxonLogger.attach_output_handler()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#ignite.contrib.handlers.polyaxon_logger.global_step_from_engine"><code class="docutils literal notranslate"><span class="pre">global_step_from_engine()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#wandb-logger">wandb_logger</a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.wandb_logger.OptimizerParamsHandler"><code class="docutils literal notranslate"><span class="pre">OptimizerParamsHandler</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.wandb_logger.OutputHandler"><code class="docutils literal notranslate"><span class="pre">OutputHandler</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.wandb_logger.WandBLogger"><code class="docutils literal notranslate"><span class="pre">WandBLogger</span></code></a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.wandb_logger.WandBLogger.attach"><code class="docutils literal notranslate"><span class="pre">WandBLogger.attach()</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.wandb_logger.WandBLogger.attach_opt_params_handler"><code class="docutils literal notranslate"><span class="pre">WandBLogger.attach_opt_params_handler()</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.wandb_logger.WandBLogger.attach_output_handler"><code class="docutils literal notranslate"><span class="pre">WandBLogger.attach_output_handler()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#ignite.contrib.handlers.wandb_logger.global_step_from_engine"><code class="docutils literal notranslate"><span class="pre">global_step_from_engine()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#trains-logger">trains_logger</a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.trains_logger.GradsHistHandler"><code class="docutils literal notranslate"><span class="pre">GradsHistHandler</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.trains_logger.GradsScalarHandler"><code class="docutils literal notranslate"><span class="pre">GradsScalarHandler</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.trains_logger.OptimizerParamsHandler"><code class="docutils literal notranslate"><span class="pre">OptimizerParamsHandler</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.trains_logger.OutputHandler"><code class="docutils literal notranslate"><span class="pre">OutputHandler</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.trains_logger.TrainsLogger"><code class="docutils literal notranslate"><span class="pre">TrainsLogger</span></code></a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.trains_logger.TrainsLogger.attach"><code class="docutils literal notranslate"><span class="pre">TrainsLogger.attach()</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.trains_logger.TrainsLogger.attach_opt_params_handler"><code class="docutils literal notranslate"><span class="pre">TrainsLogger.attach_opt_params_handler()</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.trains_logger.TrainsLogger.attach_output_handler"><code class="docutils literal notranslate"><span class="pre">TrainsLogger.attach_output_handler()</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.trains_logger.TrainsLogger.bypass_mode"><code class="docutils literal notranslate"><span class="pre">TrainsLogger.bypass_mode()</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.trains_logger.TrainsLogger.set_bypass_mode"><code class="docutils literal notranslate"><span class="pre">TrainsLogger.set_bypass_mode()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#ignite.contrib.handlers.trains_logger.TrainsSaver"><code class="docutils literal notranslate"><span class="pre">TrainsSaver</span></code></a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.trains_logger.TrainsSaver.get_local_copy"><code class="docutils literal notranslate"><span class="pre">TrainsSaver.get_local_copy()</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.trains_logger.TrainsSaver.remove"><code class="docutils literal notranslate"><span class="pre">TrainsSaver.remove()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#ignite.contrib.handlers.trains_logger.WeightsHistHandler"><code class="docutils literal notranslate"><span class="pre">WeightsHistHandler</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.trains_logger.WeightsScalarHandler"><code class="docutils literal notranslate"><span class="pre">WeightsScalarHandler</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.trains_logger.global_step_from_engine"><code class="docutils literal notranslate"><span class="pre">global_step_from_engine()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#more-on-parameter-scheduling">More on parameter scheduling</a><ul>
<li><a class="reference internal" href="#example-with-ignite-contrib-handlers-cosineannealingscheduler">Example with <code class="xref py py-class docutils literal notranslate"><span class="pre">ignite.contrib.handlers.CosineAnnealingScheduler</span></code></a></li>
<li><a class="reference internal" href="#example-with-ignite-contrib-handlers-linearcyclicalscheduler">Example with <code class="xref py py-class docutils literal notranslate"><span class="pre">ignite.contrib.handlers.LinearCyclicalScheduler</span></code></a></li>
<li><a class="reference internal" href="#example-with-ignite-contrib-handlers-concatscheduler">Example with <code class="xref py py-class docutils literal notranslate"><span class="pre">ignite.contrib.handlers.ConcatScheduler</span></code></a><ul>
<li><a class="reference internal" href="#piecewise-linear-scheduler">Piecewise linear scheduler</a></li>
</ul>
</li>
<li><a class="reference internal" href="#example-with-ignite-contrib-handlers-lrscheduler">Example with <code class="xref py py-class docutils literal notranslate"><span class="pre">ignite.contrib.handlers.LRScheduler</span></code></a><ul>
<li><a class="reference internal" href="#concatenate-with-torch-schedulers">Concatenate with torch schedulers</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
         <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
         <script src="../_static/jquery.js"></script>
         <script src="../_static/underscore.js"></script>
         <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="../_static/doctools.js"></script>
         <script src="../_static/sphinx_highlight.js"></script>
         <script src="../_static/clipboard.min.js"></script>
         <script src="../_static/copybutton.js"></script>
         <script>let toggleHintShow = 'Show default setup';</script>
         <script>let toggleHintHide = 'Hide default setup';</script>
         <script>let toggleOpenOnPrint = 'true';</script>
         <script src="../_static/togglebutton.js"></script>
         <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
         <script src="../_static/design-tabs.js"></script>
     

  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <!-- commented out for Ignite -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <!-- <div class="container">
      <div class="row">
        <div class="text-center col-md-4">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/ignite/index.html">View Docs</a>
        </div>

        <div class="text-center col-md-4">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="">View Tutorials</a>
        </div>

        <div class="text-center col-md-4">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="">View Resources</a>
        </div>
      </div>
    </div> -->
  </div>

  <!-- <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch-ignite.ai" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch-ignite.ai">PyTorch</a></li>
            <li><a href="">Get Started</a></li>
            <li><a href="">Features</a></li>
            <li><a href="">Ecosystem</a></li>
            <li><a href="">Blog</a></li>
            <li><a href="">Resources</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="">Support</a></li>
            <li><a href="">Tutorials</a></li>
            <li><a href="https://pytorch.org/ignite/index.html">Docs</a></li>
            <li><a href="" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/ignite/issues" target="_blank">Github Issues</a></li>
            <li><a href="" target="_blank">Slack</a></li>
            <li><a href="https://github.com/pytorch/ignite/blob/master/CONTRIBUTING.md" target="_blank">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Follow Us</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>    <!~~ real people should not fill this in and expect good things - do not remove this or risk form bot signups ~~>

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="" target="_blank" class="facebook"></a>
            <a href="" target="_blank" class="twitter"></a>
          </div>
        </div>
      </div>
    </div>
  </footer> -->


  <!-- end of commented out for Ignite -->

  <!-- <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook‚Äôs Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../_static/images/pytorch-x.svg">
  </div>
</div> -->

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->
  <!--
  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch-ignite.ai" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="#">Get Started</a>
          </li>

          <li>
            <a href="#">Features</a>
          </li>

          <li>
            <a href="#">Ecosystem</a>
          </li>

          <li>
            <a href="">Blog</a>
          </li>

          <li>
            <a href="">Tutorials</a>
          </li>

          <li>
            <a href="https://pytorch.org/ignite/index.html">Docs</a>
          </li>

          <li>
            <a href="">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/ignite">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>
  -->
  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    var collapsedSections = []
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
  <script src="https://cdn.jsdelivr.net/npm/@docsearch/js@3"></script>
  <script type="text/javascript">
  let VERSION
  if ('v0.4.2'.startsWith('v')) {
    VERSION = 'v0.4.2'
  } else {
    VERSION = 'master'
  }
  docsearch({
    container: '#docsearch',
    appId: '7EWYE1JCT3',
    apiKey: '841e93e60c16975ba1bd8c7c716eed82',
    indexName: 'pytorch-ignite',
    placeholder: 'Search PyTorch-Ignite docs',
    searchParameters: {
      facetFilters: [`version:${VERSION}`, 'tags:API-reference'],
    }
  });
  </script>
</body>
</html>