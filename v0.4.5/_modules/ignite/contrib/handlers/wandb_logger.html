



<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="author" content="PyTorch-Ignite Contributors">
  <meta name="creator" content="PyTorch-Ignite Contributors">
  <meta name="publisher" content="PyTorch-Ignite Contributors">
  <meta name="generator" content="Sphinx 5.3.0">
  <meta name="description" content="High-level library to help with training and evaluating neural networks in PyTorch flexibly and transparently.">
  <meta name="keywords" content="pytorch, pytorch ignite, ignite, engine, events, handlers, metrics">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="theme-color" content="#ee4c2c">

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@pytorch_ignite">
  <meta name="twitter:creator" content="@pytorch_ignite">
  <meta name="twitter:description" content="High-level library to help with training and evaluating neural networks in PyTorch flexibly and transparently.">
  <meta name="twitter:title" content="ignite.contrib.handlers.wandb_logger &mdash; PyTorch-Ignite v0.4.5 Documentation">
  <meta name="twitter:image" content="https://raw.githubusercontent.com/pytorch/ignite/master/assets/logo/ignite_logo.png">
  <meta name="twitter:image:alt" content="PyTorch-Ignite logo">

  <meta property="og:title" content="ignite.contrib.handlers.wandb_logger &mdash; PyTorch-Ignite v0.4.5 Documentation">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://pytorch.org/ignite/">
  <meta property="og:site_name" content="PyTorch-Ignite">
  <meta property="og:image" content="https://raw.githubusercontent.com/pytorch/ignite/master/assets/logo/ignite_logo.png">
  <meta property="og:image:alt" content="PyTorch-Ignite logo">
  <meta property="og:description" content="High-level library to help with training and evaluating neural networks in PyTorch flexibly and transparently.">

  <link rel="preconnect" href="https://BH4D9OD16A-dsn.algolia.net" crossorigin />

  
  <title>ignite.contrib.handlers.wandb_logger &mdash; PyTorch-Ignite v0.4.5 Documentation</title>
  

  
  
    <link rel="shortcut icon" type="image/svg+xml" href="../../../../_static/ignite_logomark.svg"/>
  
  
  
    <link rel="canonical" href="https://pytorch.org/ignite/_modules/ignite/contrib/handlers/wandb_logger.html"/>
  

  

  
  
    

  

  <link rel="preload" href="../../../../_static/css/theme.css" as="style" />
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" /> -->
  <link rel="preload" href="../../../../_static/pygments.css" as="style" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="preload" href="../../../../_static/css/theme.css" as="style" />
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="preload" href="../../../../_static/copybutton.css" as="style" />
  <link rel="stylesheet" href="../../../../_static/copybutton.css" type="text/css" />
  <link rel="preload" href="../../../../_static/togglebutton.css" as="style" />
  <link rel="stylesheet" href="../../../../_static/togglebutton.css" type="text/css" />
  <link rel="preload" href="../../../../_static/banner.css" as="style" />
  <link rel="stylesheet" href="../../../../_static/banner.css" type="text/css" />
  <link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.css" as="style" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.css" type="text/css" />
  <link rel="preload" href="../../../../_static/katex-math.css" as="style" />
  <link rel="stylesheet" href="../../../../_static/katex-math.css" type="text/css" />
  <link rel="preload" href="../../../../_static/sphinx-design.5ea377869091fd0449014c60fc090103.min.css" as="style" />
  <link rel="stylesheet" href="../../../../_static/sphinx-design.5ea377869091fd0449014c60fc090103.min.css" type="text/css" />
    <link rel="preload" href="../../../../_static/css/ignite_theme.css" as="style" />
    <link rel="stylesheet" href="../../../../_static/css/ignite_theme.css" type="text/css" />
    <link rel="preload" href="https://cdn.jsdelivr.net/npm/@docsearch/css@3" as="style" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@docsearch/css@3" type="text/css" />
    <link rel="author" title="About these documents" href="../../../../about.html" />
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 

  <!-- katex links / this needs to be loaded before fonts.html -->

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/katex.min.css" crossorigin="anonymous">
<script async src="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/katex.min.js" crossorigin="anonymous"></script>

<!-- Preload the theme fonts -->

<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/IBMPlexMono/IBMPlexMono-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-5FELLLFHCP"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-5FELLLFHCP');
  </script>
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">

    <a class="header-logo" href="/ignite" aria-label="PyTorch-Ignite"></a>

    <div class="header-container">

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch-ignite.ai/tutorials/beginner/01-getting-started/">Quickstart</a>
          </li>

          <li>
            <a href="https://pytorch-ignite.ai/concepts/">Concepts</a>
          </li>

          <!-- <li>
            <a href="https://pytorch-ignite.ai/tutorials/beginner/01-getting-started/#complete-code">Examples</a>
          </li> -->

          <li>
            <a href="https://pytorch-ignite.ai/how-to-guides/">FAQ</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/ignite" target="_blank" rel="noopener noreferrer">GitHub</a>
          </li>

          <li>
            <a href="https://pytorch-ignite.ai/about/community/">About us</a>
          </li>

          <li>
            <a href="https://pytorch-ignite.ai">‚ä≥ pytorch-ignite.ai</a>
          </li>


        </ul>
      </div>

      <!-- <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a> -->
    </div>

  </div>
</div>


<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <div class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></div>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  v0.4.5
                </div>
              
            

            <div id="docsearch"></div>

            
          </div>

          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../quickstart.html">Quick start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../concepts.html">Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Package Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../engine.html">ignite.engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../handlers.html">ignite.handlers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../metrics.html">ignite.metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributed.html">ignite.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../exceptions.html">ignite.exceptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../utils.html">ignite.utils</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contrib Package Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../contrib/engines.html">ignite.contrib.engines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../contrib/metrics.html">ignite.contrib.metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../contrib/handlers.html">ignite.contrib.handlers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Team</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/ignite/master/about.html">About us</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../governance.html">PyTorch-Ignite governance</a></li>
</ul>

            
          
        </div>
      </div>

      <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
        <span class="fa fa-book"> Other Versions</span>
        v: v0.4.5
        <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
        <dl>
            <dt>Tags</dt>
            <dd><a href="../../../../../v0.3.0/index.html">v0.3.0</a></dd>
            <dd><a href="../../../../../v0.4.0.post1/index.html">v0.4.0.post1</a></dd>
            <dd><a href="../../../../../v0.4.1/index.html">v0.4.1</a></dd>
            <dd><a href="../../../../../v0.4.10/index.html">v0.4.10</a></dd>
            <dd><a href="../../../../../v0.4.11/index.html">v0.4.11</a></dd>
            <dd><a href="../../../../../v0.4.12/index.html">v0.4.12</a></dd>
            <dd><a href="../../../../../v0.4.13/index.html">v0.4.13</a></dd>
            <dd><a href="../../../../../v0.4.2/index.html">v0.4.2</a></dd>
            <dd><a href="../../../../../v0.4.3/index.html">v0.4.3</a></dd>
            <dd><a href="../../../../../v0.4.4.post1/index.html">v0.4.4.post1</a></dd>
            <dd><a href="wandb_logger.html">v0.4.5</a></dd>
            <dd><a href="../../../../../v0.4.6/index.html">v0.4.6</a></dd>
            <dd><a href="../../../../../v0.4.7/index.html">v0.4.7</a></dd>
            <dd><a href="../../../../../v0.4.8/index.html">v0.4.8</a></dd>
            <dd><a href="../../../../../v0.4.9/index.html">v0.4.9</a></dd>
            <dd><a href="../../../../../v0.4rc.0.post1/index.html">v0.4rc.0.post1</a></dd>
            <dd><a href="../../../../../v0.5.0.post2/index.html">v0.5.0.post2</a></dd>
            <dd><a href="../../../../../v0.5.1/index.html">v0.5.1</a></dd>
            <dd><a href="../../../../../v0.5.2/index.html">v0.5.2</a></dd>
            <dd><a href="../../../../../v0.5.3/index.html">v0.5.3</a></dd>
        </dl>
        <dl>
            <dt>Branches</dt>
            <dd><a href="../../../../../master/index.html">master</a></dd>
        </dl>
    </div>
</div>

    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../../../index.html">Module code</a> &gt;</li>
        
      <li>ignite.contrib.handlers.wandb_logger</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for ignite.contrib.handlers.wandb_logger</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;WandB logger and its helper handlers.&quot;&quot;&quot;</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numbers</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Optimizer</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.base_logger</span><span class="w"> </span><span class="kn">import</span> <span class="n">BaseLogger</span><span class="p">,</span> <span class="n">BaseOptimizerParamsHandler</span><span class="p">,</span> <span class="n">BaseOutputHandler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ignite.engine</span><span class="w"> </span><span class="kn">import</span> <span class="n">Engine</span><span class="p">,</span> <span class="n">Events</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ignite.handlers</span><span class="w"> </span><span class="kn">import</span> <span class="n">global_step_from_engine</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;WandBLogger&quot;</span><span class="p">,</span> <span class="s2">&quot;OutputHandler&quot;</span><span class="p">,</span> <span class="s2">&quot;OptimizerParamsHandler&quot;</span><span class="p">,</span> <span class="s2">&quot;global_step_from_engine&quot;</span><span class="p">]</span>


<div class="viewcode-block" id="WandBLogger"><a class="viewcode-back" href="../../../../generated/ignite.contrib.handlers.wandb_logger.html#ignite.contrib.handlers.wandb_logger.WandBLogger">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">WandBLogger</span><span class="p">(</span><span class="n">BaseLogger</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;`Weights &amp; Biases &lt;https://wandb.ai/site&gt;`_ handler to log metrics, model/optimizer parameters, gradients</span>
<span class="sd">    during training and validation. It can also be used to log model checkpoints to the Weights &amp; Biases cloud.</span>

<span class="sd">    .. code-block:: bash</span>

<span class="sd">        pip install wandb</span>

<span class="sd">    This class is also a wrapper for the wandb module. This means that you can call any wandb function using</span>
<span class="sd">    this wrapper. See examples on how to save model parameters and gradients.</span>

<span class="sd">    Args:</span>
<span class="sd">        args: Positional arguments accepted by `wandb.init`.</span>
<span class="sd">        kwargs: Keyword arguments accepted by `wandb.init`.</span>
<span class="sd">            Please see `wandb.init &lt;https://docs.wandb.ai/library/init&gt;`_ for documentation of possible parameters.</span>

<span class="sd">    Examples:</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            from ignite.contrib.handlers.wandb_logger import *</span>

<span class="sd">            # Create a logger. All parameters are optional. See documentation</span>
<span class="sd">            # on wandb.init for details.</span>

<span class="sd">            wandb_logger = WandBLogger(</span>
<span class="sd">                entity=&quot;shared&quot;,</span>
<span class="sd">                project=&quot;pytorch-ignite-integration&quot;,</span>
<span class="sd">                name=&quot;cnn-mnist&quot;,</span>
<span class="sd">                config={&quot;max_epochs&quot;: 10},</span>
<span class="sd">                tags=[&quot;pytorch-ignite&quot;, &quot;minst&quot;]</span>
<span class="sd">            )</span>

<span class="sd">            # Attach the logger to the trainer to log training loss at each iteration</span>
<span class="sd">            wandb_logger.attach_output_handler(</span>
<span class="sd">                trainer,</span>
<span class="sd">                event_name=Events.ITERATION_COMPLETED,</span>
<span class="sd">                tag=&quot;training&quot;,</span>
<span class="sd">                output_transform=lambda loss: {&quot;loss&quot;: loss}</span>
<span class="sd">            )</span>

<span class="sd">            # Attach the logger to the evaluator on the training dataset and log NLL, Accuracy metrics after each epoch</span>
<span class="sd">            # We setup `global_step_transform=lambda *_: trainer.state.iteration` to take iteration value</span>
<span class="sd">            # of the `trainer`:</span>
<span class="sd">            wandb_logger.attach_output_handler(</span>
<span class="sd">                train_evaluator,</span>
<span class="sd">                event_name=Events.EPOCH_COMPLETED,</span>
<span class="sd">                tag=&quot;training&quot;,</span>
<span class="sd">                metric_names=[&quot;nll&quot;, &quot;accuracy&quot;],</span>
<span class="sd">                global_step_transform=lambda *_: trainer.state.iteration,</span>
<span class="sd">            )</span>

<span class="sd">            # Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="sd">            # each epoch. We setup `global_step_transform=lambda *_: trainer.state.iteration` to take iteration value</span>
<span class="sd">            # of the `trainer` instead of `evaluator`.</span>
<span class="sd">            wandb_logger.attach_output_handler(</span>
<span class="sd">                evaluator,</span>
<span class="sd">                event_name=Events.EPOCH_COMPLETED,</span>
<span class="sd">                tag=&quot;validation&quot;,</span>
<span class="sd">                metric_names=[&quot;nll&quot;, &quot;accuracy&quot;],</span>
<span class="sd">                global_step_transform=lambda *_: trainer.state.iteration,</span>
<span class="sd">            )</span>

<span class="sd">            # Attach the logger to the trainer to log optimizer&#39;s parameters, e.g. learning rate at each iteration</span>
<span class="sd">            wandb_logger.attach_opt_params_handler(</span>
<span class="sd">                trainer,</span>
<span class="sd">                event_name=Events.ITERATION_STARTED,</span>
<span class="sd">                optimizer=optimizer,</span>
<span class="sd">                param_name=&#39;lr&#39;  # optional</span>
<span class="sd">            )</span>

<span class="sd">            # We need to close the logger when we are done</span>
<span class="sd">            wandb_logger.close()</span>

<span class="sd">        If you want to log model gradients, the model call graph, etc., use the logger as wrapper of wandb. Refer</span>
<span class="sd">        to the documentation of wandb.watch for details:</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            wandb_logger = WandBLogger(</span>
<span class="sd">                entity=&quot;shared&quot;,</span>
<span class="sd">                project=&quot;pytorch-ignite-integration&quot;,</span>
<span class="sd">                name=&quot;cnn-mnist&quot;,</span>
<span class="sd">                config={&quot;max_epochs&quot;: 10},</span>
<span class="sd">                tags=[&quot;pytorch-ignite&quot;, &quot;minst&quot;]</span>
<span class="sd">            )</span>

<span class="sd">            model = torch.nn.Sequential(...)</span>
<span class="sd">            wandb_logger.watch(model)</span>

<span class="sd">        For model checkpointing, Weights &amp; Biases creates a local run dir, and automatically synchronizes all</span>
<span class="sd">        files saved there at the end of the run. You can just use the `wandb_logger.run.dir` as path for the</span>
<span class="sd">        `ModelCheckpoint`:</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            from ignite.handlers import ModelCheckpoint</span>

<span class="sd">            def score_function(engine):</span>
<span class="sd">                return engine.state.metrics[&#39;accuracy&#39;]</span>

<span class="sd">            model_checkpoint = ModelCheckpoint(</span>
<span class="sd">                wandb_logger.run.dir, n_saved=2, filename_prefix=&#39;best&#39;,</span>
<span class="sd">                require_empty=False, score_function=score_function,</span>
<span class="sd">                score_name=&quot;validation_accuracy&quot;,</span>
<span class="sd">                global_step_transform=global_step_from_engine(trainer)</span>
<span class="sd">            )</span>
<span class="sd">            evaluator.add_event_handler(Events.COMPLETED, model_checkpoint, {&#39;model&#39;: model})</span>


<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">import</span><span class="w"> </span><span class="nn">wandb</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_wandb</span> <span class="o">=</span> <span class="n">wandb</span>
        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;This contrib module requires wandb to be installed. &quot;</span>
                <span class="s2">&quot;You man install wandb with the command:</span><span class="se">\n</span><span class="s2"> pip install wandb</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;init&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
            <span class="n">wandb</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__getattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attr</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_wandb</span><span class="p">,</span> <span class="n">attr</span><span class="p">)</span>  <span class="c1"># type: ignore[misc]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">close</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_wandb</span><span class="o">.</span><span class="n">finish</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_create_output_handler</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;OutputHandler&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">OutputHandler</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_create_opt_params_handler</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;OptimizerParamsHandler&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">OptimizerParamsHandler</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>


<div class="viewcode-block" id="OutputHandler"><a class="viewcode-back" href="../../../../generated/ignite.contrib.handlers.wandb_logger.html#ignite.contrib.handlers.wandb_logger.OutputHandler">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">OutputHandler</span><span class="p">(</span><span class="n">BaseOutputHandler</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Helper handler to log engine&#39;s output and/or metrics</span>

<span class="sd">    Examples:</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            from ignite.contrib.handlers.wandb_logger import *</span>

<span class="sd">            # Create a logger. All parameters are optional. See documentation</span>
<span class="sd">            # on wandb.init for details.</span>

<span class="sd">            wandb_logger = WandBLogger(</span>
<span class="sd">                entity=&quot;shared&quot;,</span>
<span class="sd">                project=&quot;pytorch-ignite-integration&quot;,</span>
<span class="sd">                name=&quot;cnn-mnist&quot;,</span>
<span class="sd">                config={&quot;max_epochs&quot;: 10},</span>
<span class="sd">                tags=[&quot;pytorch-ignite&quot;, &quot;minst&quot;]</span>
<span class="sd">            )</span>

<span class="sd">            # Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="sd">            # each epoch. We setup `global_step_transform=lambda *_: trainer.state.iteration,` to take iteration value</span>
<span class="sd">            # of the `trainer`:</span>
<span class="sd">            wandb_logger.attach(</span>
<span class="sd">                evaluator,</span>
<span class="sd">                log_handler=OutputHandler(</span>
<span class="sd">                    tag=&quot;validation&quot;,</span>
<span class="sd">                    metric_names=[&quot;nll&quot;, &quot;accuracy&quot;],</span>
<span class="sd">                    global_step_transform=lambda *_: trainer.state.iteration,</span>
<span class="sd">                ),</span>
<span class="sd">                event_name=Events.EPOCH_COMPLETED</span>
<span class="sd">            )</span>
<span class="sd">            # or equivalently</span>
<span class="sd">            wandb_logger.attach_output_handler(</span>
<span class="sd">                evaluator,</span>
<span class="sd">                event_name=Events.EPOCH_COMPLETED,</span>
<span class="sd">                tag=&quot;validation&quot;,</span>
<span class="sd">                metric_names=[&quot;nll&quot;, &quot;accuracy&quot;],</span>
<span class="sd">                global_step_transform=lambda *_: trainer.state.iteration,</span>
<span class="sd">            )</span>

<span class="sd">        Another example, where model is evaluated every 500 iterations:</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            from ignite.contrib.handlers.wandb_logger import *</span>

<span class="sd">            @trainer.on(Events.ITERATION_COMPLETED(every=500))</span>
<span class="sd">            def evaluate(engine):</span>
<span class="sd">                evaluator.run(validation_set, max_epochs=1)</span>

<span class="sd">            # Create a logger. All parameters are optional. See documentation</span>
<span class="sd">            # on wandb.init for details.</span>

<span class="sd">            wandb_logger = WandBLogger(</span>
<span class="sd">                entity=&quot;shared&quot;,</span>
<span class="sd">                project=&quot;pytorch-ignite-integration&quot;,</span>
<span class="sd">                name=&quot;cnn-mnist&quot;,</span>
<span class="sd">                config={&quot;max_epochs&quot;: 10},</span>
<span class="sd">                tags=[&quot;pytorch-ignite&quot;, &quot;minst&quot;]</span>
<span class="sd">            )</span>

<span class="sd">            def global_step_transform(*args, **kwargs):</span>
<span class="sd">                return trainer.state.iteration</span>

<span class="sd">            # Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="sd">            # every 500 iterations. Since evaluator engine does not have access to the training iteration, we</span>
<span class="sd">            # provide a global_step_transform to return the trainer.state.iteration for the global_step, each time</span>
<span class="sd">            # evaluator metrics are plotted on Weights &amp; Biases.</span>

<span class="sd">            wandb_logger.attach_output_handler(</span>
<span class="sd">                evaluator,</span>
<span class="sd">                event_name=Events.EPOCH_COMPLETED,</span>
<span class="sd">                tag=&quot;validation&quot;,</span>
<span class="sd">                metrics=[&quot;nll&quot;, &quot;accuracy&quot;],</span>
<span class="sd">                global_step_transform=global_step_transform</span>
<span class="sd">            )</span>

<span class="sd">    Args:</span>
<span class="sd">        tag: common title for all produced plots. For example, &quot;training&quot;</span>
<span class="sd">        metric_names: list of metric names to plot or a string &quot;all&quot; to plot all available</span>
<span class="sd">            metrics.</span>
<span class="sd">        output_transform: output transform function to prepare `engine.state.output` as a number.</span>
<span class="sd">            For example, `output_transform = lambda output: output`</span>
<span class="sd">            This function can also return a dictionary, e.g `{&quot;loss&quot;: loss1, &quot;another_loss&quot;: loss2}` to label the plot</span>
<span class="sd">            with corresponding keys.</span>
<span class="sd">        global_step_transform: global step transform function to output a desired global step.</span>
<span class="sd">            Input of the function is `(engine, event_name)`. Output of function should be an integer.</span>
<span class="sd">            Default is None, global_step based on attached engine. If provided,</span>
<span class="sd">            uses function output as global_step. To setup global step from another engine, please use</span>
<span class="sd">            :meth:`~ignite.contrib.handlers.wandb_logger.global_step_from_engine`.</span>
<span class="sd">        sync: If set to False, process calls to log in a seperate thread. Default (None) uses whatever</span>
<span class="sd">            the default value of wandb.log.</span>

<span class="sd">    Note:</span>

<span class="sd">        Example of `global_step_transform`:</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            def global_step_transform(engine, event_name):</span>
<span class="sd">                return engine.state.get_event_attrib_value(event_name)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tag</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">metric_names</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_transform</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">global_step_transform</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">sync</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">tag</span><span class="p">,</span> <span class="n">metric_names</span><span class="p">,</span> <span class="n">output_transform</span><span class="p">,</span> <span class="n">global_step_transform</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sync</span> <span class="o">=</span> <span class="n">sync</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">engine</span><span class="p">:</span> <span class="n">Engine</span><span class="p">,</span> <span class="n">logger</span><span class="p">:</span> <span class="n">WandBLogger</span><span class="p">,</span> <span class="n">event_name</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Events</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">logger</span><span class="p">,</span> <span class="n">WandBLogger</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Handler &#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&#39; works only with WandBLogger.&quot;</span><span class="p">)</span>

        <span class="n">global_step</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_step_transform</span><span class="p">(</span><span class="n">engine</span><span class="p">,</span> <span class="n">event_name</span><span class="p">)</span>  <span class="c1"># type: ignore[misc]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">global_step</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;global_step must be int, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">global_step</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="s2">&quot; Please check the output of global_step_transform.&quot;</span>
            <span class="p">)</span>

        <span class="n">metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_setup_output_metrics</span><span class="p">(</span><span class="n">engine</span><span class="p">)</span>
        <span class="n">rendered_metrics</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># type: Dict[str, Union[str, float, numbers.Number]]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tag</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">metrics</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Number</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                    <span class="n">rendered_metrics</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">tag</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
                <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="n">value</span><span class="o">.</span><span class="n">ndimension</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">rendered_metrics</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">tag</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="n">value</span><span class="o">.</span><span class="n">ndimension</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
                        <span class="n">rendered_metrics</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">tag</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;WandBLogger output_handler can not log metrics value type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">value</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">rendered_metrics</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">global_step</span><span class="p">,</span> <span class="n">sync</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sync</span><span class="p">)</span></div>


<div class="viewcode-block" id="OptimizerParamsHandler"><a class="viewcode-back" href="../../../../generated/ignite.contrib.handlers.wandb_logger.html#ignite.contrib.handlers.wandb_logger.OptimizerParamsHandler">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">OptimizerParamsHandler</span><span class="p">(</span><span class="n">BaseOptimizerParamsHandler</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Helper handler to log optimizer parameters</span>

<span class="sd">    Examples:</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            from ignite.contrib.handlers.wandb_logger import *</span>

<span class="sd">            # Create a logger. All parameters are optional. See documentation</span>
<span class="sd">            # on wandb.init for details.</span>

<span class="sd">            wandb_logger = WandBLogger(</span>
<span class="sd">                entity=&quot;shared&quot;,</span>
<span class="sd">                project=&quot;pytorch-ignite-integration&quot;,</span>
<span class="sd">                name=&quot;cnn-mnist&quot;,</span>
<span class="sd">                config={&quot;max_epochs&quot;: 10},</span>
<span class="sd">                tags=[&quot;pytorch-ignite&quot;, &quot;minst&quot;]</span>
<span class="sd">            )</span>

<span class="sd">            # Attach the logger to the trainer to log optimizer&#39;s parameters, e.g. learning rate at each iteration</span>
<span class="sd">            wandb_logger.attach(</span>
<span class="sd">                trainer,</span>
<span class="sd">                log_handler=OptimizerParamsHandler(optimizer),</span>
<span class="sd">                event_name=Events.ITERATION_STARTED</span>
<span class="sd">            )</span>
<span class="sd">            # or equivalently</span>
<span class="sd">            wandb_logger.attach_opt_params_handler(</span>
<span class="sd">                trainer,</span>
<span class="sd">                event_name=Events.ITERATION_STARTED,</span>
<span class="sd">                optimizer=optimizer</span>
<span class="sd">            )</span>

<span class="sd">    Args:</span>
<span class="sd">        optimizer: torch optimizer or any object with attribute ``param_groups``</span>
<span class="sd">            as a sequence.</span>
<span class="sd">        param_name: parameter name</span>
<span class="sd">        tag: common title for all produced plots. For example, &quot;generator&quot;</span>
<span class="sd">        sync: If set to False, process calls to log in a seperate thread. Default (None) uses whatever</span>
<span class="sd">            the default value of wandb.log.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">:</span> <span class="n">Optimizer</span><span class="p">,</span> <span class="n">param_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="n">tag</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">sync</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">OptimizerParamsHandler</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">param_name</span><span class="p">,</span> <span class="n">tag</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sync</span> <span class="o">=</span> <span class="n">sync</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">engine</span><span class="p">:</span> <span class="n">Engine</span><span class="p">,</span> <span class="n">logger</span><span class="p">:</span> <span class="n">WandBLogger</span><span class="p">,</span> <span class="n">event_name</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Events</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">logger</span><span class="p">,</span> <span class="n">WandBLogger</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Handler OptimizerParamsHandler works only with WandBLogger&quot;</span><span class="p">)</span>

        <span class="n">global_step</span> <span class="o">=</span> <span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">get_event_attrib_value</span><span class="p">(</span><span class="n">event_name</span><span class="p">)</span>
        <span class="n">tag_prefix</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">tag</span><span class="si">}</span><span class="s2">/&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tag</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span>
        <span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">tag_prefix</span><span class="si">}{</span><span class="bp">self</span><span class="o">.</span><span class="n">param_name</span><span class="si">}</span><span class="s2">/group_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">param_group</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">param_name</span><span class="p">])</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">param_group</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">)</span>
        <span class="p">}</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">global_step</span><span class="p">,</span> <span class="n">sync</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sync</span><span class="p">)</span></div>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <table>
      <tr>
        <td>
            <p>
                &copy; Copyright 2025, PyTorch-Ignite Contributors.
              Last updated on 10/16/2025, 3:53:21‚ÄØPM.
            </p>
            
              <div>
                Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
              </div>
          
        </td>
        <td>
            
              <div>
                <a href="https://www.netlify.com" target="_blank" rel="noopener noreferrer">
                  <img
                  src="_static/img/netlify-light.svg"
                  alt="Deploys by Netlify"
                  width=114
                  height=51 />
                </a>
              </div>
            
        </td>
      </tr>
    </table>
  </div> 

</footer>
          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
         <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
         <script src="../../../../_static/jquery.js"></script>
         <script src="../../../../_static/underscore.js"></script>
         <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="../../../../_static/doctools.js"></script>
         <script src="../../../../_static/sphinx_highlight.js"></script>
         <script src="../../../../_static/clipboard.min.js"></script>
         <script src="../../../../_static/copybutton.js"></script>
         <script>let toggleHintShow = 'Show default setup';</script>
         <script>let toggleHintHide = 'Hide default setup';</script>
         <script>let toggleOpenOnPrint = 'true';</script>
         <script src="../../../../_static/togglebutton.js"></script>
         <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
         <script src="../../../../_static/design-tabs.js"></script>
     

  

  <script type="text/javascript" src="../../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/vendor/bootstrap.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <!-- commented out for Ignite -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <!-- <div class="container">
      <div class="row">
        <div class="text-center col-md-4">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/ignite/index.html">View Docs</a>
        </div>

        <div class="text-center col-md-4">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="">View Tutorials</a>
        </div>

        <div class="text-center col-md-4">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="">View Resources</a>
        </div>
      </div>
    </div> -->
  </div>

  <!-- <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch-ignite.ai" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch-ignite.ai">PyTorch</a></li>
            <li><a href="">Get Started</a></li>
            <li><a href="">Features</a></li>
            <li><a href="">Ecosystem</a></li>
            <li><a href="">Blog</a></li>
            <li><a href="">Resources</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="">Support</a></li>
            <li><a href="">Tutorials</a></li>
            <li><a href="https://pytorch.org/ignite/index.html">Docs</a></li>
            <li><a href="" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/ignite/issues" target="_blank">Github Issues</a></li>
            <li><a href="" target="_blank">Slack</a></li>
            <li><a href="https://github.com/pytorch/ignite/blob/master/CONTRIBUTING.md" target="_blank">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Follow Us</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>    <!~~ real people should not fill this in and expect good things - do not remove this or risk form bot signups ~~>

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="" target="_blank" class="facebook"></a>
            <a href="" target="_blank" class="twitter"></a>
          </div>
        </div>
      </div>
    </div>
  </footer> -->


  <!-- end of commented out for Ignite -->

  <!-- <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook‚Äôs Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../../../_static/images/pytorch-x.svg">
  </div>
</div> -->

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->
  <!--
  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch-ignite.ai" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="#">Get Started</a>
          </li>

          <li>
            <a href="#">Features</a>
          </li>

          <li>
            <a href="#">Ecosystem</a>
          </li>

          <li>
            <a href="">Blog</a>
          </li>

          <li>
            <a href="">Tutorials</a>
          </li>

          <li>
            <a href="https://pytorch.org/ignite/index.html">Docs</a>
          </li>

          <li>
            <a href="">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/ignite">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>
  -->
  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    var collapsedSections = []
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
  <script src="https://cdn.jsdelivr.net/npm/@docsearch/js@3"></script>
  <script type="text/javascript">
  let VERSION
  if ('v0.4.5'.startsWith('v')) {
    VERSION = 'v0.4.5'
  } else {
    VERSION = 'master'
  }
  docsearch({
    container: '#docsearch',
    appId: '7EWYE1JCT3',
    apiKey: '841e93e60c16975ba1bd8c7c716eed82',
    indexName: 'pytorch-ignite',
    placeholder: 'Search PyTorch-Ignite docs',
    searchParameters: {
      facetFilters: [`version:${VERSION}`, 'tags:API-reference'],
    }
  });
  </script>
</body>
</html>