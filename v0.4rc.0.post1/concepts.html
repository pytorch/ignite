



<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="author" content="PyTorch-Ignite Contributors">
  <meta name="creator" content="PyTorch-Ignite Contributors">
  <meta name="publisher" content="PyTorch-Ignite Contributors">
  <meta name="generator" content="Sphinx 5.3.0">
  <meta name="description" content="High-level library to help with training and evaluating neural networks in PyTorch flexibly and transparently.">
  <meta name="keywords" content="pytorch, pytorch ignite, ignite, engine, events, handlers, metrics">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="theme-color" content="#ee4c2c">

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@pytorch_ignite">
  <meta name="twitter:creator" content="@pytorch_ignite">
  <meta name="twitter:description" content="High-level library to help with training and evaluating neural networks in PyTorch flexibly and transparently.">
  <meta name="twitter:title" content="Concepts &mdash; PyTorch-Ignite v0.4rc.0.post1 Documentation">
  <meta name="twitter:image" content="https://raw.githubusercontent.com/pytorch/ignite/master/assets/logo/ignite_logo.png">
  <meta name="twitter:image:alt" content="PyTorch-Ignite logo">

  <meta property="og:title" content="Concepts &mdash; PyTorch-Ignite v0.4rc.0.post1 Documentation">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://pytorch.org/ignite/">
  <meta property="og:site_name" content="PyTorch-Ignite">
  <meta property="og:image" content="https://raw.githubusercontent.com/pytorch/ignite/master/assets/logo/ignite_logo.png">
  <meta property="og:image:alt" content="PyTorch-Ignite logo">
  <meta property="og:description" content="High-level library to help with training and evaluating neural networks in PyTorch flexibly and transparently.">

  <link rel="preconnect" href="https://BH4D9OD16A-dsn.algolia.net" crossorigin />

  
  <title>Concepts &mdash; PyTorch-Ignite v0.4rc.0.post1 Documentation</title>
  

  
  
    <link rel="shortcut icon" type="image/svg+xml" href="_static/ignite_logomark.svg"/>
  
  
  
    <link rel="canonical" href="https://pytorch.org/ignite/concepts.html"/>
  

  

  
  
    

  

  <link rel="preload" href="_static/css/theme.css" as="style" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="_static/pygments.css" type="text/css" /> -->
  <link rel="preload" href="_static/pygments.css" as="style" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="preload" href="_static/css/theme.css" as="style" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="preload" href="_static/copybutton.css" as="style" />
  <link rel="stylesheet" href="_static/copybutton.css" type="text/css" />
  <link rel="preload" href="_static/togglebutton.css" as="style" />
  <link rel="stylesheet" href="_static/togglebutton.css" type="text/css" />
  <link rel="preload" href="_static/banner.css" as="style" />
  <link rel="stylesheet" href="_static/banner.css" type="text/css" />
  <link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.css" as="style" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.css" type="text/css" />
  <link rel="preload" href="_static/katex-math.css" as="style" />
  <link rel="stylesheet" href="_static/katex-math.css" type="text/css" />
  <link rel="preload" href="_static/sphinx-design.5ea377869091fd0449014c60fc090103.min.css" as="style" />
  <link rel="stylesheet" href="_static/sphinx-design.5ea377869091fd0449014c60fc090103.min.css" type="text/css" />
    <link rel="preload" href="_static/css/ignite_theme.css" as="style" />
    <link rel="stylesheet" href="_static/css/ignite_theme.css" type="text/css" />
    <link rel="preload" href="https://cdn.jsdelivr.net/npm/@docsearch/css@3" as="style" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@docsearch/css@3" type="text/css" />
    <link rel="author" title="About these documents" href="about.html" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Quickstart" href="quickstart.html" />
    <link rel="prev" title="Ignite Your Networks!" href="index.html" /> 

  <!-- katex links / this needs to be loaded before fonts.html -->

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/katex.min.css" crossorigin="anonymous">
<script async src="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/katex.min.js" crossorigin="anonymous"></script>

<!-- Preload the theme fonts -->

<link rel="preload" href="_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-5FELLLFHCP"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-5FELLLFHCP');
  </script>
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">

    <a class="header-logo" href="/ignite" aria-label="PyTorch-Ignite"></a>

    <div class="header-container">

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch-ignite.ai/tutorials/beginner/01-getting-started/">Quickstart</a>
          </li>

          <li>
            <a href="https://pytorch-ignite.ai/concepts/">Concepts</a>
          </li>

          <!-- <li>
            <a href="https://pytorch-ignite.ai/tutorials/beginner/01-getting-started/#complete-code">Examples</a>
          </li> -->

          <li>
            <a href="https://pytorch-ignite.ai/how-to-guides/">FAQ</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/ignite" target="_blank" rel="noopener noreferrer">GitHub</a>
          </li>

          <li>
            <a href="https://pytorch-ignite.ai/about/community/">About us</a>
          </li>

          <li>
            <a href="https://pytorch-ignite.ai">‚ä≥ pytorch-ignite.ai</a>
          </li>


        </ul>
      </div>

      <!-- <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a> -->
    </div>

  </div>
</div>


<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <div class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></div>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  v0.4rc.0.post1
                </div>
              
            

            <div id="docsearch"></div>

            
          </div>

          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Notes</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="quickstart.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Package Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="engine.html">ignite.engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="handlers.html">ignite.handlers</a></li>
<li class="toctree-l1"><a class="reference internal" href="metrics.html">ignite.metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed.html">ignite.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="exceptions.html">ignite.exceptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="utils.html">ignite.utils</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contrib Package Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="contrib/engines.html">ignite.contrib.engines</a></li>
<li class="toctree-l1"><a class="reference internal" href="contrib/metrics.html">ignite.contrib.metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="contrib/handlers.html">ignite.contrib.handlers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Team</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="about.html">About us</a></li>
<li class="toctree-l1"><a class="reference internal" href="governance.html">PyTorch-Ignite governance</a></li>
</ul>

            
          
        </div>
      </div>

      <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
        <span class="fa fa-book"> Other Versions</span>
        v: v0.4rc.0.post1
        <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
        <dl>
            <dt>Tags</dt>
            <dd><a href="../v0.3.0/concepts.html">v0.3.0</a></dd>
            <dd><a href="../v0.4.0.post1/concepts.html">v0.4.0.post1</a></dd>
            <dd><a href="../v0.4.1/concepts.html">v0.4.1</a></dd>
            <dd><a href="../v0.4.10/concepts.html">v0.4.10</a></dd>
            <dd><a href="../v0.4.11/index.html">v0.4.11</a></dd>
            <dd><a href="../v0.4.12/index.html">v0.4.12</a></dd>
            <dd><a href="../v0.4.13/index.html">v0.4.13</a></dd>
            <dd><a href="../v0.4.2/concepts.html">v0.4.2</a></dd>
            <dd><a href="../v0.4.3/concepts.html">v0.4.3</a></dd>
            <dd><a href="../v0.4.4.post1/concepts.html">v0.4.4.post1</a></dd>
            <dd><a href="../v0.4.5/concepts.html">v0.4.5</a></dd>
            <dd><a href="../v0.4.6/concepts.html">v0.4.6</a></dd>
            <dd><a href="../v0.4.7/concepts.html">v0.4.7</a></dd>
            <dd><a href="../v0.4.8/concepts.html">v0.4.8</a></dd>
            <dd><a href="../v0.4.9/concepts.html">v0.4.9</a></dd>
            <dd><a href="concepts.html">v0.4rc.0.post1</a></dd>
            <dd><a href="../v0.5.0.post2/index.html">v0.5.0.post2</a></dd>
            <dd><a href="../v0.5.1/index.html">v0.5.1</a></dd>
            <dd><a href="../v0.5.2/index.html">v0.5.2</a></dd>
            <dd><a href="../v0.5.3/index.html">v0.5.3</a></dd>
        </dl>
        <dl>
            <dt>Branches</dt>
            <dd><a href="../master/index.html">master</a></dd>
        </dl>
    </div>
</div>

    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li>Concepts</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="_sources/concepts.rst.txt" rel="nofollow"><img src="_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <section id="concepts">
<h1>Concepts<a class="headerlink" href="#concepts" title="Permalink to this heading">#</a></h1>
<section id="engine">
<h2>Engine<a class="headerlink" href="#engine" title="Permalink to this heading">#</a></h2>
<p>The <strong>essence</strong> of the framework is the class <a class="reference internal" href="engine.html#id0" title="ignite.engine.engine.Engine"><code class="xref py py-class docutils literal notranslate"><span class="pre">Engine</span></code></a>, an abstraction that loops a given number of times over
provided data, executes a processing function and returns a result:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">while</span> <span class="n">epoch</span> <span class="o">&lt;</span> <span class="n">max_epochs</span><span class="p">:</span>
    <span class="c1"># run an epoch on data</span>
    <span class="n">data_iter</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">data_iter</span><span class="p">)</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">process_function</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
            <span class="n">iter_counter</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">except</span> <span class="ne">StopIteration</span><span class="p">:</span>
            <span class="n">data_iter</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">iter_counter</span> <span class="o">==</span> <span class="n">epoch_length</span><span class="p">:</span>
            <span class="k">break</span>
</pre></div>
</div>
<p>Thus, a model trainer is simply an engine that loops multiple times over the training dataset and updates model parameters.
Similarly, model evaluation can be done with an engine that runs a single time over the validation dataset and computes metrics.
For example, model trainer for a supervised task:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">update_model</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">prepare_batch</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">Engine</span><span class="p">(</span><span class="n">update_model</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>By default, epoch length is defined by <cite>len(data)</cite>. However, user can also manually define the epoch length as a
number of iterations to loop. In this way the input data can be an iterator.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">epoch_length</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="events-and-handlers">
<h2>Events and Handlers<a class="headerlink" href="#events-and-handlers" title="Permalink to this heading">#</a></h2>
<p>To improve the <a class="reference internal" href="engine.html#id0" title="ignite.engine.engine.Engine"><code class="xref py py-class docutils literal notranslate"><span class="pre">Engine</span></code></a>‚Äôs flexibility, an event system is introduced that facilitates interaction on each step of
the run:</p>
<ul class="simple">
<li><p><em>engine is started/completed</em></p></li>
<li><p><em>epoch is started/completed</em></p></li>
<li><p><em>batch iteration is started/completed</em></p></li>
</ul>
<p>Complete list of events can be found at <a class="reference internal" href="engine.html#ignite.engine.events.Events" title="ignite.engine.events.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a>.</p>
<p>Thus, user can execute a custom code as an event handler. Handlers can be any function: e.g. lambda, simple function,
class method etc. The first argument can be optionally <cite>engine</cite>, but not necessary.</p>
<p>Let us consider in more detail what happens when <a class="reference internal" href="engine.html#id10" title="ignite.engine.engine.Engine.run"><code class="xref py py-meth docutils literal notranslate"><span class="pre">run()</span></code></a> is called:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">fire_event</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">STARTED</span><span class="p">)</span>
<span class="k">while</span> <span class="n">epoch</span> <span class="o">&lt;</span> <span class="n">max_epochs</span><span class="p">:</span>
    <span class="n">fire_event</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_STARTED</span><span class="p">)</span>
    <span class="c1"># run once on data</span>
    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
        <span class="n">fire_event</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">)</span>

        <span class="n">output</span> <span class="o">=</span> <span class="n">process_function</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>

        <span class="n">fire_event</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">)</span>
    <span class="n">fire_event</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">)</span>
<span class="n">fire_event</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">COMPLETED</span><span class="p">)</span>
</pre></div>
</div>
<p>At first <em>engine is started</em> event is fired and all this event handlers are executed (we will see in the next paragraph
how to add event handlers). Next, <cite>while</cite> loop is started and <em>epoch is started</em> event occurs, etc. Every time
an event is ‚Äúfired‚Äù, attached handlers are executed.</p>
<p>Attaching an event handler is simple using method <a class="reference internal" href="engine.html#id3" title="ignite.engine.engine.Engine.add_event_handler"><code class="xref py py-meth docutils literal notranslate"><span class="pre">add_event_handler()</span></code></a> or
<a class="reference internal" href="engine.html#id7" title="ignite.engine.engine.Engine.on"><code class="xref py py-meth docutils literal notranslate"><span class="pre">on()</span></code></a> decorator:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span> <span class="o">=</span> <span class="n">Engine</span><span class="p">(</span><span class="n">update_model</span><span class="p">)</span>

<span class="n">trainer</span><span class="o">.</span><span class="n">add_event_handler</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">STARTED</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">engine</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Start training&quot;</span><span class="p">))</span>
<span class="c1"># or</span>
<span class="nd">@trainer</span><span class="o">.</span><span class="n">on</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">STARTED</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">on_training_started</span><span class="p">(</span><span class="n">engine</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Another message of start training&quot;</span><span class="p">)</span>
<span class="c1"># or even simpler, use only what you need !</span>
<span class="nd">@trainer</span><span class="o">.</span><span class="n">on</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">STARTED</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">on_training_started</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Another message of start training&quot;</span><span class="p">)</span>

<span class="c1"># attach handler with args, kwargs</span>
<span class="n">mydata</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>

<span class="k">def</span><span class="w"> </span><span class="nf">on_training_ended</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training is ended. mydata=</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>

<span class="n">trainer</span><span class="o">.</span><span class="n">add_event_handler</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">COMPLETED</span><span class="p">,</span> <span class="n">on_training_ended</span><span class="p">,</span> <span class="n">mydata</span><span class="p">)</span>
</pre></div>
</div>
<p>Event handlers can be detached via <a class="reference internal" href="engine.html#id9" title="ignite.engine.engine.Engine.remove_event_handler"><code class="xref py py-meth docutils literal notranslate"><span class="pre">remove_event_handler()</span></code></a> or via the <a class="reference internal" href="engine.html#ignite.engine.events.RemovableEventHandle" title="ignite.engine.events.RemovableEventHandle"><code class="xref py py-class docutils literal notranslate"><span class="pre">RemovableEventHandle</span></code></a>
reference returned by <a class="reference internal" href="engine.html#id3" title="ignite.engine.engine.Engine.add_event_handler"><code class="xref py py-meth docutils literal notranslate"><span class="pre">add_event_handler()</span></code></a>. This can be used to reuse a configured engine for multiple loops:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">train_loader</span><span class="p">,</span> <span class="n">validation_loader</span><span class="p">,</span> <span class="n">test_loader</span> <span class="o">=</span> <span class="o">...</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">create_supervised_trainer</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
<span class="n">evaluator</span> <span class="o">=</span> <span class="n">create_supervised_evaluator</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;acc&#39;</span><span class="p">:</span> <span class="n">Accuracy</span><span class="p">()})</span>

<span class="k">def</span><span class="w"> </span><span class="nf">log_metrics</span><span class="p">(</span><span class="n">engine</span><span class="p">,</span> <span class="n">title</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Epoch: </span><span class="si">{}</span><span class="s2"> - </span><span class="si">{}</span><span class="s2"> accuracy: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span>
           <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">trainer</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">epoch</span><span class="p">,</span> <span class="n">title</span><span class="p">,</span> <span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;acc&#39;</span><span class="p">]))</span>

<span class="nd">@trainer</span><span class="o">.</span><span class="n">on</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span><span class="n">trainer</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">evaluator</span><span class="o">.</span><span class="n">add_event_handler</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">COMPLETED</span><span class="p">,</span> <span class="n">log_metrics</span><span class="p">,</span> <span class="s2">&quot;train&quot;</span><span class="p">):</span>
        <span class="n">evaluator</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">evaluator</span><span class="o">.</span><span class="n">add_event_handler</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">COMPLETED</span><span class="p">,</span> <span class="n">log_metrics</span><span class="p">,</span> <span class="s2">&quot;validation&quot;</span><span class="p">):</span>
        <span class="n">evaluator</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">validation_loader</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">evaluator</span><span class="o">.</span><span class="n">add_event_handler</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">COMPLETED</span><span class="p">,</span> <span class="n">log_metrics</span><span class="p">,</span> <span class="s2">&quot;test&quot;</span><span class="p">):</span>
        <span class="n">evaluator</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">test_loader</span><span class="p">)</span>

<span class="n">trainer</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
<p>Event handlers can be also configured to be called with a user pattern: every n-th events, once or using a custom
event filtering function:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">train_loader</span><span class="p">,</span> <span class="n">validation_loader</span><span class="p">,</span> <span class="n">test_loader</span> <span class="o">=</span> <span class="o">...</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">create_supervised_trainer</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>

<span class="nd">@trainer</span><span class="o">.</span><span class="n">on</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">(</span><span class="n">every</span><span class="o">=</span><span class="mi">50</span><span class="p">))</span>
<span class="k">def</span><span class="w"> </span><span class="nf">log_training_loss_every_50_iterations</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2"> / </span><span class="si">{}</span><span class="s2"> : </span><span class="si">{}</span><span class="s2"> - loss: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span>
          <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">trainer</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">epoch</span><span class="p">,</span> <span class="n">trainer</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">max_epochs</span><span class="p">,</span> <span class="n">trainer</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">iteration</span><span class="p">,</span> <span class="n">trainer</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">output</span><span class="p">))</span>

<span class="nd">@trainer</span><span class="o">.</span><span class="n">on</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_STARTED</span><span class="p">(</span><span class="n">once</span><span class="o">=</span><span class="mi">25</span><span class="p">))</span>
<span class="k">def</span><span class="w"> </span><span class="nf">do_something_once_on_25_epoch</span><span class="p">():</span>
    <span class="c1"># do something</span>

<span class="k">def</span><span class="w"> </span><span class="nf">custom_event_filter</span><span class="p">(</span><span class="n">engine</span><span class="p">,</span> <span class="n">event</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">event</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">]:</span>
        <span class="k">return</span> <span class="kc">True</span>
    <span class="k">return</span> <span class="kc">False</span>

<span class="nd">@engine</span><span class="o">.</span><span class="n">on</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">(</span><span class="n">event_filter</span><span class="o">=</span><span class="n">custom_event_filter</span><span class="p">))</span>
<span class="k">def</span><span class="w"> </span><span class="nf">call_on_special_event</span><span class="p">(</span><span class="n">engine</span><span class="p">):</span>
     <span class="c1"># do something on 1, 2, 5, 10, 50, 100 iterations</span>

<span class="n">trainer</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>User can also register custom events with <a class="reference internal" href="engine.html#id8" title="ignite.engine.engine.Engine.register_events"><code class="xref py py-meth docutils literal notranslate"><span class="pre">register_events()</span></code></a>, attach handlers and fire custom events
calling <a class="reference internal" href="engine.html#id4" title="ignite.engine.engine.Engine.fire_event"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fire_event()</span></code></a> in any handler or <cite>process_function</cite>.</p>
<p>See the source code of <code class="xref py py-class docutils literal notranslate"><span class="pre">create_supervised_tbptt_trainer</span></code> for an example of usage of
custom events.</p>
</div>
<section id="timeline-and-events">
<h3>Timeline and events<a class="headerlink" href="#timeline-and-events" title="Permalink to this heading">#</a></h3>
<p>Below the events and some typical handlers are displayed on a timeline for a training loop with evaluation after every
epoch:</p>
<a class="reference external image-reference" href="_static/img/concepts/timeline_and_events.png"><img alt="_images/timeline_and_events.png" src="_images/timeline_and_events.png" /></a>
</section>
</section>
<section id="state">
<h2>State<a class="headerlink" href="#state" title="Permalink to this heading">#</a></h2>
<p>A state is introduced in <a class="reference internal" href="engine.html#id0" title="ignite.engine.engine.Engine"><code class="xref py py-class docutils literal notranslate"><span class="pre">Engine</span></code></a> to store the output of the <cite>process_function</cite>, current epoch,
iteration and other helpful information. Each <a class="reference internal" href="engine.html#id0" title="ignite.engine.engine.Engine"><code class="xref py py-class docutils literal notranslate"><span class="pre">Engine</span></code></a> contains a <a class="reference internal" href="engine.html#ignite.engine.events.State" title="ignite.engine.events.State"><code class="xref py py-class docutils literal notranslate"><span class="pre">State</span></code></a>,
which includes the following:</p>
<ul class="simple">
<li><p><strong>engine.state.seed</strong>: Seed to set at each data ‚Äúepoch‚Äù.</p></li>
<li><p><strong>engine.state.epoch</strong>: Number of epochs the engine has completed. Initializated as 0 and the first epoch is 1.</p></li>
<li><p><strong>engine.state.iteration</strong>: Number of iterations the engine has completed. Initialized as 0 and the first iteration is 1.</p></li>
<li><p><strong>engine.state.max_epochs</strong>: Number of epochs to run for. Initializated as 1.</p></li>
<li><p><strong>engine.state.output</strong>: The output of the <cite>process_function</cite> defined for the <a class="reference internal" href="engine.html#id0" title="ignite.engine.engine.Engine"><code class="xref py py-class docutils literal notranslate"><span class="pre">Engine</span></code></a>. See below.</p></li>
<li><p>etc</p></li>
</ul>
<p>Other attributes can be found in the docs of <a class="reference internal" href="engine.html#ignite.engine.events.State" title="ignite.engine.events.State"><code class="xref py py-class docutils literal notranslate"><span class="pre">State</span></code></a>.</p>
<p>In the code below, <cite>engine.state.output</cite> will store the batch loss. This output is used to print the loss at
every iteration.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">update</span><span class="p">(</span><span class="n">engine</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

<span class="k">def</span><span class="w"> </span><span class="nf">on_iteration_completed</span><span class="p">(</span><span class="n">engine</span><span class="p">):</span>
    <span class="n">iteration</span> <span class="o">=</span> <span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">iteration</span>
    <span class="n">epoch</span> <span class="o">=</span> <span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">epoch</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">output</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Epoch: </span><span class="si">{}</span><span class="s2">, Iteration: </span><span class="si">{}</span><span class="s2">, Loss: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">iteration</span><span class="p">,</span> <span class="n">loss</span><span class="p">))</span>

<span class="n">trainer</span><span class="o">.</span><span class="n">add_event_handler</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">,</span> <span class="n">on_iteration_completed</span><span class="p">)</span>
</pre></div>
</div>
<p>Since there is no restrictions on the output of <cite>process_function</cite>, Ignite provides <cite>output_transform</cite> argument for its
<code class="xref py py-class docutils literal notranslate"><span class="pre">metrics</span></code> and <code class="xref py py-class docutils literal notranslate"><span class="pre">handlers</span></code>. Argument <cite>output_transform</cite> is a function used to transform <cite>engine.state.output</cite> for intended use. Below we‚Äôll see different types of <cite>engine.state.output</cite> and how to transform them.</p>
<p>In the code below, <cite>engine.state.output</cite> will be a list of loss, y_pred, y for the processed batch. If we want to attach <a class="reference internal" href="metrics.html#ignite.metrics.Accuracy" title="ignite.metrics.Accuracy"><code class="xref py py-class docutils literal notranslate"><span class="pre">Accuracy</span></code></a> to the engine, <cite>output_transform</cite> will be needed to get y_pred and y from
<cite>engine.state.output</cite>. Let‚Äôs see how that is done:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">update</span><span class="p">(</span><span class="n">engine</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">y</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">Engine</span><span class="p">(</span><span class="n">update</span><span class="p">)</span>

<span class="nd">@trainer</span><span class="o">.</span><span class="n">on</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">print_loss</span><span class="p">(</span><span class="n">engine</span><span class="p">):</span>
    <span class="n">epoch</span> <span class="o">=</span> <span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">epoch</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;Epoch </span><span class="si">{epoch}</span><span class="s1">: train_loss = </span><span class="si">{loss}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">))</span>

<span class="n">accuracy</span> <span class="o">=</span> <span class="n">Accuracy</span><span class="p">(</span><span class="n">output_transform</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">]])</span>
<span class="n">accuracy</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="s1">&#39;acc&#39;</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
<p>Similar to above, but this time the output of the <cite>process_function</cite> is a dictionary of loss, y_pred, y for the processed
batch, this is how the user can use <cite>output_transform</cite> to get y_pred and y from <cite>engine.state.output</cite>. See below:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">update</span><span class="p">(</span><span class="n">engine</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
            <span class="s1">&#39;y_pred&#39;</span><span class="p">:</span> <span class="n">y_pred</span><span class="p">,</span>
            <span class="s1">&#39;y&#39;</span><span class="p">:</span> <span class="n">y</span><span class="p">}</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">Engine</span><span class="p">(</span><span class="n">update</span><span class="p">)</span>

<span class="nd">@trainer</span><span class="o">.</span><span class="n">on</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">print_loss</span><span class="p">(</span><span class="n">engine</span><span class="p">):</span>
    <span class="n">epoch</span> <span class="o">=</span> <span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">epoch</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
    <span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;Epoch </span><span class="si">{epoch}</span><span class="s1">: train_loss = </span><span class="si">{loss}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">))</span>

<span class="n">accuracy</span> <span class="o">=</span> <span class="n">Accuracy</span><span class="p">(</span><span class="n">output_transform</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="s1">&#39;y_pred&#39;</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">]])</span>
<span class="n">accuracy</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="s1">&#39;acc&#39;</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A good practice is to use <a class="reference internal" href="engine.html#ignite.engine.events.State" title="ignite.engine.events.State"><code class="xref py py-class docutils literal notranslate"><span class="pre">State</span></code></a> also as a storage of user data created in update or handler functions.
For example, we would like to save <cite>new_attribute</cite> in the <cite>state</cite>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">user_handler_function</span><span class="p">(</span><span class="n">engine</span><span class="p">):</span>
    <span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">new_attribute</span> <span class="o">=</span> <span class="mi">12345</span>
</pre></div>
</div>
</div>
</section>
<section id="deterministic-training">
<h2>Deterministic training<a class="headerlink" href="#deterministic-training" title="Permalink to this heading">#</a></h2>
<p>In general, it is rather difficult task to achieve deterministic and reproducible trainings as it relies on multiple
aspects, e.g. data version, code version, software environment, hardware etc. According to <a class="reference external" href="https://pytorch.org/docs/stable/notes/randomness.html">PyTorch documentation</a>:
there are some steps to take in order to make computations deterministic on your specific problem on one specific
platform and PyTorch release:</p>
<ul class="simple">
<li><p>setup random state seed</p></li>
<li><p>set <a class="reference external" href="https://pytorch.org/docs/stable/notes/randomness.html#cudnn">cudnn to deterministic</a> if applicable</p></li>
</ul>
<p>By default, these two options can be enough to run and rerun experiments in a deterministic way.
Ignite‚Äôs engine does not impact this behaviour.</p>
</section>
<section id="resuming-the-training">
<h2>Resuming the training<a class="headerlink" href="#resuming-the-training" title="Permalink to this heading">#</a></h2>
<p>It is also possible to resume the training from a checkpoint and approximatively reproduce original run‚Äôs behaviour.
Using Ignite, this can be easily done using <a class="reference internal" href="handlers.html#ignite.handlers.Checkpoint" title="ignite.handlers.Checkpoint"><code class="xref py py-class docutils literal notranslate"><span class="pre">Checkpoint</span></code></a> handler. Engine provides two methods
to serialize and deserialize its internal state <a class="reference internal" href="engine.html#id12" title="ignite.engine.engine.Engine.state_dict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">state_dict()</span></code></a> and
<a class="reference internal" href="engine.html#id6" title="ignite.engine.engine.Engine.load_state_dict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">load_state_dict()</span></code></a>. In addition to serializing model, optimizer, lr scheduler etc user can
store the trainer and then resume the training. For example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.engine</span><span class="w"> </span><span class="kn">import</span> <span class="n">Engine</span><span class="p">,</span> <span class="n">Events</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ignite.handlers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Checkpoint</span><span class="p">,</span> <span class="n">DiskSaver</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">model</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">lr_scheduler</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">data_loader</span> <span class="o">=</span> <span class="o">...</span>

<span class="n">to_save</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;trainer&#39;</span><span class="p">:</span> <span class="n">trainer</span><span class="p">,</span> <span class="s1">&#39;model&#39;</span><span class="p">:</span> <span class="n">model</span><span class="p">,</span> <span class="s1">&#39;optimizer&#39;</span><span class="p">:</span> <span class="n">optimizer</span><span class="p">,</span> <span class="s1">&#39;lr_scheduler&#39;</span><span class="p">:</span> <span class="n">lr_scheduler</span><span class="p">}</span>
<span class="n">handler</span> <span class="o">=</span> <span class="n">Checkpoint</span><span class="p">(</span><span class="n">to_save</span><span class="p">,</span> <span class="n">DiskSaver</span><span class="p">(</span><span class="s1">&#39;/tmp/training&#39;</span><span class="p">,</span> <span class="n">create_dir</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">add_event_handler</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">,</span> <span class="n">handler</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">data_loader</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>ls<span class="w"> </span>/tmp/training
&gt;<span class="w"> </span><span class="s2">&quot;checkpoint_50000.pt&quot;</span>
</pre></div>
</div>
<p>We can then restore the training from the last checkpoint.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.handlers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Checkpoint</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">model</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">lr_scheduler</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">data_loader</span> <span class="o">=</span> <span class="o">...</span>

<span class="n">to_load</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;trainer&#39;</span><span class="p">:</span> <span class="n">trainer</span><span class="p">,</span> <span class="s1">&#39;model&#39;</span><span class="p">:</span> <span class="n">model</span><span class="p">,</span> <span class="s1">&#39;optimizer&#39;</span><span class="p">:</span> <span class="n">optimizer</span><span class="p">,</span> <span class="s1">&#39;lr_scheduler&#39;</span><span class="p">:</span> <span class="n">lr_scheduler</span><span class="p">}</span>
<span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">checkpoint_file</span><span class="p">)</span>
<span class="n">Checkpoint</span><span class="o">.</span><span class="n">load_objects</span><span class="p">(</span><span class="n">to_load</span><span class="o">=</span><span class="n">to_load</span><span class="p">,</span> <span class="n">checkpoint</span><span class="o">=</span><span class="n">checkpoint</span><span class="p">)</span>

<span class="n">trainer</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
<p>It is also possible to store checkpoints every N iterations and continue the training from one of these checkpoints, i.e
from iteration.</p>
<section id="dataflow-synchronization">
<h3>Dataflow synchronization<a class="headerlink" href="#dataflow-synchronization" title="Permalink to this heading">#</a></h3>
<p>Previous approach, however, does not synchronize the dataflow and the model does not see the same data samples when
resuming from a checkpoint. Therefore, training curves will not be exactly the same.</p>
<p>Ignite provides an option to control the dataflow by synchronizing random state on epochs. In this way, for a given
iteration/epoch the dataflow can be the same for a given seed. More precisely it is roughly looks like:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span> <span class="o">+</span> <span class="n">e</span><span class="p">)</span>
    <span class="n">do_single_epoch_iterations</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span>
</pre></div>
</div>
<p>In addition, if data provider is <cite>torch.utils.data.DataLoader</cite>, batch data indices can be made completely deterministic.
Here is a trivial example of usage:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ignite.engine</span><span class="w"> </span><span class="kn">import</span> <span class="n">DeterministicEngine</span><span class="p">,</span> <span class="n">Events</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ignite.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">manual_seed</span>


<span class="k">def</span><span class="w"> </span><span class="nf">random_train_data_loader</span><span class="p">(</span><span class="n">size</span><span class="p">):</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">print_train_data</span><span class="p">(</span><span class="n">engine</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
    <span class="n">i</span> <span class="o">=</span> <span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">iteration</span>
    <span class="n">e</span> <span class="o">=</span> <span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">epoch</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="n">e</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">batch</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">DeterministicEngine</span><span class="p">(</span><span class="n">print_train_data</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Original Run&quot;</span><span class="p">)</span>
<span class="n">manual_seed</span><span class="p">(</span><span class="mi">56</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">random_train_data_loader</span><span class="p">(</span><span class="mi">40</span><span class="p">),</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">epoch_length</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Resumed Run&quot;</span><span class="p">)</span>
<span class="c1"># Resume from 2nd epoch</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">({</span><span class="s2">&quot;epoch&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;epoch_length&quot;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="s2">&quot;max_epochs&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;rng_states&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">})</span>
<span class="n">manual_seed</span><span class="p">(</span><span class="mi">56</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">random_train_data_loader</span><span class="p">(</span><span class="mi">40</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Original Run
train 1 1 [31, 13, 3, 4]
train 1 2 [23, 18, 6, 16]
train 1 3 [10, 8, 33, 36]
train 1 4 [1, 37, 19, 9]
train 1 5 [20, 30, 14, 26]
train 2 6 [29, 35, 38, 34]
train 2 7 [7, 22, 12, 17]
train 2 8 [25, 21, 24, 15]
train 2 9 [39, 5, 2, 28]
train 2 10 [27, 11, 32, 0]
Resumed Run
train 2 6 [29, 35, 38, 34]
train 2 7 [7, 22, 12, 17]
train 2 8 [25, 21, 24, 15]
train 2 9 [39, 5, 2, 28]
train 2 10 [27, 11, 32, 0]
</pre></div>
</div>
<p>We can see that the data samples are exactly the same between original and resumed runs.</p>
<p>Complete examples that simulates a crash on a defined iteration and resumes the training from a checkpoint can be found
here:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/pytorch/ignite/tree/master/examples/mnist#training-save--resume">save/resume MNIST</a></p></li>
<li><p><a class="reference external" href="https://github.com/pytorch/ignite/tree/master/examples/contrib/cifar10#check-resume-training">save/resume Distributed CIFAR10</a></p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In case when input data is <cite>torch.utils.data.DataLoader</cite>, previous batches are skipped and the first provided batch
corresponds to the batch after the checkpoint iteration. Internally, while resuming, previous datapoint indices are just
skipped without fetching the data.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>However, while resuming from iteration, random data augmentations are not synchronized in the middle of the epoch and
thus batches remaining until the end of the epoch can be different of those from the initial run.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>However, please, keep in mind that there can be an issue with dataflow synchronization on every epoch
if user‚Äôs handler synchronizes the random state, for example, by calling periodically <cite>torch.manual_seed(seed)</cite> during
the run. This can have an impact on the dataflow:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">random_train_data_generator</span><span class="p">():</span>
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="k">yield</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">))</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">DeterministicEngine</span><span class="p">(</span><span class="n">print_train_data</span><span class="p">)</span>

<span class="nd">@trainer</span><span class="o">.</span><span class="n">on</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">(</span><span class="n">every</span><span class="o">=</span><span class="mi">3</span><span class="p">))</span>
<span class="k">def</span><span class="w"> </span><span class="nf">user_handler</span><span class="p">(</span><span class="n">_</span><span class="p">):</span>
    <span class="c1"># handler synchronizes the random state</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="n">trainer</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">random_train_data_generator</span><span class="p">(),</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">epoch_length</span><span class="o">=</span><span class="mi">5</span><span class="p">);</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>train 1 1 [32]
train 1 2 [29]
train 1 3 [40]
train 1 4 [3]  &lt;---
train 1 5 [22]
train 2 6 [77]
train 2 7 [3]  &lt;---
train 2 8 [22]
train 2 9 [77]
train 2 10 [3] &lt;---
train 3 11 [22]
train 3 12 [77]
train 3 13 [3] &lt;---
train 3 14 [22]
train 3 15 [77]
</pre></div>
</div>
<p>Initially, the function <cite>random_train_data_generator()</cite> generates randomly data batches using the random state set
up by <cite>trainer</cite>. This is intended behaviour until <cite>user_handler()</cite> is called.
After <cite>user_handler()</cite> execution, random state is altered and thus <cite>random_train_data_generator()</cite> will produce
random batches based on altered random state.</p>
<p>We provide helper decorator <a class="reference internal" href="engine.html#ignite.engine.deterministic.keep_random_state" title="ignite.engine.deterministic.keep_random_state"><code class="xref py py-meth docutils literal notranslate"><span class="pre">keep_random_state()</span></code></a> to save and restore random states for
<cite>torch</cite>, <cite>numpy</cite> and <cite>random</cite>. Therefore, we can deal with described issue using this decorator:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.engine.deterministic</span><span class="w"> </span><span class="kn">import</span> <span class="n">keep_random_state</span>

<span class="nd">@trainer</span><span class="o">.</span><span class="n">on</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">(</span><span class="n">every</span><span class="o">=</span><span class="mi">3</span><span class="p">))</span>
<span class="nd">@keep_random_state</span>
<span class="k">def</span><span class="w"> </span><span class="nf">user_handler</span><span class="p">(</span><span class="n">_</span><span class="p">):</span>
    <span class="c1"># handler synchronizes the random state</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
</section>
</section>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="quickstart.html" class="btn btn-neutral float-right" title="Quickstart" accesskey="n" rel="next">Next
          <img src="_static/images/chevron-right-orange.svg" alt="right arrow" class="next-page">
        </a>
      
      
        <a href="index.html" class="btn btn-neutral" title="Ignite Your Networks!" accesskey="p" rel="prev">
          <img src="_static/images/chevron-right-orange.svg" alt="left arrow" class="previous-page"> Previous
        </a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <table>
      <tr>
        <td>
            <p>
                &copy; Copyright 2025, PyTorch-Ignite Contributors.
              Last updated on 05/01/2020, 12:14:09‚ÄØPM.
            </p>
            
              <div>
                Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
              </div>
          
        </td>
        <td>
            
              <div>
                <a href="https://www.netlify.com" target="_blank" rel="noopener noreferrer">
                  <img
                  src="_static/img/netlify-light.svg"
                  alt="Deploys by Netlify"
                  width=114
                  height=51 />
                </a>
              </div>
            
        </td>
      </tr>
    </table>
  </div> 

</footer>
          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">Concepts</a><ul>
<li><a class="reference internal" href="#engine">Engine</a></li>
<li><a class="reference internal" href="#events-and-handlers">Events and Handlers</a><ul>
<li><a class="reference internal" href="#timeline-and-events">Timeline and events</a></li>
</ul>
</li>
<li><a class="reference internal" href="#state">State</a></li>
<li><a class="reference internal" href="#deterministic-training">Deterministic training</a></li>
<li><a class="reference internal" href="#resuming-the-training">Resuming the training</a><ul>
<li><a class="reference internal" href="#dataflow-synchronization">Dataflow synchronization</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  

     
       <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
         <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
         <script src="_static/jquery.js"></script>
         <script src="_static/underscore.js"></script>
         <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="_static/doctools.js"></script>
         <script src="_static/sphinx_highlight.js"></script>
         <script src="_static/clipboard.min.js"></script>
         <script src="_static/copybutton.js"></script>
         <script>let toggleHintShow = 'Show default setup';</script>
         <script>let toggleHintHide = 'Hide default setup';</script>
         <script>let toggleOpenOnPrint = 'true';</script>
         <script src="_static/togglebutton.js"></script>
         <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
         <script src="_static/design-tabs.js"></script>
     

  

  <script type="text/javascript" src="_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="_static/js/vendor/bootstrap.min.js"></script>
  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <!-- commented out for Ignite -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <!-- <div class="container">
      <div class="row">
        <div class="text-center col-md-4">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/ignite/index.html">View Docs</a>
        </div>

        <div class="text-center col-md-4">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="">View Tutorials</a>
        </div>

        <div class="text-center col-md-4">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="">View Resources</a>
        </div>
      </div>
    </div> -->
  </div>

  <!-- <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch-ignite.ai" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch-ignite.ai">PyTorch</a></li>
            <li><a href="">Get Started</a></li>
            <li><a href="">Features</a></li>
            <li><a href="">Ecosystem</a></li>
            <li><a href="">Blog</a></li>
            <li><a href="">Resources</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="">Support</a></li>
            <li><a href="">Tutorials</a></li>
            <li><a href="https://pytorch.org/ignite/index.html">Docs</a></li>
            <li><a href="" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/ignite/issues" target="_blank">Github Issues</a></li>
            <li><a href="" target="_blank">Slack</a></li>
            <li><a href="https://github.com/pytorch/ignite/blob/master/CONTRIBUTING.md" target="_blank">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Follow Us</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>    <!~~ real people should not fill this in and expect good things - do not remove this or risk form bot signups ~~>

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="" target="_blank" class="facebook"></a>
            <a href="" target="_blank" class="twitter"></a>
          </div>
        </div>
      </div>
    </div>
  </footer> -->


  <!-- end of commented out for Ignite -->

  <!-- <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook‚Äôs Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="_static/images/pytorch-x.svg">
  </div>
</div> -->

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->
  <!--
  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch-ignite.ai" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="#">Get Started</a>
          </li>

          <li>
            <a href="#">Features</a>
          </li>

          <li>
            <a href="#">Ecosystem</a>
          </li>

          <li>
            <a href="">Blog</a>
          </li>

          <li>
            <a href="">Tutorials</a>
          </li>

          <li>
            <a href="https://pytorch.org/ignite/index.html">Docs</a>
          </li>

          <li>
            <a href="">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/ignite">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>
  -->
  <!-- End Mobile Menu -->

  <script type="text/javascript" src="_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    var collapsedSections = []
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
  <script src="https://cdn.jsdelivr.net/npm/@docsearch/js@3"></script>
  <script type="text/javascript">
  let VERSION
  if ('v0.4rc.0.post1'.startsWith('v')) {
    VERSION = 'v0.4rc.0.post1'
  } else {
    VERSION = 'master'
  }
  docsearch({
    container: '#docsearch',
    appId: '7EWYE1JCT3',
    apiKey: '841e93e60c16975ba1bd8c7c716eed82',
    indexName: 'pytorch-ignite',
    placeholder: 'Search PyTorch-Ignite docs',
    searchParameters: {
      facetFilters: [`version:${VERSION}`, 'tags:API-reference'],
    }
  });
  </script>
</body>
</html>