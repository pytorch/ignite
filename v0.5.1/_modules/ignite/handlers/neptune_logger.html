



<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="author" content="PyTorch-Ignite Contributors">
  <meta name="creator" content="PyTorch-Ignite Contributors">
  <meta name="publisher" content="PyTorch-Ignite Contributors">
  <meta name="generator" content="Sphinx 5.3.0">
  <meta name="description" content="High-level library to help with training and evaluating neural networks in PyTorch flexibly and transparently.">
  <meta name="keywords" content="pytorch, pytorch ignite, ignite, engine, events, handlers, metrics">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="theme-color" content="#ee4c2c">

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@pytorch_ignite">
  <meta name="twitter:creator" content="@pytorch_ignite">
  <meta name="twitter:description" content="High-level library to help with training and evaluating neural networks in PyTorch flexibly and transparently.">
  <meta name="twitter:title" content="ignite.handlers.neptune_logger &mdash; PyTorch-Ignite v0.5.1 Documentation">
  <meta name="twitter:image" content="https://raw.githubusercontent.com/pytorch/ignite/master/assets/logo/ignite_logo.png">
  <meta name="twitter:image:alt" content="PyTorch-Ignite logo">

  <meta property="og:title" content="ignite.handlers.neptune_logger &mdash; PyTorch-Ignite v0.5.1 Documentation">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://pytorch.org/ignite/">
  <meta property="og:site_name" content="PyTorch-Ignite">
  <meta property="og:image" content="https://raw.githubusercontent.com/pytorch/ignite/master/assets/logo/ignite_logo.png">
  <meta property="og:image:alt" content="PyTorch-Ignite logo">
  <meta property="og:description" content="High-level library to help with training and evaluating neural networks in PyTorch flexibly and transparently.">

  <link rel="preconnect" href="https://BH4D9OD16A-dsn.algolia.net" crossorigin />

  
  <title>ignite.handlers.neptune_logger &mdash; PyTorch-Ignite v0.5.1 Documentation</title>
  

  
  
    <link rel="shortcut icon" type="image/svg+xml" href="../../../_static/ignite_logomark.svg"/>
  
  
  
    <link rel="canonical" href="https://pytorch.org/ignite/_modules/ignite/handlers/neptune_logger.html"/>
  

  

  
  
    

  

  <link rel="preload" href="../../../_static/css/theme.css" as="style" />
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" /> -->
  <link rel="preload" href="../../../_static/pygments.css" as="style" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="preload" href="../../../_static/css/theme.css" as="style" />
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="preload" href="../../../_static/copybutton.css" as="style" />
  <link rel="stylesheet" href="../../../_static/copybutton.css" type="text/css" />
  <link rel="preload" href="../../../_static/togglebutton.css" as="style" />
  <link rel="stylesheet" href="../../../_static/togglebutton.css" type="text/css" />
  <link rel="preload" href="../../../_static/banner.css" as="style" />
  <link rel="stylesheet" href="../../../_static/banner.css" type="text/css" />
  <link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.css" as="style" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.css" type="text/css" />
  <link rel="preload" href="../../../_static/katex-math.css" as="style" />
  <link rel="stylesheet" href="../../../_static/katex-math.css" type="text/css" />
  <link rel="preload" href="../../../_static/sphinx-design.5ea377869091fd0449014c60fc090103.min.css" as="style" />
  <link rel="stylesheet" href="../../../_static/sphinx-design.5ea377869091fd0449014c60fc090103.min.css" type="text/css" />
    <link rel="preload" href="../../../_static/css/ignite_theme.css" as="style" />
    <link rel="stylesheet" href="../../../_static/css/ignite_theme.css" type="text/css" />
    <link rel="preload" href="https://cdn.jsdelivr.net/npm/@docsearch/css@3" as="style" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@docsearch/css@3" type="text/css" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 

  <!-- katex links / this needs to be loaded before fonts.html -->

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/katex.min.css" crossorigin="anonymous">
<script async src="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/katex.min.js" crossorigin="anonymous"></script>

<!-- Preload the theme fonts -->

<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/IBMPlexMono/IBMPlexMono-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-5FELLLFHCP"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-5FELLLFHCP');
  </script>
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">

    <a class="header-logo" href="/ignite" aria-label="PyTorch-Ignite"></a>

    <div class="header-container">

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch-ignite.ai/tutorials/beginner/01-getting-started/">Quickstart</a>
          </li>

          <li>
            <a href="https://pytorch-ignite.ai/concepts/">Concepts</a>
          </li>

          <!-- <li>
            <a href="https://pytorch-ignite.ai/tutorials/beginner/01-getting-started/#complete-code">Examples</a>
          </li> -->

          <li>
            <a href="https://pytorch-ignite.ai/how-to-guides/">FAQ</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/ignite" target="_blank" rel="noopener noreferrer">GitHub</a>
          </li>

          <li>
            <a href="https://pytorch-ignite.ai/about/community/">About us</a>
          </li>

          <li>
            <a href="https://pytorch-ignite.ai">‚ä≥ pytorch-ignite.ai</a>
          </li>


        </ul>
      </div>

      <!-- <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a> -->
    </div>

  </div>
</div>


<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <div class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></div>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  v0.5.1
                </div>
              
            

            <div id="docsearch"></div>

            
          </div>

          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Package Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../engine.html">ignite.engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../handlers.html">ignite.handlers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../metrics.html">ignite.metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../distributed.html">ignite.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../exceptions.html">ignite.exceptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../utils.html">ignite.utils</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contrib Package Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../contrib/engines.html">ignite.contrib.engines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../contrib/metrics.html">ignite.contrib.metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../contrib/handlers.html">ignite.contrib.handlers</a></li>
</ul>

            
          
        </div>
      </div>

      <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
        <span class="fa fa-book"> Other Versions</span>
        v: v0.5.1
        <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
        <dl>
            <dt>Tags</dt>
            <dd><a href="../../../../v0.3.0/index.html">v0.3.0</a></dd>
            <dd><a href="../../../../v0.4.0.post1/index.html">v0.4.0.post1</a></dd>
            <dd><a href="../../../../v0.4.1/index.html">v0.4.1</a></dd>
            <dd><a href="../../../../v0.4.10/index.html">v0.4.10</a></dd>
            <dd><a href="../../../../v0.4.11/index.html">v0.4.11</a></dd>
            <dd><a href="../../../../v0.4.12/index.html">v0.4.12</a></dd>
            <dd><a href="../../../../v0.4.13/index.html">v0.4.13</a></dd>
            <dd><a href="../../../../v0.4.2/index.html">v0.4.2</a></dd>
            <dd><a href="../../../../v0.4.3/index.html">v0.4.3</a></dd>
            <dd><a href="../../../../v0.4.4.post1/index.html">v0.4.4.post1</a></dd>
            <dd><a href="../../../../v0.4.5/index.html">v0.4.5</a></dd>
            <dd><a href="../../../../v0.4.6/index.html">v0.4.6</a></dd>
            <dd><a href="../../../../v0.4.7/index.html">v0.4.7</a></dd>
            <dd><a href="../../../../v0.4.8/index.html">v0.4.8</a></dd>
            <dd><a href="../../../../v0.4.9/index.html">v0.4.9</a></dd>
            <dd><a href="../../../../v0.4rc.0.post1/index.html">v0.4rc.0.post1</a></dd>
            <dd><a href="../../../../v0.5.0.post2/index.html">v0.5.0.post2</a></dd>
            <dd><a href="neptune_logger.html">v0.5.1</a></dd>
            <dd><a href="../../../../v0.5.2/index.html">v0.5.2</a></dd>
            <dd><a href="../../../../v0.5.3/index.html">v0.5.3</a></dd>
        </dl>
        <dl>
            <dt>Branches</dt>
            <dd><a href="../../../../master/index.html">master</a></dd>
        </dl>
    </div>
</div>

    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../../index.html">Module code</a> &gt;</li>
        
      <li>ignite.handlers.neptune_logger</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for ignite.handlers.neptune_logger</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;Neptune logger and its helper handlers.&quot;&quot;&quot;</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">tempfile</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Mapping</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Optimizer</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">ignite.distributed</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">idist</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">ignite.engine</span><span class="w"> </span><span class="kn">import</span> <span class="n">Engine</span><span class="p">,</span> <span class="n">Events</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ignite.handlers.base_logger</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">BaseLogger</span><span class="p">,</span>
    <span class="n">BaseOptimizerParamsHandler</span><span class="p">,</span>
    <span class="n">BaseOutputHandler</span><span class="p">,</span>
    <span class="n">BaseWeightsScalarHandler</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ignite.handlers.checkpoint</span><span class="w"> </span><span class="kn">import</span> <span class="n">BaseSaveHandler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ignite.handlers.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">global_step_from_engine</span>  <span class="c1"># noqa</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;NeptuneLogger&quot;</span><span class="p">,</span>
    <span class="s2">&quot;NeptuneSaver&quot;</span><span class="p">,</span>
    <span class="s2">&quot;OptimizerParamsHandler&quot;</span><span class="p">,</span>
    <span class="s2">&quot;OutputHandler&quot;</span><span class="p">,</span>
    <span class="s2">&quot;WeightsScalarHandler&quot;</span><span class="p">,</span>
    <span class="s2">&quot;GradsScalarHandler&quot;</span><span class="p">,</span>
    <span class="s2">&quot;global_step_from_engine&quot;</span><span class="p">,</span>
<span class="p">]</span>

<span class="n">_INTEGRATION_VERSION_KEY</span> <span class="o">=</span> <span class="s2">&quot;source_code/integrations/neptune-pytorch-ignite&quot;</span>


<div class="viewcode-block" id="NeptuneLogger"><a class="viewcode-back" href="../../../generated/ignite.handlers.neptune_logger.html#ignite.handlers.neptune_logger.NeptuneLogger">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">NeptuneLogger</span><span class="p">(</span><span class="n">BaseLogger</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    `Neptune &lt;https://neptune.ai/&gt;`_ handler to log metrics, model/optimizer parameters and gradients during training</span>
<span class="sd">    and validation. It can also log model checkpoints to Neptune.</span>

<span class="sd">    .. code-block:: bash</span>

<span class="sd">        pip install neptune</span>

<span class="sd">    Args:</span>
<span class="sd">        api_token: Neptune API token, found on https://neptune.ai -&gt; User menu -&gt; &quot;Get your API token&quot;.</span>
<span class="sd">           If None, the value of the NEPTUNE_API_TOKEN environment variable is used. To keep your token</span>
<span class="sd">           secure, you should set it to the environment variable rather than including it in your code.</span>
<span class="sd">        project: Name of a Neptune project, in the form &quot;workspace-name/project-name&quot;.</span>
<span class="sd">           For example &quot;tom/mnist-classification&quot;.</span>
<span class="sd">           If None, the value of the NEPTUNE_PROJECT environment variable is used.</span>
<span class="sd">        **kwargs: Other arguments to be passed to the `init_run()` function.</span>

<span class="sd">    Examples:</span>
<span class="sd">        .. code-block:: python</span>

<span class="sd">            from ignite.handlers.neptune_logger import *</span>

<span class="sd">            # Create a logger</span>
<span class="sd">            # Note: We are using the API token for anonymous logging. You can pass your own token, or save it as an</span>
<span class="sd">            # environment variable and leave out the api_token argument.</span>

<span class="sd">            npt_logger = NeptuneLogger(</span>
<span class="sd">                api_token=&quot;ANONYMOUS&quot;,</span>
<span class="sd">                project=&quot;common/pytorch-ignite-integration&quot;,</span>
<span class="sd">                name=&quot;cnn-mnist&quot;,  # Optional,</span>
<span class="sd">                tags=[&quot;pytorch-ignite&quot;, &quot;minst&quot;],  # Optional</span>
<span class="sd">            )</span>

<span class="sd">            # Attach the logger to the trainer to log training loss at each iteration.</span>
<span class="sd">            npt_logger.attach_output_handler(</span>
<span class="sd">                trainer,</span>
<span class="sd">                event_name=Events.ITERATION_COMPLETED,</span>
<span class="sd">                tag=&quot;training&quot;,</span>
<span class="sd">                output_transform=lambda loss: {&quot;loss&quot;: loss},</span>
<span class="sd">            )</span>

<span class="sd">            # Attach the logger to the evaluator on the training dataset and log NLL</span>
<span class="sd">            # and accuracy metrics after each epoch.</span>
<span class="sd">            # We set up `global_step_transform=global_step_from_engine(trainer)` to take the epoch</span>
<span class="sd">            # of the `trainer` instead of `train_evaluator`.</span>
<span class="sd">            npt_logger.attach_output_handler(</span>
<span class="sd">                train_evaluator,</span>
<span class="sd">                event_name=Events.EPOCH_COMPLETED,</span>
<span class="sd">                tag=&quot;training&quot;,</span>
<span class="sd">                metric_names=[&quot;nll&quot;, &quot;accuracy&quot;],</span>
<span class="sd">                global_step_transform=global_step_from_engine(trainer),</span>
<span class="sd">            )</span>

<span class="sd">            # Attach the logger to the evaluator on the validation dataset and log NLL and accuracy metrics after</span>
<span class="sd">            # each epoch. We set up `global_step_transform=global_step_from_engine(trainer)` to take the epoch of the</span>
<span class="sd">            # `trainer` instead of `evaluator`.</span>
<span class="sd">            npt_logger.attach_output_handler(</span>
<span class="sd">                evaluator,</span>
<span class="sd">                event_name=Events.EPOCH_COMPLETED,</span>
<span class="sd">                tag=&quot;validation&quot;,</span>
<span class="sd">                metric_names=[&quot;nll&quot;, &quot;accuracy&quot;],</span>
<span class="sd">                global_step_transform=global_step_from_engine(trainer),</span>
<span class="sd">            )</span>

<span class="sd">            # Attach the logger to the trainer to log optimizer parameters, such as learning rate at each iteration.</span>
<span class="sd">            npt_logger.attach_opt_params_handler(</span>
<span class="sd">                trainer,</span>
<span class="sd">                event_name=Events.ITERATION_STARTED,</span>
<span class="sd">                optimizer=optimizer,</span>
<span class="sd">                param_name=&quot;lr&quot;,  # optional</span>
<span class="sd">            )</span>

<span class="sd">            # Attach the logger to the trainer to log model&#39;s weights norm after each iteration.</span>
<span class="sd">            npt_logger.attach(</span>
<span class="sd">                trainer,</span>
<span class="sd">                event_name=Events.ITERATION_COMPLETED,</span>
<span class="sd">                log_handler=WeightsScalarHandler(model),</span>
<span class="sd">            )</span>

<span class="sd">        Explore runs with Neptune tracking here:</span>
<span class="sd">        https://app.neptune.ai/o/common/org/pytorch-ignite-integration/</span>

<span class="sd">        You can also save model checkpoints to a Neptune:</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            from ignite.handlers import Checkpoint</span>


<span class="sd">            def score_function(engine):</span>
<span class="sd">                return engine.state.metrics[&quot;accuracy&quot;]</span>


<span class="sd">            to_save = {&quot;model&quot;: model}</span>
<span class="sd">            handler = Checkpoint(</span>
<span class="sd">                to_save,</span>
<span class="sd">                NeptuneSaver(npt_logger), n_saved=2,</span>
<span class="sd">                filename_prefix=&quot;best&quot;,</span>
<span class="sd">                score_function=score_function,</span>
<span class="sd">                score_name=&quot;validation_accuracy&quot;,</span>
<span class="sd">                global_step_transform=global_step_from_engine(trainer),</span>
<span class="sd">            )</span>
<span class="sd">            validation_evaluator.add_event_handler(Events.COMPLETED, handler)</span>

<span class="sd">        It is also possible to use the logger as a context manager:</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            from ignite.handlers.neptune_logger import *</span>

<span class="sd">            with NeptuneLogger() as npt_logger:</span>
<span class="sd">                trainer = Engine(update_fn)</span>
<span class="sd">                # Attach the logger to the trainer to log training loss at each iteration</span>
<span class="sd">                npt_logger.attach_output_handler(</span>
<span class="sd">                    trainer,</span>
<span class="sd">                    event_name=Events.ITERATION_COMPLETED,</span>
<span class="sd">                    tag=&quot;training&quot;,</span>
<span class="sd">                    output_transform=lambda loss: {&quot;loss&quot;: loss},</span>
<span class="sd">                )</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__getattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attr</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">experiment</span><span class="p">,</span> <span class="n">attr</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">experiment</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__setitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">val</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">experiment</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">val</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">api_token</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">project</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="c1"># neptune-client&lt;1.0.0 package structure</span>
                <span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
                    <span class="c1"># ignore the deprecation warnings</span>
                    <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
                    <span class="kn">import</span><span class="w"> </span><span class="nn">neptune.new</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">neptune</span>
            <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
                <span class="c1"># neptune&gt;=1.0.0 package structure</span>
                <span class="kn">import</span><span class="w"> </span><span class="nn">neptune</span>
        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ModuleNotFoundError</span><span class="p">(</span>
                <span class="s2">&quot;This contrib module requires the Neptune client library to be installed. &quot;</span>
                <span class="s2">&quot;Install neptune with the command: </span><span class="se">\n</span><span class="s2"> pip install neptune </span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="n">run</span> <span class="o">=</span> <span class="n">neptune</span><span class="o">.</span><span class="n">init_run</span><span class="p">(</span>
            <span class="n">api_token</span><span class="o">=</span><span class="n">api_token</span><span class="p">,</span>
            <span class="n">project</span><span class="o">=</span><span class="n">project</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">ignite</span><span class="w"> </span><span class="kn">import</span> <span class="n">__version__</span>

        <span class="n">run</span><span class="p">[</span><span class="n">_INTEGRATION_VERSION_KEY</span><span class="p">]</span> <span class="o">=</span> <span class="n">__version__</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">experiment</span> <span class="o">=</span> <span class="n">run</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">close</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">experiment</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_create_output_handler</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;OutputHandler&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">OutputHandler</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_create_opt_params_handler</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;OptimizerParamsHandler&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">OptimizerParamsHandler</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>


<div class="viewcode-block" id="OutputHandler"><a class="viewcode-back" href="../../../generated/ignite.handlers.neptune_logger.html#ignite.handlers.neptune_logger.OutputHandler">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">OutputHandler</span><span class="p">(</span><span class="n">BaseOutputHandler</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Helper handler to log engine&#39;s output and/or metrics.</span>

<span class="sd">    Args:</span>
<span class="sd">        tag: common title for all produced plots. For example, &quot;training&quot;</span>
<span class="sd">        metric_names: list of metric names to plot or a string &quot;all&quot; to plot all available</span>
<span class="sd">            metrics.</span>
<span class="sd">        output_transform: output transform function to prepare `engine.state.output` as a number.</span>
<span class="sd">            For example, `output_transform = lambda output: output`</span>
<span class="sd">            This function can also return a dictionary, e.g `{&quot;loss&quot;: loss1, &quot;another_loss&quot;: loss2}` to label the plot</span>
<span class="sd">            with corresponding keys.</span>
<span class="sd">        global_step_transform: global step transform function to output a desired global step.</span>
<span class="sd">            Input of the function is `(engine, event_name)`. Output of function should be an integer.</span>
<span class="sd">            Default is None, global_step based on attached engine. If provided,</span>
<span class="sd">            uses function output as global_step. To setup global step from another engine, please use</span>
<span class="sd">            :meth:`~ignite.handlers.neptune_logger.global_step_from_engine`.</span>
<span class="sd">        state_attributes: list of attributes of the ``trainer.state`` to plot.</span>

<span class="sd">    Examples:</span>
<span class="sd">        .. code-block:: python</span>

<span class="sd">            from ignite.handlers.neptune_logger import *</span>

<span class="sd">            # Create a logger</span>
<span class="sd">            # We are using the api_token for the anonymous user neptuner but you can use your own.</span>

<span class="sd">            npt_logger = NeptuneLogger(</span>
<span class="sd">                api_token=&quot;ANONYMOUS&quot;,</span>
<span class="sd">                project_name=&quot;shared/pytorch-ignite-integration&quot;,</span>
<span class="sd">                experiment_name=&quot;cnn-mnist&quot;, # Optional,</span>
<span class="sd">                params={&quot;max_epochs&quot;: 10}, # Optional,</span>
<span class="sd">                tags=[&quot;pytorch-ignite&quot;,&quot;minst&quot;] # Optional</span>
<span class="sd">            )</span>

<span class="sd">            # Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="sd">            # each epoch. We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch</span>
<span class="sd">            # of the `trainer`:</span>
<span class="sd">            npt_logger.attach(</span>
<span class="sd">                evaluator,</span>
<span class="sd">                log_handler=OutputHandler(</span>
<span class="sd">                    tag=&quot;validation&quot;,</span>
<span class="sd">                    metric_names=[&quot;nll&quot;, &quot;accuracy&quot;],</span>
<span class="sd">                    global_step_transform=global_step_from_engine(trainer)</span>
<span class="sd">                ),</span>
<span class="sd">                event_name=Events.EPOCH_COMPLETED</span>
<span class="sd">            )</span>
<span class="sd">            # or equivalently</span>
<span class="sd">            npt_logger.attach_output_handler(</span>
<span class="sd">                evaluator,</span>
<span class="sd">                event_name=Events.EPOCH_COMPLETED,</span>
<span class="sd">                tag=&quot;validation&quot;,</span>
<span class="sd">                metric_names=[&quot;nll&quot;, &quot;accuracy&quot;],</span>
<span class="sd">                global_step_transform=global_step_from_engine(trainer)</span>
<span class="sd">            )</span>

<span class="sd">        Another example, where model is evaluated every 500 iterations:</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            from ignite.handlers.neptune_logger import *</span>

<span class="sd">            @trainer.on(Events.ITERATION_COMPLETED(every=500))</span>
<span class="sd">            def evaluate(engine):</span>
<span class="sd">                evaluator.run(validation_set, max_epochs=1)</span>

<span class="sd">            # We are using the api_token for the anonymous user neptuner but you can use your own.</span>

<span class="sd">            npt_logger = NeptuneLogger(</span>
<span class="sd">                api_token=&quot;ANONYMOUS&quot;,</span>
<span class="sd">                project_name=&quot;shared/pytorch-ignite-integration&quot;,</span>
<span class="sd">                experiment_name=&quot;cnn-mnist&quot;, # Optional,</span>
<span class="sd">                params={&quot;max_epochs&quot;: 10}, # Optional,</span>
<span class="sd">                tags=[&quot;pytorch-ignite&quot;, &quot;minst&quot;] # Optional</span>
<span class="sd">            )</span>

<span class="sd">            def global_step_transform(*args, **kwargs):</span>
<span class="sd">                return trainer.state.iteration</span>

<span class="sd">            # Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="sd">            # every 500 iterations. Since evaluator engine does not have access to the training iteration, we</span>
<span class="sd">            # provide a global_step_transform to return the trainer.state.iteration for the global_step, each time</span>
<span class="sd">            # evaluator metrics are plotted on NeptuneML.</span>

<span class="sd">            npt_logger.attach_output_handler(</span>
<span class="sd">                evaluator,</span>
<span class="sd">                event_name=Events.EPOCH_COMPLETED,</span>
<span class="sd">                tag=&quot;validation&quot;,</span>
<span class="sd">                metrics=[&quot;nll&quot;, &quot;accuracy&quot;],</span>
<span class="sd">                global_step_transform=global_step_transform</span>
<span class="sd">            )</span>

<span class="sd">        Another example where the State Attributes ``trainer.state.alpha`` and ``trainer.state.beta``</span>
<span class="sd">        are also logged along with the NLL and Accuracy after each iteration:</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            npt_logger.attach_output_handler(</span>
<span class="sd">                trainer,</span>
<span class="sd">                event_name=Events.ITERATION_COMPLETED,</span>
<span class="sd">                tag=&quot;training&quot;,</span>
<span class="sd">                metrics=[&quot;nll&quot;, &quot;accuracy&quot;],</span>
<span class="sd">                state_attributes=[&quot;alpha&quot;, &quot;beta&quot;],</span>
<span class="sd">            )</span>

<span class="sd">        Example of `global_step_transform`:</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            def global_step_transform(engine, event_name):</span>
<span class="sd">                return engine.state.get_event_attrib_value(event_name)</span>

<span class="sd">    .. versionchanged:: 0.4.7</span>
<span class="sd">        accepts an optional list of `state_attributes`</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tag</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">metric_names</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_transform</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">global_step_transform</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Engine</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Events</span><span class="p">]],</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">state_attributes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">OutputHandler</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">tag</span><span class="p">,</span> <span class="n">metric_names</span><span class="p">,</span> <span class="n">output_transform</span><span class="p">,</span> <span class="n">global_step_transform</span><span class="p">,</span> <span class="n">state_attributes</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">engine</span><span class="p">:</span> <span class="n">Engine</span><span class="p">,</span> <span class="n">logger</span><span class="p">:</span> <span class="n">NeptuneLogger</span><span class="p">,</span> <span class="n">event_name</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Events</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">logger</span><span class="p">,</span> <span class="n">NeptuneLogger</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Handler OutputHandler works only with NeptuneLogger&quot;</span><span class="p">)</span>

        <span class="n">metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_setup_output_metrics_state_attrs</span><span class="p">(</span><span class="n">engine</span><span class="p">,</span> <span class="n">key_tuple</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="n">global_step</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_step_transform</span><span class="p">(</span><span class="n">engine</span><span class="p">,</span> <span class="n">event_name</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">global_step</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;global_step must be int, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">global_step</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="s2">&quot; Please check the output of global_step_transform.&quot;</span>
            <span class="p">)</span>

        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">metrics</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">logger</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">global_step</span><span class="p">)</span></div>


<div class="viewcode-block" id="OptimizerParamsHandler"><a class="viewcode-back" href="../../../generated/ignite.handlers.neptune_logger.html#ignite.handlers.neptune_logger.OptimizerParamsHandler">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">OptimizerParamsHandler</span><span class="p">(</span><span class="n">BaseOptimizerParamsHandler</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Helper handler to log optimizer parameters</span>

<span class="sd">    Args:</span>
<span class="sd">        optimizer: torch optimizer or any object with attribute ``param_groups``</span>
<span class="sd">            as a sequence.</span>
<span class="sd">        param_name: parameter name</span>
<span class="sd">        tag: common title for all produced plots. For example, &quot;generator&quot;</span>

<span class="sd">    Examples:</span>
<span class="sd">        .. code-block:: python</span>

<span class="sd">            from ignite.handlers.neptune_logger import *</span>

<span class="sd">            # Create a logger</span>
<span class="sd">            # We are using the api_token for the anonymous user neptuner but you can use your own.</span>

<span class="sd">            npt_logger = NeptuneLogger(</span>
<span class="sd">                api_token=&quot;ANONYMOUS&quot;,</span>
<span class="sd">                project_name=&quot;shared/pytorch-ignite-integration&quot;,</span>
<span class="sd">                experiment_name=&quot;cnn-mnist&quot;, # Optional,</span>
<span class="sd">                params={&quot;max_epochs&quot;: 10}, # Optional,</span>
<span class="sd">                tags=[&quot;pytorch-ignite&quot;,&quot;minst&quot;] # Optional</span>
<span class="sd">            )</span>

<span class="sd">            # Attach the logger to the trainer to log optimizer&#39;s parameters, e.g. learning rate at each iteration</span>
<span class="sd">            npt_logger.attach(</span>
<span class="sd">                trainer,</span>
<span class="sd">                log_handler=OptimizerParamsHandler(optimizer),</span>
<span class="sd">                event_name=Events.ITERATION_STARTED</span>
<span class="sd">            )</span>
<span class="sd">            # or equivalently</span>
<span class="sd">            npt_logger.attach_opt_params_handler(</span>
<span class="sd">                trainer,</span>
<span class="sd">                event_name=Events.ITERATION_STARTED,</span>
<span class="sd">                optimizer=optimizer</span>
<span class="sd">            )</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">:</span> <span class="n">Optimizer</span><span class="p">,</span> <span class="n">param_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="n">tag</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">OptimizerParamsHandler</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">param_name</span><span class="p">,</span> <span class="n">tag</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">engine</span><span class="p">:</span> <span class="n">Engine</span><span class="p">,</span> <span class="n">logger</span><span class="p">:</span> <span class="n">NeptuneLogger</span><span class="p">,</span> <span class="n">event_name</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Events</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">logger</span><span class="p">,</span> <span class="n">NeptuneLogger</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Handler OptimizerParamsHandler works only with NeptuneLogger&quot;</span><span class="p">)</span>

        <span class="n">global_step</span> <span class="o">=</span> <span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">get_event_attrib_value</span><span class="p">(</span><span class="n">event_name</span><span class="p">)</span>
        <span class="n">tag_prefix</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">tag</span><span class="si">}</span><span class="s2">/&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tag</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span>
        <span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">tag_prefix</span><span class="si">}{</span><span class="bp">self</span><span class="o">.</span><span class="n">param_name</span><span class="si">}</span><span class="s2">/group_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">param_group</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">param_name</span><span class="p">])</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">param_group</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">)</span>
        <span class="p">}</span>

        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">params</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">logger</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">global_step</span><span class="p">)</span></div>


<div class="viewcode-block" id="WeightsScalarHandler"><a class="viewcode-back" href="../../../generated/ignite.handlers.neptune_logger.html#ignite.handlers.neptune_logger.WeightsScalarHandler">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">WeightsScalarHandler</span><span class="p">(</span><span class="n">BaseWeightsScalarHandler</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Helper handler to log model&#39;s weights as scalars.</span>
<span class="sd">    Handler, upon construction, iterates over named parameters of the model and keep</span>
<span class="sd">    reference to ones permitted by `whitelist`. Then at every call, applies</span>
<span class="sd">    reduction function to each parameter, produces a scalar and logs it.</span>

<span class="sd">    Args:</span>
<span class="sd">        model: model to log weights</span>
<span class="sd">        reduction: function to reduce parameters into scalar</span>
<span class="sd">        tag: common title for all produced plots. For example, &quot;generator&quot;</span>
<span class="sd">        whitelist: specific weights to log. Should be list of model&#39;s submodules</span>
<span class="sd">            or parameters names, or a callable which gets weight along with its name</span>
<span class="sd">            and determines if it should be logged. Names should be fully-qualified.</span>
<span class="sd">            For more information please refer to `PyTorch docs</span>
<span class="sd">            &lt;https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.get_submodule&gt;`_.</span>
<span class="sd">            If not given, all of model&#39;s weights are logged.</span>

<span class="sd">    Examples:</span>
<span class="sd">        .. code-block:: python</span>

<span class="sd">            from ignite.handlers.neptune_logger import *</span>

<span class="sd">            # Create a logger</span>
<span class="sd">            # We are using the api_token for the anonymous user neptuner but you can use your own.</span>

<span class="sd">            npt_logger = NeptuneLogger(</span>
<span class="sd">                api_token=&quot;ANONYMOUS&quot;,</span>
<span class="sd">                project_name=&quot;shared/pytorch-ignite-integration&quot;,</span>
<span class="sd">                experiment_name=&quot;cnn-mnist&quot;, # Optional,</span>
<span class="sd">                params={&quot;max_epochs&quot;: 10}, # Optional,</span>
<span class="sd">                tags=[&quot;pytorch-ignite&quot;,&quot;minst&quot;] # Optional</span>
<span class="sd">            )</span>

<span class="sd">            # Attach the logger to the trainer to log model&#39;s weights norm after each iteration</span>
<span class="sd">            npt_logger.attach(</span>
<span class="sd">                trainer,</span>
<span class="sd">                event_name=Events.ITERATION_COMPLETED,</span>
<span class="sd">                log_handler=WeightsScalarHandler(model, reduction=torch.norm)</span>
<span class="sd">            )</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            from ignite.handlers.neptune_logger import *</span>

<span class="sd">            npt_logger = NeptuneLogger(</span>
<span class="sd">                api_token=&quot;ANONYMOUS&quot;,</span>
<span class="sd">                project_name=&quot;shared/pytorch-ignite-integration&quot;,</span>
<span class="sd">                experiment_name=&quot;cnn-mnist&quot;, # Optional,</span>
<span class="sd">                params={&quot;max_epochs&quot;: 10}, # Optional,</span>
<span class="sd">                tags=[&quot;pytorch-ignite&quot;,&quot;minst&quot;] # Optional</span>
<span class="sd">            )</span>

<span class="sd">            # Log only `fc` weights</span>
<span class="sd">            npt_logger.attach(</span>
<span class="sd">                trainer,</span>
<span class="sd">                event_name=Events.ITERATION_COMPLETED,</span>
<span class="sd">                log_handler=WeightsScalarHandler(</span>
<span class="sd">                    model,</span>
<span class="sd">                    whitelist=[&#39;fc&#39;]</span>
<span class="sd">                )</span>
<span class="sd">            )</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            from ignite.handlers.neptune_logger import *</span>

<span class="sd">            npt_logger = NeptuneLogger(</span>
<span class="sd">                api_token=&quot;ANONYMOUS&quot;,</span>
<span class="sd">                project_name=&quot;shared/pytorch-ignite-integration&quot;,</span>
<span class="sd">                experiment_name=&quot;cnn-mnist&quot;, # Optional,</span>
<span class="sd">                params={&quot;max_epochs&quot;: 10}, # Optional,</span>
<span class="sd">                tags=[&quot;pytorch-ignite&quot;,&quot;minst&quot;] # Optional</span>
<span class="sd">            )</span>

<span class="sd">            # Log weights which have `bias` in their names</span>
<span class="sd">            def has_bias_in_name(n, p):</span>
<span class="sd">                return &#39;bias&#39; in n</span>

<span class="sd">            npt_logger.attach(</span>
<span class="sd">                trainer,</span>
<span class="sd">                event_name=Events.ITERATION_COMPLETED,</span>
<span class="sd">                log_handler=WeightsScalarHandler(model, whitelist=has_bias_in_name)</span>
<span class="sd">            )</span>

<span class="sd">    ..  versionchanged:: 0.4.9</span>
<span class="sd">        optional argument `whitelist` added.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">engine</span><span class="p">:</span> <span class="n">Engine</span><span class="p">,</span> <span class="n">logger</span><span class="p">:</span> <span class="n">NeptuneLogger</span><span class="p">,</span> <span class="n">event_name</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Events</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">logger</span><span class="p">,</span> <span class="n">NeptuneLogger</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Handler WeightsScalarHandler works only with NeptuneLogger&quot;</span><span class="p">)</span>

        <span class="n">global_step</span> <span class="o">=</span> <span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">get_event_attrib_value</span><span class="p">(</span><span class="n">event_name</span><span class="p">)</span>
        <span class="n">tag_prefix</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">tag</span><span class="si">}</span><span class="s2">/&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tag</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="n">name</span> <span class="o">=</span> <span class="n">name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="s2">&quot;/&quot;</span><span class="p">)</span>
            <span class="n">key</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">tag_prefix</span><span class="si">}</span><span class="s2">weights_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">reduction</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="n">logger</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reduction</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">data</span><span class="p">),</span> <span class="n">step</span><span class="o">=</span><span class="n">global_step</span><span class="p">)</span></div>


<div class="viewcode-block" id="GradsScalarHandler"><a class="viewcode-back" href="../../../generated/ignite.handlers.neptune_logger.html#ignite.handlers.neptune_logger.GradsScalarHandler">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">GradsScalarHandler</span><span class="p">(</span><span class="n">BaseWeightsScalarHandler</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Helper handler to log model&#39;s gradients as scalars.</span>
<span class="sd">    Handler, upon construction, iterates over named parameters of the model and keep</span>
<span class="sd">    reference to ones permitted by the `whitelist`. Then at every call, applies</span>
<span class="sd">    reduction function to each parameter&#39;s gradient, produces a scalar and logs it.</span>

<span class="sd">    Args:</span>
<span class="sd">        model: model to log weights</span>
<span class="sd">        reduction: function to reduce parameters into scalar</span>
<span class="sd">        tag: common title for all produced plots. For example, &quot;generator&quot;</span>
<span class="sd">        whitelist: specific gradients to log. Should be list of model&#39;s submodules</span>
<span class="sd">            or parameters names, or a callable which gets weight along with its name</span>
<span class="sd">            and determines if its gradient should be logged. Names should be</span>
<span class="sd">            fully-qualified. For more information please refer to `PyTorch docs</span>
<span class="sd">            &lt;https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.get_submodule&gt;`_.</span>
<span class="sd">            If not given, all of model&#39;s gradients are logged.</span>

<span class="sd">    Examples:</span>
<span class="sd">        .. code-block:: python</span>

<span class="sd">            from ignite.handlers.neptune_logger import *</span>

<span class="sd">            # Create a logger</span>
<span class="sd">            # We are using the api_token for the anonymous user neptuner but you can use your own.</span>

<span class="sd">            npt_logger = NeptuneLogger(</span>
<span class="sd">                api_token=&quot;ANONYMOUS&quot;,</span>
<span class="sd">                project_name=&quot;shared/pytorch-ignite-integration&quot;,</span>
<span class="sd">                experiment_name=&quot;cnn-mnist&quot;, # Optional,</span>
<span class="sd">                params={&quot;max_epochs&quot;: 10}, # Optional,</span>
<span class="sd">                tags=[&quot;pytorch-ignite&quot;,&quot;minst&quot;] # Optional</span>
<span class="sd">            )</span>

<span class="sd">            # Attach the logger to the trainer to log model&#39;s weights norm after each iteration</span>
<span class="sd">            npt_logger.attach(</span>
<span class="sd">                trainer,</span>
<span class="sd">                event_name=Events.ITERATION_COMPLETED,</span>
<span class="sd">                log_handler=GradsScalarHandler(model, reduction=torch.norm)</span>
<span class="sd">            )</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            from ignite.handlers.neptune_logger import *</span>

<span class="sd">            npt_logger = NeptuneLogger(</span>
<span class="sd">                api_token=&quot;ANONYMOUS&quot;,</span>
<span class="sd">                project_name=&quot;shared/pytorch-ignite-integration&quot;,</span>
<span class="sd">                experiment_name=&quot;cnn-mnist&quot;, # Optional,</span>
<span class="sd">                params={&quot;max_epochs&quot;: 10}, # Optional,</span>
<span class="sd">                tags=[&quot;pytorch-ignite&quot;,&quot;minst&quot;] # Optional</span>
<span class="sd">            )</span>

<span class="sd">            # Log gradient of `base`</span>
<span class="sd">            npt_logger.attach(</span>
<span class="sd">                trainer,</span>
<span class="sd">                event_name=Events.ITERATION_COMPLETED,</span>
<span class="sd">                log_handler=GradsScalarHandler(</span>
<span class="sd">                    model,</span>
<span class="sd">                    reduction=torch.norm,</span>
<span class="sd">                    whitelist=[&#39;base&#39;]</span>
<span class="sd">                )</span>
<span class="sd">            )</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            from ignite.handlers.neptune_logger import *</span>

<span class="sd">            npt_logger = NeptuneLogger(</span>
<span class="sd">                api_token=&quot;ANONYMOUS&quot;,</span>
<span class="sd">                project_name=&quot;shared/pytorch-ignite-integration&quot;,</span>
<span class="sd">                experiment_name=&quot;cnn-mnist&quot;, # Optional,</span>
<span class="sd">                params={&quot;max_epochs&quot;: 10}, # Optional,</span>
<span class="sd">                tags=[&quot;pytorch-ignite&quot;,&quot;minst&quot;] # Optional</span>
<span class="sd">            )</span>

<span class="sd">            # Log gradient of weights which belong to a `fc` layer</span>
<span class="sd">            def is_in_fc_layer(n, p):</span>
<span class="sd">                return &#39;fc&#39; in n</span>

<span class="sd">            npt_logger.attach(</span>
<span class="sd">                trainer,</span>
<span class="sd">                event_name=Events.ITERATION_COMPLETED,</span>
<span class="sd">                log_handler=GradsScalarHandler(model, whitelist=is_in_fc_layer)</span>
<span class="sd">            )</span>

<span class="sd">    ..  versionchanged:: 0.4.9</span>
<span class="sd">        optional argument `whitelist` added.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">engine</span><span class="p">:</span> <span class="n">Engine</span><span class="p">,</span> <span class="n">logger</span><span class="p">:</span> <span class="n">NeptuneLogger</span><span class="p">,</span> <span class="n">event_name</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Events</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">logger</span><span class="p">,</span> <span class="n">NeptuneLogger</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Handler GradsScalarHandler works only with NeptuneLogger&quot;</span><span class="p">)</span>

        <span class="n">global_step</span> <span class="o">=</span> <span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">get_event_attrib_value</span><span class="p">(</span><span class="n">event_name</span><span class="p">)</span>
        <span class="n">tag_prefix</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">tag</span><span class="si">}</span><span class="s2">/&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tag</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="n">name</span> <span class="o">=</span> <span class="n">name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="s2">&quot;/&quot;</span><span class="p">)</span>
            <span class="n">key</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">tag_prefix</span><span class="si">}</span><span class="s2">grads_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">reduction</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="n">logger</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reduction</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="p">),</span> <span class="n">step</span><span class="o">=</span><span class="n">global_step</span><span class="p">)</span></div>


<div class="viewcode-block" id="NeptuneSaver"><a class="viewcode-back" href="../../../generated/ignite.handlers.neptune_logger.html#ignite.handlers.neptune_logger.NeptuneSaver">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">NeptuneSaver</span><span class="p">(</span><span class="n">BaseSaveHandler</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Handler that saves input checkpoint to the Neptune server.</span>

<span class="sd">    Args:</span>
<span class="sd">        neptune_logger: an instance of</span>
<span class="sd">            NeptuneLogger class.</span>

<span class="sd">    .. Note ::</span>

<span class="sd">        NeptuneSaver is currently not supported on Windows.</span>

<span class="sd">    Examples:</span>
<span class="sd">        .. code-block:: python</span>

<span class="sd">            from ignite.handlers.neptune_logger import *</span>

<span class="sd">            # Create a logger</span>
<span class="sd">            # We are using the api_token for the anonymous user neptuner but you can use your own.</span>

<span class="sd">            npt_logger = NeptuneLogger(</span>
<span class="sd">                api_token=&quot;ANONYMOUS&quot;,</span>
<span class="sd">                project_name=&quot;shared/pytorch-ignite-integration&quot;,</span>
<span class="sd">                experiment_name=&quot;cnn-mnist&quot;, # Optional,</span>
<span class="sd">                params={&quot;max_epochs&quot;: 10}, # Optional,</span>
<span class="sd">                tags=[&quot;pytorch-ignite&quot;,&quot;minst&quot;] # Optional</span>
<span class="sd">            )</span>

<span class="sd">            ...</span>
<span class="sd">            evaluator = create_supervised_evaluator(model, metrics=metrics, ...)</span>
<span class="sd">            ...</span>

<span class="sd">            from ignite.handlers import Checkpoint</span>

<span class="sd">            def score_function(engine):</span>
<span class="sd">                return engine.state.metrics[&quot;accuracy&quot;]</span>

<span class="sd">            to_save = {&quot;model&quot;: model}</span>

<span class="sd">            # pass neptune logger to NeptuneServer</span>

<span class="sd">            handler = Checkpoint(</span>
<span class="sd">                to_save,</span>
<span class="sd">                NeptuneSaver(npt_logger), n_saved=2,</span>
<span class="sd">                filename_prefix=&quot;best&quot;, score_function=score_function,</span>
<span class="sd">                score_name=&quot;validation_accuracy&quot;,</span>
<span class="sd">                global_step_transform=global_step_from_engine(trainer)</span>
<span class="sd">            )</span>

<span class="sd">            evaluator.add_event_handler(Events.COMPLETED, handler)</span>

<span class="sd">            # We need to close the logger when we are done</span>
<span class="sd">            npt_logger.close()</span>

<span class="sd">    For example, you can access model checkpoints and download them from here:</span>
<span class="sd">    https://ui.neptune.ai/o/shared/org/pytorch-ignite-integration/e/PYTOR1-18/charts</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@idist</span><span class="o">.</span><span class="n">one_rank_only</span><span class="p">()</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">neptune_logger</span><span class="p">:</span> <span class="n">NeptuneLogger</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_logger</span> <span class="o">=</span> <span class="n">neptune_logger</span>

    <span class="nd">@idist</span><span class="o">.</span><span class="n">one_rank_only</span><span class="p">()</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">checkpoint</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">,</span> <span class="n">filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">metadata</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Mapping</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># wont work on XLA</span>

        <span class="c1"># Imports for BC compatibility</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># neptune-client&lt;1.0.0 package structure</span>
            <span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
                <span class="c1"># ignore the deprecation warnings</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
                <span class="kn">from</span><span class="w"> </span><span class="nn">neptune.new.types</span><span class="w"> </span><span class="kn">import</span> <span class="n">File</span>
        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
            <span class="c1"># neptune&gt;=1.0.0 package structure</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">neptune.types</span><span class="w"> </span><span class="kn">import</span> <span class="n">File</span>

        <span class="k">with</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">NamedTemporaryFile</span><span class="p">()</span> <span class="k">as</span> <span class="n">tmp</span><span class="p">:</span>
            <span class="c1"># we can not use tmp.name to open tmp.file twice on Win32</span>
            <span class="c1"># https://docs.python.org/3/library/tempfile.html#tempfile.NamedTemporaryFile</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">tmp</span><span class="o">.</span><span class="n">file</span><span class="p">)</span>

            <span class="c1"># rewind the buffer</span>
            <span class="n">tmp</span><span class="o">.</span><span class="n">file</span><span class="o">.</span><span class="n">seek</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

            <span class="c1"># hold onto the file stream for uploading.</span>
            <span class="c1"># NOTE: This won&#39;t load the whole file in memory and upload</span>
            <span class="c1">#       the stream in smaller chunks.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_logger</span><span class="p">[</span><span class="n">filename</span><span class="p">]</span><span class="o">.</span><span class="n">upload</span><span class="p">(</span><span class="n">File</span><span class="o">.</span><span class="n">from_stream</span><span class="p">(</span><span class="n">tmp</span><span class="o">.</span><span class="n">file</span><span class="p">))</span>

<div class="viewcode-block" id="NeptuneSaver.remove"><a class="viewcode-back" href="../../../generated/ignite.handlers.neptune_logger.html#ignite.handlers.neptune_logger.NeptuneSaver.remove">[docs]</a>    <span class="nd">@idist</span><span class="o">.</span><span class="n">one_rank_only</span><span class="p">(</span><span class="n">with_barrier</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">remove</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_logger</span><span class="o">.</span><span class="n">experiment</span><span class="p">[</span><span class="n">filename</span><span class="p">]</span></div></div>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <table>
      <tr>
        <td>
            <p>
                &copy; Copyright 2026, PyTorch-Ignite Contributors.
              Last updated on 03/01/2026, 6:49:25‚ÄØPM.
            </p>
            
              <div>
                Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
              </div>
          
        </td>
        <td>
            
              <div>
                <a href="https://www.netlify.com" target="_blank" rel="noopener noreferrer">
                  <img
                  src="_static/img/netlify-light.svg"
                  alt="Deploys by Netlify"
                  width=114
                  height=51 />
                </a>
              </div>
            
        </td>
      </tr>
    </table>
  </div> 

</footer>
          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
         <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
         <script src="../../../_static/jquery.js"></script>
         <script src="../../../_static/underscore.js"></script>
         <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="../../../_static/doctools.js"></script>
         <script src="../../../_static/sphinx_highlight.js"></script>
         <script src="../../../_static/clipboard.min.js"></script>
         <script src="../../../_static/copybutton.js"></script>
         <script>let toggleHintShow = 'Show default setup';</script>
         <script>let toggleHintHide = 'Hide default setup';</script>
         <script>let toggleOpenOnPrint = 'true';</script>
         <script src="../../../_static/togglebutton.js"></script>
         <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
         <script src="../../../_static/design-tabs.js"></script>
     

  

  <script type="text/javascript" src="../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/vendor/bootstrap.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <!-- commented out for Ignite -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <!-- <div class="container">
      <div class="row">
        <div class="text-center col-md-4">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/ignite/index.html">View Docs</a>
        </div>

        <div class="text-center col-md-4">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="">View Tutorials</a>
        </div>

        <div class="text-center col-md-4">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="">View Resources</a>
        </div>
      </div>
    </div> -->
  </div>

  <!-- <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch-ignite.ai" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch-ignite.ai">PyTorch</a></li>
            <li><a href="">Get Started</a></li>
            <li><a href="">Features</a></li>
            <li><a href="">Ecosystem</a></li>
            <li><a href="">Blog</a></li>
            <li><a href="">Resources</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="">Support</a></li>
            <li><a href="">Tutorials</a></li>
            <li><a href="https://pytorch.org/ignite/index.html">Docs</a></li>
            <li><a href="" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/ignite/issues" target="_blank">Github Issues</a></li>
            <li><a href="" target="_blank">Slack</a></li>
            <li><a href="https://github.com/pytorch/ignite/blob/master/CONTRIBUTING.md" target="_blank">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Follow Us</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>    <!~~ real people should not fill this in and expect good things - do not remove this or risk form bot signups ~~>

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="" target="_blank" class="facebook"></a>
            <a href="" target="_blank" class="twitter"></a>
          </div>
        </div>
      </div>
    </div>
  </footer> -->


  <!-- end of commented out for Ignite -->

  <!-- <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook‚Äôs Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../../_static/images/pytorch-x.svg">
  </div>
</div> -->

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->
  <!--
  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch-ignite.ai" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="#">Get Started</a>
          </li>

          <li>
            <a href="#">Features</a>
          </li>

          <li>
            <a href="#">Ecosystem</a>
          </li>

          <li>
            <a href="">Blog</a>
          </li>

          <li>
            <a href="">Tutorials</a>
          </li>

          <li>
            <a href="https://pytorch.org/ignite/index.html">Docs</a>
          </li>

          <li>
            <a href="">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/ignite">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>
  -->
  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    var collapsedSections = []
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
  <script src="https://cdn.jsdelivr.net/npm/@docsearch/js@3"></script>
  <script type="text/javascript">
  let VERSION
  if ('v0.5.1'.startsWith('v')) {
    VERSION = 'v0.5.1'
  } else {
    VERSION = 'master'
  }
  docsearch({
    container: '#docsearch',
    appId: '7EWYE1JCT3',
    apiKey: '841e93e60c16975ba1bd8c7c716eed82',
    indexName: 'pytorch-ignite',
    placeholder: 'Search PyTorch-Ignite docs',
    searchParameters: {
      facetFilters: [`version:${VERSION}`, 'tags:API-reference'],
    }
  });
  </script>
</body>
</html>