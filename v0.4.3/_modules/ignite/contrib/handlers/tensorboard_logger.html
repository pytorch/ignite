



<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="author" content="PyTorch-Ignite Contributors">
  <meta name="creator" content="PyTorch-Ignite Contributors">
  <meta name="publisher" content="PyTorch-Ignite Contributors">
  <meta name="generator" content="Sphinx 5.3.0">
  <meta name="description" content="High-level library to help with training and evaluating neural networks in PyTorch flexibly and transparently.">
  <meta name="keywords" content="pytorch, pytorch ignite, ignite, engine, events, handlers, metrics">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="theme-color" content="#ee4c2c">

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@pytorch_ignite">
  <meta name="twitter:creator" content="@pytorch_ignite">
  <meta name="twitter:description" content="High-level library to help with training and evaluating neural networks in PyTorch flexibly and transparently.">
  <meta name="twitter:title" content="ignite.contrib.handlers.tensorboard_logger &mdash; PyTorch-Ignite v0.4.3 Documentation">
  <meta name="twitter:image" content="https://raw.githubusercontent.com/pytorch/ignite/master/assets/logo/ignite_logo.png">
  <meta name="twitter:image:alt" content="PyTorch-Ignite logo">

  <meta property="og:title" content="ignite.contrib.handlers.tensorboard_logger &mdash; PyTorch-Ignite v0.4.3 Documentation">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://pytorch.org/ignite/">
  <meta property="og:site_name" content="PyTorch-Ignite">
  <meta property="og:image" content="https://raw.githubusercontent.com/pytorch/ignite/master/assets/logo/ignite_logo.png">
  <meta property="og:image:alt" content="PyTorch-Ignite logo">
  <meta property="og:description" content="High-level library to help with training and evaluating neural networks in PyTorch flexibly and transparently.">

  <link rel="preconnect" href="https://BH4D9OD16A-dsn.algolia.net" crossorigin />

  
  <title>ignite.contrib.handlers.tensorboard_logger &mdash; PyTorch-Ignite v0.4.3 Documentation</title>
  

  
  
    <link rel="shortcut icon" type="image/svg+xml" href="../../../../_static/ignite_logomark.svg"/>
  
  
  
    <link rel="canonical" href="https://pytorch.org/ignite/_modules/ignite/contrib/handlers/tensorboard_logger.html"/>
  

  

  
  
    

  

  <link rel="preload" href="../../../../_static/css/theme.css" as="style" />
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" /> -->
  <link rel="preload" href="../../../../_static/pygments.css" as="style" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="preload" href="../../../../_static/css/theme.css" as="style" />
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="preload" href="../../../../_static/copybutton.css" as="style" />
  <link rel="stylesheet" href="../../../../_static/copybutton.css" type="text/css" />
  <link rel="preload" href="../../../../_static/togglebutton.css" as="style" />
  <link rel="stylesheet" href="../../../../_static/togglebutton.css" type="text/css" />
  <link rel="preload" href="../../../../_static/banner.css" as="style" />
  <link rel="stylesheet" href="../../../../_static/banner.css" type="text/css" />
  <link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.css" as="style" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.css" type="text/css" />
  <link rel="preload" href="../../../../_static/katex-math.css" as="style" />
  <link rel="stylesheet" href="../../../../_static/katex-math.css" type="text/css" />
  <link rel="preload" href="../../../../_static/sphinx-design.5ea377869091fd0449014c60fc090103.min.css" as="style" />
  <link rel="stylesheet" href="../../../../_static/sphinx-design.5ea377869091fd0449014c60fc090103.min.css" type="text/css" />
    <link rel="preload" href="../../../../_static/css/ignite_theme.css" as="style" />
    <link rel="stylesheet" href="../../../../_static/css/ignite_theme.css" type="text/css" />
    <link rel="preload" href="https://cdn.jsdelivr.net/npm/@docsearch/css@3" as="style" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@docsearch/css@3" type="text/css" />
    <link rel="author" title="About these documents" href="../../../../about.html" />
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 

  <!-- katex links / this needs to be loaded before fonts.html -->

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/katex.min.css" crossorigin="anonymous">
<script async src="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/katex.min.js" crossorigin="anonymous"></script>

<!-- Preload the theme fonts -->

<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/IBMPlexMono/IBMPlexMono-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-5FELLLFHCP"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-5FELLLFHCP');
  </script>
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">

    <a class="header-logo" href="/ignite" aria-label="PyTorch-Ignite"></a>

    <div class="header-container">

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch-ignite.ai/tutorials/beginner/01-getting-started/">Quickstart</a>
          </li>

          <li>
            <a href="https://pytorch-ignite.ai/concepts/">Concepts</a>
          </li>

          <!-- <li>
            <a href="https://pytorch-ignite.ai/tutorials/beginner/01-getting-started/#complete-code">Examples</a>
          </li> -->

          <li>
            <a href="https://pytorch-ignite.ai/how-to-guides/">FAQ</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/ignite" target="_blank" rel="noopener noreferrer">GitHub</a>
          </li>

          <li>
            <a href="https://pytorch-ignite.ai/about/community/">About us</a>
          </li>

          <li>
            <a href="https://pytorch-ignite.ai">‚ä≥ pytorch-ignite.ai</a>
          </li>


        </ul>
      </div>

      <!-- <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a> -->
    </div>

  </div>
</div>


<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <div class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></div>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  v0.4.3
                </div>
              
            

            <div id="docsearch"></div>

            
          </div>

          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../quickstart.html">Quick start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../concepts.html">Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Package Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../engine.html">ignite.engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../handlers.html">ignite.handlers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../metrics.html">ignite.metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributed.html">ignite.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../exceptions.html">ignite.exceptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../utils.html">ignite.utils</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contrib Package Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../contrib/engines.html">ignite.contrib.engines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../contrib/metrics.html">ignite.contrib.metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../contrib/handlers.html">ignite.contrib.handlers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Team</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../about.html">About us</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../governance.html">PyTorch-Ignite governance</a></li>
</ul>

            
          
        </div>
      </div>

      <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
        <span class="fa fa-book"> Other Versions</span>
        v: v0.4.3
        <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
        <dl>
            <dt>Tags</dt>
            <dd><a href="../../../../../v0.3.0/index.html">v0.3.0</a></dd>
            <dd><a href="../../../../../v0.4.0.post1/index.html">v0.4.0.post1</a></dd>
            <dd><a href="../../../../../v0.4.1/index.html">v0.4.1</a></dd>
            <dd><a href="../../../../../v0.4.10/index.html">v0.4.10</a></dd>
            <dd><a href="../../../../../v0.4.11/index.html">v0.4.11</a></dd>
            <dd><a href="../../../../../v0.4.12/index.html">v0.4.12</a></dd>
            <dd><a href="../../../../../v0.4.13/index.html">v0.4.13</a></dd>
            <dd><a href="../../../../../v0.4.2/index.html">v0.4.2</a></dd>
            <dd><a href="tensorboard_logger.html">v0.4.3</a></dd>
            <dd><a href="../../../../../v0.4.4.post1/index.html">v0.4.4.post1</a></dd>
            <dd><a href="../../../../../v0.4.5/index.html">v0.4.5</a></dd>
            <dd><a href="../../../../../v0.4.6/index.html">v0.4.6</a></dd>
            <dd><a href="../../../../../v0.4.7/index.html">v0.4.7</a></dd>
            <dd><a href="../../../../../v0.4.8/index.html">v0.4.8</a></dd>
            <dd><a href="../../../../../v0.4.9/index.html">v0.4.9</a></dd>
            <dd><a href="../../../../../v0.4rc.0.post1/index.html">v0.4rc.0.post1</a></dd>
            <dd><a href="../../../../../v0.5.0.post2/index.html">v0.5.0.post2</a></dd>
            <dd><a href="../../../../../v0.5.1/index.html">v0.5.1</a></dd>
            <dd><a href="../../../../../v0.5.2/index.html">v0.5.2</a></dd>
            <dd><a href="../../../../../v0.5.3/index.html">v0.5.3</a></dd>
        </dl>
        <dl>
            <dt>Branches</dt>
            <dd><a href="../../../../../master/index.html">master</a></dd>
        </dl>
    </div>
</div>

    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../../../index.html">Module code</a> &gt;</li>
        
      <li>ignite.contrib.handlers.tensorboard_logger</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for ignite.contrib.handlers.tensorboard_logger</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numbers</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Optimizer</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.base_logger</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">BaseLogger</span><span class="p">,</span>
    <span class="n">BaseOptimizerParamsHandler</span><span class="p">,</span>
    <span class="n">BaseOutputHandler</span><span class="p">,</span>
    <span class="n">BaseWeightsHistHandler</span><span class="p">,</span>
    <span class="n">BaseWeightsScalarHandler</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ignite.engine</span><span class="w"> </span><span class="kn">import</span> <span class="n">Engine</span><span class="p">,</span> <span class="n">EventEnum</span><span class="p">,</span> <span class="n">Events</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ignite.handlers</span><span class="w"> </span><span class="kn">import</span> <span class="n">global_step_from_engine</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;TensorboardLogger&quot;</span><span class="p">,</span>
    <span class="s2">&quot;OptimizerParamsHandler&quot;</span><span class="p">,</span>
    <span class="s2">&quot;OutputHandler&quot;</span><span class="p">,</span>
    <span class="s2">&quot;WeightsScalarHandler&quot;</span><span class="p">,</span>
    <span class="s2">&quot;WeightsHistHandler&quot;</span><span class="p">,</span>
    <span class="s2">&quot;GradsScalarHandler&quot;</span><span class="p">,</span>
    <span class="s2">&quot;GradsHistHandler&quot;</span><span class="p">,</span>
    <span class="s2">&quot;global_step_from_engine&quot;</span><span class="p">,</span>
<span class="p">]</span>


<div class="viewcode-block" id="TensorboardLogger"><a class="viewcode-back" href="../../../../contrib/handlers.html#ignite.contrib.handlers.tensorboard_logger.TensorboardLogger">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">TensorboardLogger</span><span class="p">(</span><span class="n">BaseLogger</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    TensorBoard handler to log metrics, model/optimizer parameters, gradients during the training and validation.</span>

<span class="sd">    By default, this class favors `tensorboardX &lt;https://github.com/lanpa/tensorboardX&gt;`_ package if installed:</span>

<span class="sd">    .. code-block:: bash</span>

<span class="sd">        pip install tensorboardX</span>

<span class="sd">    otherwise, it falls back to using</span>
<span class="sd">    `PyTorch&#39;s SummaryWriter</span>
<span class="sd">    &lt;https://pytorch.org/docs/stable/tensorboard.html&gt;`_</span>
<span class="sd">    (&gt;=v1.2.0).</span>

<span class="sd">    Args:</span>
<span class="sd">        *args: Positional arguments accepted from</span>
<span class="sd">            `SummaryWriter</span>
<span class="sd">            &lt;https://pytorch.org/docs/stable/tensorboard.html&gt;`_.</span>
<span class="sd">        **kwargs: Keyword arguments accepted from</span>
<span class="sd">            `SummaryWriter</span>
<span class="sd">            &lt;https://pytorch.org/docs/stable/tensorboard.html&gt;`_.</span>
<span class="sd">            For example, `log_dir` to setup path to the directory where to log.</span>

<span class="sd">    Examples:</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            from ignite.contrib.handlers.tensorboard_logger import *</span>

<span class="sd">            # Create a logger</span>
<span class="sd">            tb_logger = TensorboardLogger(log_dir=&quot;experiments/tb_logs&quot;)</span>

<span class="sd">            # Attach the logger to the trainer to log training loss at each iteration</span>
<span class="sd">            tb_logger.attach_output_handler(</span>
<span class="sd">                trainer,</span>
<span class="sd">                event_name=Events.ITERATION_COMPLETED,</span>
<span class="sd">                tag=&quot;training&quot;,</span>
<span class="sd">                output_transform=lambda loss: {&quot;loss&quot;: loss}</span>
<span class="sd">            )</span>

<span class="sd">            # Attach the logger to the evaluator on the training dataset and log NLL, Accuracy metrics after each epoch</span>
<span class="sd">            # We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch</span>
<span class="sd">            # of the `trainer` instead of `train_evaluator`.</span>
<span class="sd">            tb_logger.attach_output_handler(</span>
<span class="sd">                train_evaluator,</span>
<span class="sd">                event_name=Events.EPOCH_COMPLETED,</span>
<span class="sd">                tag=&quot;training&quot;,</span>
<span class="sd">                metric_names=[&quot;nll&quot;, &quot;accuracy&quot;],</span>
<span class="sd">                global_step_transform=global_step_from_engine(trainer),</span>
<span class="sd">            )</span>

<span class="sd">            # Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="sd">            # each epoch. We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch of the</span>
<span class="sd">            # `trainer` instead of `evaluator`.</span>
<span class="sd">            tb_logger.attach_output_handler(</span>
<span class="sd">                evaluator,</span>
<span class="sd">                event_name=Events.EPOCH_COMPLETED,</span>
<span class="sd">                tag=&quot;validation&quot;,</span>
<span class="sd">                metric_names=[&quot;nll&quot;, &quot;accuracy&quot;],</span>
<span class="sd">                global_step_transform=global_step_from_engine(trainer)),</span>
<span class="sd">            )</span>

<span class="sd">            # Attach the logger to the trainer to log optimizer&#39;s parameters, e.g. learning rate at each iteration</span>
<span class="sd">            tb_logger.attach_opt_params_handler(</span>
<span class="sd">                trainer,</span>
<span class="sd">                event_name=Events.ITERATION_STARTED,</span>
<span class="sd">                optimizer=optimizer,</span>
<span class="sd">                param_name=&#39;lr&#39;  # optional</span>
<span class="sd">            )</span>

<span class="sd">            # Attach the logger to the trainer to log model&#39;s weights norm after each iteration</span>
<span class="sd">            tb_logger.attach(</span>
<span class="sd">                trainer,</span>
<span class="sd">                event_name=Events.ITERATION_COMPLETED,</span>
<span class="sd">                log_handler=WeightsScalarHandler(model)</span>
<span class="sd">            )</span>

<span class="sd">            # Attach the logger to the trainer to log model&#39;s weights as a histogram after each epoch</span>
<span class="sd">            tb_logger.attach(</span>
<span class="sd">                trainer,</span>
<span class="sd">                event_name=Events.EPOCH_COMPLETED,</span>
<span class="sd">                log_handler=WeightsHistHandler(model)</span>
<span class="sd">            )</span>

<span class="sd">            # Attach the logger to the trainer to log model&#39;s gradients norm after each iteration</span>
<span class="sd">            tb_logger.attach(</span>
<span class="sd">                trainer,</span>
<span class="sd">                event_name=Events.ITERATION_COMPLETED,</span>
<span class="sd">                log_handler=GradsScalarHandler(model)</span>
<span class="sd">            )</span>

<span class="sd">            # Attach the logger to the trainer to log model&#39;s gradients as a histogram after each epoch</span>
<span class="sd">            tb_logger.attach(</span>
<span class="sd">                trainer,</span>
<span class="sd">                event_name=Events.EPOCH_COMPLETED,</span>
<span class="sd">                log_handler=GradsHistHandler(model)</span>
<span class="sd">            )</span>

<span class="sd">            # We need to close the logger with we are done</span>
<span class="sd">            tb_logger.close()</span>

<span class="sd">        It is also possible to use the logger as context manager:</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            from ignite.contrib.handlers.tensorboard_logger import *</span>

<span class="sd">            with TensorboardLogger(log_dir=&quot;experiments/tb_logs&quot;) as tb_logger:</span>

<span class="sd">                trainer = Engine(update_fn)</span>
<span class="sd">                # Attach the logger to the trainer to log training loss at each iteration</span>
<span class="sd">                tb_logger.attach_output_handler(</span>
<span class="sd">                    trainer,</span>
<span class="sd">                    event_name=Events.ITERATION_COMPLETED,</span>
<span class="sd">                    tag=&quot;training&quot;,</span>
<span class="sd">                    output_transform=lambda loss: {&quot;loss&quot;: loss}</span>
<span class="sd">                )</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">tensorboardX</span><span class="w"> </span><span class="kn">import</span> <span class="n">SummaryWriter</span>
        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.tensorboard</span><span class="w"> </span><span class="kn">import</span> <span class="n">SummaryWriter</span>  <span class="c1"># type: ignore[no-redef]</span>
            <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="s2">&quot;This contrib module requires either tensorboardX or torch &gt;= 1.2.0. &quot;</span>
                    <span class="s2">&quot;You may install tensorboardX with command: </span><span class="se">\n</span><span class="s2"> pip install tensorboardX </span><span class="se">\n</span><span class="s2">&quot;</span>
                    <span class="s2">&quot;or upgrade PyTorch using your package manager of choice (pip or conda).&quot;</span>
                <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">writer</span> <span class="o">=</span> <span class="n">SummaryWriter</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">close</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_create_output_handler</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;OutputHandler&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">OutputHandler</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_create_opt_params_handler</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;OptimizerParamsHandler&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">OptimizerParamsHandler</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>


<div class="viewcode-block" id="OutputHandler"><a class="viewcode-back" href="../../../../contrib/handlers.html#ignite.contrib.handlers.tensorboard_logger.OutputHandler">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">OutputHandler</span><span class="p">(</span><span class="n">BaseOutputHandler</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Helper handler to log engine&#39;s output and/or metrics</span>

<span class="sd">    Examples:</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            from ignite.contrib.handlers.tensorboard_logger import *</span>

<span class="sd">            # Create a logger</span>
<span class="sd">            tb_logger = TensorboardLogger(log_dir=&quot;experiments/tb_logs&quot;)</span>

<span class="sd">            # Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="sd">            # each epoch. We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch</span>
<span class="sd">            # of the `trainer`:</span>
<span class="sd">            tb_logger.attach(</span>
<span class="sd">                evaluator,</span>
<span class="sd">                log_handler=OutputHandler(</span>
<span class="sd">                    tag=&quot;validation&quot;,</span>
<span class="sd">                    metric_names=[&quot;nll&quot;, &quot;accuracy&quot;],</span>
<span class="sd">                    global_step_transform=global_step_from_engine(trainer)</span>
<span class="sd">                ),</span>
<span class="sd">                event_name=Events.EPOCH_COMPLETED</span>
<span class="sd">            )</span>
<span class="sd">            # or equivalently</span>
<span class="sd">            tb_logger.attach_output_handler(</span>
<span class="sd">                evaluator,</span>
<span class="sd">                event_name=Events.EPOCH_COMPLETED,</span>
<span class="sd">                tag=&quot;validation&quot;,</span>
<span class="sd">                metric_names=[&quot;nll&quot;, &quot;accuracy&quot;],</span>
<span class="sd">                global_step_transform=global_step_from_engine(trainer)</span>
<span class="sd">            )</span>

<span class="sd">        Another example, where model is evaluated every 500 iterations:</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            from ignite.contrib.handlers.tensorboard_logger import *</span>

<span class="sd">            @trainer.on(Events.ITERATION_COMPLETED(every=500))</span>
<span class="sd">            def evaluate(engine):</span>
<span class="sd">                evaluator.run(validation_set, max_epochs=1)</span>

<span class="sd">            tb_logger = TensorboardLogger(log_dir=&quot;experiments/tb_logs&quot;)</span>

<span class="sd">            def global_step_transform(*args, **kwargs):</span>
<span class="sd">                return trainer.state.iteration</span>

<span class="sd">            # Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="sd">            # every 500 iterations. Since evaluator engine does not have access to the training iteration, we</span>
<span class="sd">            # provide a global_step_transform to return the trainer.state.iteration for the global_step, each time</span>
<span class="sd">            # evaluator metrics are plotted on Tensorboard.</span>

<span class="sd">            tb_logger.attach_output_handler(</span>
<span class="sd">                evaluator,</span>
<span class="sd">                event_name=Events.EPOCH_COMPLETED,</span>
<span class="sd">                tag=&quot;validation&quot;,</span>
<span class="sd">                metrics=[&quot;nll&quot;, &quot;accuracy&quot;],</span>
<span class="sd">                global_step_transform=global_step_transform</span>
<span class="sd">            )</span>

<span class="sd">    Args:</span>
<span class="sd">        tag (str): common title for all produced plots. For example, &quot;training&quot;</span>
<span class="sd">        metric_names (list of str, optional): list of metric names to plot or a string &quot;all&quot; to plot all available</span>
<span class="sd">            metrics.</span>
<span class="sd">        output_transform (callable, optional): output transform function to prepare `engine.state.output` as a number.</span>
<span class="sd">            For example, `output_transform = lambda output: output`</span>
<span class="sd">            This function can also return a dictionary, e.g `{&quot;loss&quot;: loss1, &quot;another_loss&quot;: loss2}` to label the plot</span>
<span class="sd">            with corresponding keys.</span>
<span class="sd">        global_step_transform (callable, optional): global step transform function to output a desired global step.</span>
<span class="sd">            Input of the function is `(engine, event_name)`. Output of function should be an integer.</span>
<span class="sd">            Default is None, global_step based on attached engine. If provided,</span>
<span class="sd">            uses function output as global_step. To setup global step from another engine, please use</span>
<span class="sd">            :meth:`~ignite.contrib.handlers.tensorboard_logger.global_step_from_engine`.</span>

<span class="sd">    Note:</span>

<span class="sd">        Example of `global_step_transform`:</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            def global_step_transform(engine, event_name):</span>
<span class="sd">                return engine.state.get_event_attrib_value(event_name)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tag</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">metric_names</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_transform</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">global_step_transform</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">OutputHandler</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">tag</span><span class="p">,</span> <span class="n">metric_names</span><span class="p">,</span> <span class="n">output_transform</span><span class="p">,</span> <span class="n">global_step_transform</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">engine</span><span class="p">:</span> <span class="n">Engine</span><span class="p">,</span> <span class="n">logger</span><span class="p">:</span> <span class="n">TensorboardLogger</span><span class="p">,</span> <span class="n">event_name</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">EventEnum</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">logger</span><span class="p">,</span> <span class="n">TensorboardLogger</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Handler &#39;OutputHandler&#39; works only with TensorboardLogger&quot;</span><span class="p">)</span>

        <span class="n">metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_setup_output_metrics</span><span class="p">(</span><span class="n">engine</span><span class="p">)</span>

        <span class="n">global_step</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_step_transform</span><span class="p">(</span><span class="n">engine</span><span class="p">,</span> <span class="n">event_name</span><span class="p">)</span>  <span class="c1"># type: ignore[misc]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">global_step</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;global_step must be int, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">global_step</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="s2">&quot; Please check the output of global_step_transform.&quot;</span>
            <span class="p">)</span>

        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">metrics</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Number</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="n">value</span><span class="o">.</span><span class="n">ndimension</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">tag</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">global_step</span><span class="p">)</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="n">value</span><span class="o">.</span><span class="n">ndimension</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">tag</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">v</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">global_step</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TensorboardLogger output_handler can not log metrics value type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">value</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span></div>


<div class="viewcode-block" id="OptimizerParamsHandler"><a class="viewcode-back" href="../../../../contrib/handlers.html#ignite.contrib.handlers.tensorboard_logger.OptimizerParamsHandler">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">OptimizerParamsHandler</span><span class="p">(</span><span class="n">BaseOptimizerParamsHandler</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Helper handler to log optimizer parameters</span>

<span class="sd">    Examples:</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            from ignite.contrib.handlers.tensorboard_logger import *</span>

<span class="sd">            # Create a logger</span>
<span class="sd">            tb_logger = TensorboardLogger(log_dir=&quot;experiments/tb_logs&quot;)</span>

<span class="sd">            # Attach the logger to the trainer to log optimizer&#39;s parameters, e.g. learning rate at each iteration</span>
<span class="sd">            tb_logger.attach(</span>
<span class="sd">                trainer,</span>
<span class="sd">                log_handler=OptimizerParamsHandler(optimizer),</span>
<span class="sd">                event_name=Events.ITERATION_STARTED</span>
<span class="sd">            )</span>
<span class="sd">            # or equivalently</span>
<span class="sd">            tb_logger.attach_opt_params_handler(</span>
<span class="sd">                trainer,</span>
<span class="sd">                event_name=Events.ITERATION_STARTED,</span>
<span class="sd">                optimizer=optimizer</span>
<span class="sd">            )</span>

<span class="sd">    Args:</span>
<span class="sd">        optimizer (torch.optim.Optimizer or object): torch optimizer or any object with attribute ``param_groups``</span>
<span class="sd">            as a sequence.</span>
<span class="sd">        param_name (str): parameter name</span>
<span class="sd">        tag (str, optional): common title for all produced plots. For example, &quot;generator&quot;</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">:</span> <span class="n">Optimizer</span><span class="p">,</span> <span class="n">param_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="n">tag</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">OptimizerParamsHandler</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">param_name</span><span class="p">,</span> <span class="n">tag</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">engine</span><span class="p">:</span> <span class="n">Engine</span><span class="p">,</span> <span class="n">logger</span><span class="p">:</span> <span class="n">TensorboardLogger</span><span class="p">,</span> <span class="n">event_name</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Events</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">logger</span><span class="p">,</span> <span class="n">TensorboardLogger</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Handler OptimizerParamsHandler works only with TensorboardLogger&quot;</span><span class="p">)</span>

        <span class="n">global_step</span> <span class="o">=</span> <span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">get_event_attrib_value</span><span class="p">(</span><span class="n">event_name</span><span class="p">)</span>
        <span class="n">tag_prefix</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">tag</span><span class="si">}</span><span class="s2">/&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tag</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span>
        <span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">tag_prefix</span><span class="si">}{</span><span class="bp">self</span><span class="o">.</span><span class="n">param_name</span><span class="si">}</span><span class="s2">/group_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">param_group</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">param_name</span><span class="p">])</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">param_group</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">)</span>
        <span class="p">}</span>

        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">params</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">global_step</span><span class="p">)</span></div>


<div class="viewcode-block" id="WeightsScalarHandler"><a class="viewcode-back" href="../../../../contrib/handlers.html#ignite.contrib.handlers.tensorboard_logger.WeightsScalarHandler">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">WeightsScalarHandler</span><span class="p">(</span><span class="n">BaseWeightsScalarHandler</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Helper handler to log model&#39;s weights as scalars.</span>
<span class="sd">    Handler iterates over named parameters of the model, applies reduction function to each parameter</span>
<span class="sd">    produce a scalar and then logs the scalar.</span>

<span class="sd">    Examples:</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            from ignite.contrib.handlers.tensorboard_logger import *</span>

<span class="sd">            # Create a logger</span>
<span class="sd">            tb_logger = TensorboardLogger(log_dir=&quot;experiments/tb_logs&quot;)</span>

<span class="sd">            # Attach the logger to the trainer to log model&#39;s weights norm after each iteration</span>
<span class="sd">            tb_logger.attach(</span>
<span class="sd">                trainer,</span>
<span class="sd">                event_name=Events.ITERATION_COMPLETED,</span>
<span class="sd">                log_handler=WeightsScalarHandler(model, reduction=torch.norm)</span>
<span class="sd">            )</span>

<span class="sd">    Args:</span>
<span class="sd">        model (torch.nn.Module): model to log weights</span>
<span class="sd">        reduction (callable): function to reduce parameters into scalar</span>
<span class="sd">        tag (str, optional): common title for all produced plots. For example, &quot;generator&quot;</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">reduction</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">,</span> <span class="n">tag</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">WeightsScalarHandler</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">tag</span><span class="o">=</span><span class="n">tag</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">engine</span><span class="p">:</span> <span class="n">Engine</span><span class="p">,</span> <span class="n">logger</span><span class="p">:</span> <span class="n">TensorboardLogger</span><span class="p">,</span> <span class="n">event_name</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Events</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">logger</span><span class="p">,</span> <span class="n">TensorboardLogger</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Handler &#39;WeightsScalarHandler&#39; works only with TensorboardLogger&quot;</span><span class="p">)</span>

        <span class="n">global_step</span> <span class="o">=</span> <span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">get_event_attrib_value</span><span class="p">(</span><span class="n">event_name</span><span class="p">)</span>
        <span class="n">tag_prefix</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">tag</span><span class="si">}</span><span class="s2">/&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tag</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="n">name</span> <span class="o">=</span> <span class="n">name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="s2">&quot;/&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">tag_prefix</span><span class="si">}</span><span class="s2">weights_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">reduction</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduction</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">data</span><span class="p">),</span> <span class="n">global_step</span>
            <span class="p">)</span></div>


<div class="viewcode-block" id="WeightsHistHandler"><a class="viewcode-back" href="../../../../contrib/handlers.html#ignite.contrib.handlers.tensorboard_logger.WeightsHistHandler">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">WeightsHistHandler</span><span class="p">(</span><span class="n">BaseWeightsHistHandler</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Helper handler to log model&#39;s weights as histograms.</span>

<span class="sd">    Examples:</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            from ignite.contrib.handlers.tensorboard_logger import *</span>

<span class="sd">            # Create a logger</span>
<span class="sd">            tb_logger = TensorboardLogger(log_dir=&quot;experiments/tb_logs&quot;)</span>

<span class="sd">            # Attach the logger to the trainer to log model&#39;s weights norm after each iteration</span>
<span class="sd">            tb_logger.attach(</span>
<span class="sd">                trainer,</span>
<span class="sd">                event_name=Events.ITERATION_COMPLETED,</span>
<span class="sd">                log_handler=WeightsHistHandler(model)</span>
<span class="sd">            )</span>

<span class="sd">    Args:</span>
<span class="sd">        model (torch.nn.Module): model to log weights</span>
<span class="sd">        tag (str, optional): common title for all produced plots. For example, &quot;generator&quot;</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">tag</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">WeightsHistHandler</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">tag</span><span class="o">=</span><span class="n">tag</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">engine</span><span class="p">:</span> <span class="n">Engine</span><span class="p">,</span> <span class="n">logger</span><span class="p">:</span> <span class="n">TensorboardLogger</span><span class="p">,</span> <span class="n">event_name</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Events</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">logger</span><span class="p">,</span> <span class="n">TensorboardLogger</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Handler &#39;WeightsHistHandler&#39; works only with TensorboardLogger&quot;</span><span class="p">)</span>

        <span class="n">global_step</span> <span class="o">=</span> <span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">get_event_attrib_value</span><span class="p">(</span><span class="n">event_name</span><span class="p">)</span>
        <span class="n">tag_prefix</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">tag</span><span class="si">}</span><span class="s2">/&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tag</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="n">name</span> <span class="o">=</span> <span class="n">name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="s2">&quot;/&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">add_histogram</span><span class="p">(</span>
                <span class="n">tag</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">tag_prefix</span><span class="si">}</span><span class="s2">weights/</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">global_step</span><span class="o">=</span><span class="n">global_step</span><span class="p">,</span>
            <span class="p">)</span></div>


<div class="viewcode-block" id="GradsScalarHandler"><a class="viewcode-back" href="../../../../contrib/handlers.html#ignite.contrib.handlers.tensorboard_logger.GradsScalarHandler">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">GradsScalarHandler</span><span class="p">(</span><span class="n">BaseWeightsScalarHandler</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Helper handler to log model&#39;s gradients as scalars.</span>
<span class="sd">    Handler iterates over the gradients of named parameters of the model, applies reduction function to each parameter</span>
<span class="sd">    produce a scalar and then logs the scalar.</span>

<span class="sd">    Examples:</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            from ignite.contrib.handlers.tensorboard_logger import *</span>

<span class="sd">            # Create a logger</span>
<span class="sd">            tb_logger = TensorboardLogger(log_dir=&quot;experiments/tb_logs&quot;)</span>

<span class="sd">            # Attach the logger to the trainer to log model&#39;s weights norm after each iteration</span>
<span class="sd">            tb_logger.attach(</span>
<span class="sd">                trainer,</span>
<span class="sd">                event_name=Events.ITERATION_COMPLETED,</span>
<span class="sd">                log_handler=GradsScalarHandler(model, reduction=torch.norm)</span>
<span class="sd">            )</span>

<span class="sd">    Args:</span>
<span class="sd">        model (torch.nn.Module): model to log weights</span>
<span class="sd">        reduction (callable): function to reduce parameters into scalar</span>
<span class="sd">        tag (str, optional): common title for all produced plots. For example, &quot;generator&quot;</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">reduction</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">,</span> <span class="n">tag</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GradsScalarHandler</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">tag</span><span class="o">=</span><span class="n">tag</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">engine</span><span class="p">:</span> <span class="n">Engine</span><span class="p">,</span> <span class="n">logger</span><span class="p">:</span> <span class="n">TensorboardLogger</span><span class="p">,</span> <span class="n">event_name</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Events</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">logger</span><span class="p">,</span> <span class="n">TensorboardLogger</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Handler &#39;GradsScalarHandler&#39; works only with TensorboardLogger&quot;</span><span class="p">)</span>

        <span class="n">global_step</span> <span class="o">=</span> <span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">get_event_attrib_value</span><span class="p">(</span><span class="n">event_name</span><span class="p">)</span>
        <span class="n">tag_prefix</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">tag</span><span class="si">}</span><span class="s2">/&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tag</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="n">name</span> <span class="o">=</span> <span class="n">name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="s2">&quot;/&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">tag_prefix</span><span class="si">}</span><span class="s2">grads_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">reduction</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduction</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="p">),</span> <span class="n">global_step</span>
            <span class="p">)</span></div>


<div class="viewcode-block" id="GradsHistHandler"><a class="viewcode-back" href="../../../../contrib/handlers.html#ignite.contrib.handlers.tensorboard_logger.GradsHistHandler">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">GradsHistHandler</span><span class="p">(</span><span class="n">BaseWeightsHistHandler</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Helper handler to log model&#39;s gradients as histograms.</span>

<span class="sd">    Examples:</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            from ignite.contrib.handlers.tensorboard_logger import *</span>

<span class="sd">            # Create a logger</span>
<span class="sd">            tb_logger = TensorboardLogger(log_dir=&quot;experiments/tb_logs&quot;)</span>

<span class="sd">            # Attach the logger to the trainer to log model&#39;s weights norm after each iteration</span>
<span class="sd">            tb_logger.attach(</span>
<span class="sd">                trainer,</span>
<span class="sd">                event_name=Events.ITERATION_COMPLETED,</span>
<span class="sd">                log_handler=GradsHistHandler(model)</span>
<span class="sd">            )</span>

<span class="sd">    Args:</span>
<span class="sd">        model (torch.nn.Module): model to log weights</span>
<span class="sd">        tag (str, optional): common title for all produced plots. For example, &quot;generator&quot;</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">tag</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GradsHistHandler</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">tag</span><span class="o">=</span><span class="n">tag</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">engine</span><span class="p">:</span> <span class="n">Engine</span><span class="p">,</span> <span class="n">logger</span><span class="p">:</span> <span class="n">TensorboardLogger</span><span class="p">,</span> <span class="n">event_name</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Events</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">logger</span><span class="p">,</span> <span class="n">TensorboardLogger</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Handler &#39;GradsHistHandler&#39; works only with TensorboardLogger&quot;</span><span class="p">)</span>

        <span class="n">global_step</span> <span class="o">=</span> <span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">get_event_attrib_value</span><span class="p">(</span><span class="n">event_name</span><span class="p">)</span>
        <span class="n">tag_prefix</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">tag</span><span class="si">}</span><span class="s2">/&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tag</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="n">name</span> <span class="o">=</span> <span class="n">name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="s2">&quot;/&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">add_histogram</span><span class="p">(</span>
                <span class="n">tag</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">tag_prefix</span><span class="si">}</span><span class="s2">grads/</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">global_step</span><span class="o">=</span><span class="n">global_step</span>
            <span class="p">)</span></div>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <table>
      <tr>
        <td>
            <p>
                &copy; Copyright 2026, PyTorch-Ignite Contributors.
              Last updated on 03/01/2026, 6:45:41‚ÄØPM.
            </p>
            
              <div>
                Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
              </div>
          
        </td>
        <td>
            
              <div>
                <a href="https://www.netlify.com" target="_blank" rel="noopener noreferrer">
                  <img
                  src="_static/img/netlify-light.svg"
                  alt="Deploys by Netlify"
                  width=114
                  height=51 />
                </a>
              </div>
            
        </td>
      </tr>
    </table>
  </div> 

</footer>
          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
         <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
         <script src="../../../../_static/jquery.js"></script>
         <script src="../../../../_static/underscore.js"></script>
         <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="../../../../_static/doctools.js"></script>
         <script src="../../../../_static/sphinx_highlight.js"></script>
         <script src="../../../../_static/clipboard.min.js"></script>
         <script src="../../../../_static/copybutton.js"></script>
         <script>let toggleHintShow = 'Show default setup';</script>
         <script>let toggleHintHide = 'Hide default setup';</script>
         <script>let toggleOpenOnPrint = 'true';</script>
         <script src="../../../../_static/togglebutton.js"></script>
         <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
         <script src="../../../../_static/design-tabs.js"></script>
     

  

  <script type="text/javascript" src="../../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/vendor/bootstrap.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <!-- commented out for Ignite -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <!-- <div class="container">
      <div class="row">
        <div class="text-center col-md-4">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/ignite/index.html">View Docs</a>
        </div>

        <div class="text-center col-md-4">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="">View Tutorials</a>
        </div>

        <div class="text-center col-md-4">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="">View Resources</a>
        </div>
      </div>
    </div> -->
  </div>

  <!-- <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch-ignite.ai" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch-ignite.ai">PyTorch</a></li>
            <li><a href="">Get Started</a></li>
            <li><a href="">Features</a></li>
            <li><a href="">Ecosystem</a></li>
            <li><a href="">Blog</a></li>
            <li><a href="">Resources</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="">Support</a></li>
            <li><a href="">Tutorials</a></li>
            <li><a href="https://pytorch.org/ignite/index.html">Docs</a></li>
            <li><a href="" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/ignite/issues" target="_blank">Github Issues</a></li>
            <li><a href="" target="_blank">Slack</a></li>
            <li><a href="https://github.com/pytorch/ignite/blob/master/CONTRIBUTING.md" target="_blank">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Follow Us</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>    <!~~ real people should not fill this in and expect good things - do not remove this or risk form bot signups ~~>

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="" target="_blank" class="facebook"></a>
            <a href="" target="_blank" class="twitter"></a>
          </div>
        </div>
      </div>
    </div>
  </footer> -->


  <!-- end of commented out for Ignite -->

  <!-- <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook‚Äôs Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../../../_static/images/pytorch-x.svg">
  </div>
</div> -->

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->
  <!--
  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch-ignite.ai" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="#">Get Started</a>
          </li>

          <li>
            <a href="#">Features</a>
          </li>

          <li>
            <a href="#">Ecosystem</a>
          </li>

          <li>
            <a href="">Blog</a>
          </li>

          <li>
            <a href="">Tutorials</a>
          </li>

          <li>
            <a href="https://pytorch.org/ignite/index.html">Docs</a>
          </li>

          <li>
            <a href="">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/ignite">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>
  -->
  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    var collapsedSections = []
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
  <script src="https://cdn.jsdelivr.net/npm/@docsearch/js@3"></script>
  <script type="text/javascript">
  let VERSION
  if ('v0.4.3'.startsWith('v')) {
    VERSION = 'v0.4.3'
  } else {
    VERSION = 'master'
  }
  docsearch({
    container: '#docsearch',
    appId: '7EWYE1JCT3',
    apiKey: '841e93e60c16975ba1bd8c7c716eed82',
    indexName: 'pytorch-ignite',
    placeholder: 'Search PyTorch-Ignite docs',
    searchParameters: {
      facetFilters: [`version:${VERSION}`, 'tags:API-reference'],
    }
  });
  </script>
</body>
</html>