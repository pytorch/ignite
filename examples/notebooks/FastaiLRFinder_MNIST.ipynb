{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1-final"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "colab": {
      "name": "FastaiLRFinder_MNIST.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5w-QlZE9mvdY"
      },
      "source": [
        "# MNIST example with 3-conv. layer network\n",
        "\n",
        "This example demonstrates the usage of `FastaiLRFinder` with a 3-conv. layer network on the MNIST dataset.\n",
        "\n",
        "## Required Dependencies\n",
        "\n",
        "We assume that `torch` and `ignite` are already installed. We can install it using pip:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdmoIYIvmvdp"
      },
      "source": [
        "!pip install pytorch-ignite"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lP73mDV_nHV9"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "lMphyBmmmvdw"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0epEdj4mvds"
      },
      "source": [
        "import ignite\n",
        "ignite.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEl3QFzZmvd1"
      },
      "source": [
        "from ignite.engine import create_supervised_trainer, create_supervised_evaluator\n",
        "from ignite.metrics import Loss, Accuracy\n",
        "from ignite.contrib.handlers import FastaiLRFinder, ProgressBar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_wmAdFgmvdx"
      },
      "source": [
        "## Loading MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZeKOgKymvdx"
      },
      "source": [
        "mnist_pwd = \"data\"\n",
        "batch_size= 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hgq0uZHAmvdy"
      },
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
        "\n",
        "trainset = MNIST(mnist_pwd, train=True, download=True, transform=transform)\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "\n",
        "testset = MNIST(mnist_pwd, train=False, download=True, transform=transform)\n",
        "testloader = DataLoader(testset, batch_size=batch_size * 2, shuffle=False, num_workers=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTLEOUqtmvdy"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "6KqS5A4Umvd0"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = x.view(-1, 320)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_EHmN2bmvd2"
      },
      "source": [
        "## Training loss (fastai)\n",
        "\n",
        "This learning rate test range follows the same procedure used by fastai. The model is trained for `num_iter` iterations while the learning rate is increased from its initial value specified by the optimizer algorithm to `end_lr`. The increase can be linear (`step_mode=\"linear\"`) or exponential (`step_mode=\"exp\"`); linear provides good results for small ranges while exponential is recommended for larger ranges."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxaXjwDhmvd2"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "criterion = nn.NLLLoss()\n",
        "model = Net()\n",
        "model.to(device)  # Move model before creating optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=3e-4, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTGJPVI6mvd2"
      },
      "source": [
        "trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n",
        "ProgressBar(persist=True).attach(trainer, output_transform=lambda x: {\"batch loss\": x})\n",
        "\n",
        "lr_finder = FastaiLRFinder()\n",
        "to_save={'model': model, 'optimizer': optimizer}\n",
        "with lr_finder.attach(trainer, to_save, diverge_th=1.5) as trainer_with_lr_finder:\n",
        "    trainer_with_lr_finder.run(trainloader)\n",
        "    \n",
        "trainer.run(trainloader, max_epochs=10)\n",
        "\n",
        "evaluator = create_supervised_evaluator(model, metrics={\"acc\": Accuracy(), \"loss\": Loss(nn.NLLLoss())}, device=device)\n",
        "evaluator.run(testloader)\n",
        "\n",
        "print(evaluator.state.metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oN0VkPapmvd5"
      },
      "source": [
        "lr_finder.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHHNoOi8mvd6"
      },
      "source": [
        "lr_finder.lr_suggestion()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcT19wqkmvd6"
      },
      "source": [
        "Let's now setup suggested learning rate to the optimizer and we can train the model with optimal learning rate.\n",
        "\n",
        "*Note, that model and optimizer were restored to their initial states when `FastaiLRFinder` finished.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJqgyaFnmvd7"
      },
      "source": [
        "optimizer.param_groups[0]['lr'] = lr_finder.lr_suggestion()\n",
        "\n",
        "trainer.run(trainloader, max_epochs=10)\n",
        "evaluator.run(testloader)\n",
        "print(evaluator.state.metrics)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}