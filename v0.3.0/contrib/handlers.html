



<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="author" content="PyTorch-Ignite Contributors">
  <meta name="creator" content="PyTorch-Ignite Contributors">
  <meta name="publisher" content="PyTorch-Ignite Contributors">
  <meta name="generator" content="Sphinx 5.3.0">
  <meta name="description" content="High-level library to help with training and evaluating neural networks in PyTorch flexibly and transparently.">
  <meta name="keywords" content="pytorch, pytorch ignite, ignite, engine, events, handlers, metrics">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="theme-color" content="#ee4c2c">

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@pytorch_ignite">
  <meta name="twitter:creator" content="@pytorch_ignite">
  <meta name="twitter:description" content="High-level library to help with training and evaluating neural networks in PyTorch flexibly and transparently.">
  <meta name="twitter:title" content="ignite.contrib.handlers &mdash; PyTorch-Ignite v0.3.0 Documentation">
  <meta name="twitter:image" content="https://raw.githubusercontent.com/pytorch/ignite/master/assets/logo/ignite_logo.png">
  <meta name="twitter:image:alt" content="PyTorch-Ignite logo">

  <meta property="og:title" content="ignite.contrib.handlers &mdash; PyTorch-Ignite v0.3.0 Documentation">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://pytorch.org/ignite/">
  <meta property="og:site_name" content="PyTorch-Ignite">
  <meta property="og:image" content="https://raw.githubusercontent.com/pytorch/ignite/master/assets/logo/ignite_logo.png">
  <meta property="og:image:alt" content="PyTorch-Ignite logo">
  <meta property="og:description" content="High-level library to help with training and evaluating neural networks in PyTorch flexibly and transparently.">

  <link rel="preconnect" href="https://BH4D9OD16A-dsn.algolia.net" crossorigin />

  
  <title>ignite.contrib.handlers &mdash; PyTorch-Ignite v0.3.0 Documentation</title>
  

  
  
    <link rel="shortcut icon" type="image/svg+xml" href="../_static/ignite_logomark.svg"/>
  
  
  
    <link rel="canonical" href="https://pytorch.org/ignite/contrib/handlers.html"/>
  

  

  
  
    

  

  <link rel="preload" href="../_static/css/theme.css" as="style" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <link rel="preload" href="../_static/pygments.css" as="style" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="preload" href="../_static/css/theme.css" as="style" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="preload" href="../_static/copybutton.css" as="style" />
  <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
  <link rel="preload" href="../_static/togglebutton.css" as="style" />
  <link rel="stylesheet" href="../_static/togglebutton.css" type="text/css" />
  <link rel="preload" href="../_static/banner.css" as="style" />
  <link rel="stylesheet" href="../_static/banner.css" type="text/css" />
  <link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.css" as="style" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.css" type="text/css" />
  <link rel="preload" href="../_static/katex-math.css" as="style" />
  <link rel="stylesheet" href="../_static/katex-math.css" type="text/css" />
  <link rel="preload" href="../_static/sphinx-design.5ea377869091fd0449014c60fc090103.min.css" as="style" />
  <link rel="stylesheet" href="../_static/sphinx-design.5ea377869091fd0449014c60fc090103.min.css" type="text/css" />
    <link rel="preload" href="../_static/css/ignite_theme.css" as="style" />
    <link rel="stylesheet" href="../_static/css/ignite_theme.css" type="text/css" />
    <link rel="preload" href="https://cdn.jsdelivr.net/npm/@docsearch/css@3" as="style" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@docsearch/css@3" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="ignite.contrib.metrics" href="metrics.html" /> 

  <!-- katex links / this needs to be loaded before fonts.html -->

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/katex.min.css" crossorigin="anonymous">
<script async src="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/katex.min.js" crossorigin="anonymous"></script>

<!-- Preload the theme fonts -->

<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-5FELLLFHCP"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-5FELLLFHCP');
  </script>
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">

    <a class="header-logo" href="/ignite" aria-label="PyTorch-Ignite"></a>

    <div class="header-container">

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch-ignite.ai/tutorials/beginner/01-getting-started/">Quickstart</a>
          </li>

          <li>
            <a href="https://pytorch-ignite.ai/concepts/">Concepts</a>
          </li>

          <!-- <li>
            <a href="https://pytorch-ignite.ai/tutorials/beginner/01-getting-started/#complete-code">Examples</a>
          </li> -->

          <li>
            <a href="https://pytorch-ignite.ai/how-to-guides/">FAQ</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/ignite" target="_blank" rel="noopener noreferrer">GitHub</a>
          </li>

          <li>
            <a href="https://pytorch-ignite.ai/about/community/">About us</a>
          </li>

          <li>
            <a href="https://pytorch-ignite.ai">⊳ pytorch-ignite.ai</a>
          </li>


        </ul>
      </div>

      <!-- <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a> -->
    </div>

  </div>
</div>


<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <div class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></div>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  v0.3.0
                </div>
              
            

            <div id="docsearch"></div>

            
          </div>

          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../concepts.html">Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quickstart.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Package Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../engine.html">ignite.engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../handlers.html">ignite.handlers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../metrics.html">ignite.metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exceptions.html">ignite.exceptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../utils.html">ignite.utils</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contrib Package Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="engines.html">ignite.contrib.engines</a></li>
<li class="toctree-l1"><a class="reference internal" href="metrics.html">ignite.contrib.metrics</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">ignite.contrib.handlers</a></li>
</ul>

            
          
        </div>
      </div>

      <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
        <span class="fa fa-book"> Other Versions</span>
        v: v0.3.0
        <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
        <dl>
            <dt>Tags</dt>
            <dd><a href="handlers.html">v0.3.0</a></dd>
            <dd><a href="../../v0.4.0.post1/contrib/handlers.html">v0.4.0.post1</a></dd>
            <dd><a href="../../v0.4.1/contrib/handlers.html">v0.4.1</a></dd>
            <dd><a href="../../v0.4.10/contrib/handlers.html">v0.4.10</a></dd>
            <dd><a href="../../v0.4.11/contrib/handlers.html">v0.4.11</a></dd>
            <dd><a href="../../v0.4.12/contrib/handlers.html">v0.4.12</a></dd>
            <dd><a href="../../v0.4.13/contrib/handlers.html">v0.4.13</a></dd>
            <dd><a href="../../v0.4.2/contrib/handlers.html">v0.4.2</a></dd>
            <dd><a href="../../v0.4.3/contrib/handlers.html">v0.4.3</a></dd>
            <dd><a href="../../v0.4.4.post1/contrib/handlers.html">v0.4.4.post1</a></dd>
            <dd><a href="../../v0.4.5/contrib/handlers.html">v0.4.5</a></dd>
            <dd><a href="../../v0.4.6/contrib/handlers.html">v0.4.6</a></dd>
            <dd><a href="../../v0.4.7/contrib/handlers.html">v0.4.7</a></dd>
            <dd><a href="../../v0.4.8/contrib/handlers.html">v0.4.8</a></dd>
            <dd><a href="../../v0.4.9/contrib/handlers.html">v0.4.9</a></dd>
            <dd><a href="../../v0.4rc.0.post1/contrib/handlers.html">v0.4rc.0.post1</a></dd>
            <dd><a href="../../v0.5.0.post2/contrib/handlers.html">v0.5.0.post2</a></dd>
            <dd><a href="../../v0.5.1/contrib/handlers.html">v0.5.1</a></dd>
            <dd><a href="../../v0.5.2/contrib/handlers.html">v0.5.2</a></dd>
            <dd><a href="../../v0.5.3/contrib/handlers.html">v0.5.3</a></dd>
        </dl>
        <dl>
            <dt>Branches</dt>
            <dd><a href="../../master/contrib/handlers.html">master</a></dd>
        </dl>
    </div>
</div>

    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li>ignite.contrib.handlers</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../_sources/contrib/handlers.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <section id="ignite-contrib-handlers">
<h1>ignite.contrib.handlers<a class="headerlink" href="#ignite-contrib-handlers" title="Permalink to this heading">#</a></h1>
<p>Contribution module of handlers</p>
<section id="module-ignite.contrib.handlers.custom_events">
<span id="custom-events"></span><h2>custom_events<a class="headerlink" href="#module-ignite.contrib.handlers.custom_events" title="Permalink to this heading">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.custom_events.CustomPeriodicEvent">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.custom_events.</span></span><span class="sig-name descname"><span class="pre">CustomPeriodicEvent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_iterations</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_epochs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/custom_events.html#CustomPeriodicEvent"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.custom_events.CustomPeriodicEvent" title="Permalink to this definition">#</a></dt>
<dd><p>Handler to define a custom periodic events as a number of elapsed iterations/epochs for an engine.</p>
<p>When custom periodic event is created and attached to an engine, the following events are fired:
1) K iterations is specified:
- <cite>Events.ITERATIONS_&lt;K&gt;_STARTED</cite>
- <cite>Events.ITERATIONS_&lt;K&gt;_COMPLETED</cite></p>
<p>1) K epochs is specified:
- <cite>Events.EPOCHS_&lt;K&gt;_STARTED</cite>
- <cite>Events.EPOCHS_&lt;K&gt;_COMPLETED</cite></p>
<p>Examples:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.engine</span><span class="w"> </span><span class="kn">import</span> <span class="n">Engine</span><span class="p">,</span> <span class="n">Events</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers</span><span class="w"> </span><span class="kn">import</span> <span class="n">CustomPeriodicEvent</span>

<span class="c1"># Let&#39;s define an event every 1000 iterations</span>
<span class="n">cpe1</span> <span class="o">=</span> <span class="n">CustomPeriodicEvent</span><span class="p">(</span><span class="n">n_iterations</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">cpe1</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>

<span class="c1"># Let&#39;s define an event every 10 epochs</span>
<span class="n">cpe2</span> <span class="o">=</span> <span class="n">CustomPeriodicEvent</span><span class="p">(</span><span class="n">n_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">cpe2</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>

<span class="nd">@trainer</span><span class="o">.</span><span class="n">on</span><span class="p">(</span><span class="n">cpe1</span><span class="o">.</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATIONS_1000_COMPLETED</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">on_every_1000_iterations</span><span class="p">(</span><span class="n">engine</span><span class="p">):</span>
    <span class="c1"># run a computation after 1000 iterations</span>
    <span class="c1"># ...</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">iterations_1000</span><span class="p">)</span>

<span class="nd">@trainer</span><span class="o">.</span><span class="n">on</span><span class="p">(</span><span class="n">cpe2</span><span class="o">.</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCHS_10_STARTED</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">on_every_10_epochs</span><span class="p">(</span><span class="n">engine</span><span class="p">):</span>
    <span class="c1"># run a computation every 10 epochs</span>
    <span class="c1"># ...</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">epochs_10</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_iterations</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><em>optional</em>) – number iterations of the custom periodic event</p></li>
<li><p><strong>n_epochs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><em>optional</em>) – number iterations of the custom periodic event. Argument is optional, but only one,
either n_iterations or n_epochs should defined.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-ignite.contrib.handlers.param_scheduler">
<span id="param-scheduler"></span><h2>param_scheduler<a class="headerlink" href="#module-ignite.contrib.handlers.param_scheduler" title="Permalink to this heading">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.ConcatScheduler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.param_scheduler.</span></span><span class="sig-name descname"><span class="pre">ConcatScheduler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">schedulers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">durations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_history</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#ConcatScheduler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.ConcatScheduler" title="Permalink to this definition">#</a></dt>
<dd><p>Concat a list of parameter schedulers.</p>
<p>The <cite>ConcatScheduler</cite> goes through a list of schedulers given by <cite>schedulers</cite>. Duration of each
scheduler is defined by <cite>durations</cite> list of integers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>schedulers</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.14)"><em>list</em></a><em> of </em><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ParamScheduler" title="ignite.contrib.handlers.param_scheduler.ParamScheduler"><em>ParamScheduler</em></a>) – list of parameter schedulers.</p></li>
<li><p><strong>durations</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.14)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a>) – list of number of events that lasts a parameter scheduler from schedulers.</p></li>
<li><p><strong>save_history</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) – whether to log the parameter values to
<cite>engine.state.param_history</cite>, (default=False).</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.param_scheduler</span><span class="w"> </span><span class="kn">import</span> <span class="n">ConcatScheduler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.param_scheduler</span><span class="w"> </span><span class="kn">import</span> <span class="n">LinearCyclicalScheduler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.param_scheduler</span><span class="w"> </span><span class="kn">import</span> <span class="n">CosineAnnealingScheduler</span>

<span class="n">scheduler_1</span> <span class="o">=</span> <span class="n">LinearCyclicalScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="n">start_value</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">cycle_size</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>
<span class="n">scheduler_2</span> <span class="o">=</span> <span class="n">CosineAnnealingScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="n">start_value</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">cycle_size</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>

<span class="n">combined_scheduler</span> <span class="o">=</span> <span class="n">ConcatScheduler</span><span class="p">(</span><span class="n">schedulers</span><span class="o">=</span><span class="p">[</span><span class="n">scheduler_1</span><span class="p">,</span> <span class="n">scheduler_2</span><span class="p">],</span> <span class="n">durations</span><span class="o">=</span><span class="p">[</span><span class="mi">30</span><span class="p">,</span> <span class="p">])</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">add_event_handler</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">,</span> <span class="n">combined_scheduler</span><span class="p">)</span>
<span class="c1">#</span>
<span class="c1"># Sets the Learning rate linearly from 0.1 to 0.5 over 30 iterations. Then</span>
<span class="c1"># starts an annealing schedule from 0.5 to 0.01 over 60 iterations.</span>
<span class="c1"># The annealing cycles are repeated indefinitely.</span>
<span class="c1">#</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.ConcatScheduler.get_param">
<span class="sig-name descname"><span class="pre">get_param</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#ConcatScheduler.get_param"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.ConcatScheduler.get_param" title="Permalink to this definition">#</a></dt>
<dd><p>Method to get current optimizer’s parameter value</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.ConcatScheduler.load_state_dict">
<span class="sig-name descname"><span class="pre">load_state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_dict</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#ConcatScheduler.load_state_dict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.ConcatScheduler.load_state_dict" title="Permalink to this definition">#</a></dt>
<dd><p>Copies parameters from <a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ConcatScheduler.state_dict" title="ignite.contrib.handlers.param_scheduler.ConcatScheduler.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> into this ConcatScheduler.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>state_dict</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.14)"><em>dict</em></a>) – a dict containing parameters.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.ConcatScheduler.simulate_values">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">simulate_values</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_events</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">schedulers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">durations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#ConcatScheduler.simulate_values"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.ConcatScheduler.simulate_values" title="Permalink to this definition">#</a></dt>
<dd><p>Method to simulate scheduled values during num_events events.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_events</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a>) – number of events during the simulation.</p></li>
<li><p><strong>schedulers</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.14)"><em>list</em></a><em> of </em><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ParamScheduler" title="ignite.contrib.handlers.param_scheduler.ParamScheduler"><em>ParamScheduler</em></a>) – list of parameter schedulers.</p></li>
<li><p><strong>durations</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.14)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a>) – list of number of events that lasts a parameter scheduler from schedulers.</p></li>
<li><p><strong>param_names</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.14)"><em>list</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.14)"><em>tuple</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) – parameter name or list of parameter names to simulate values.
By default, the first scheduler’s parameter name is taken.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>list of [event_index, value_0, value_1, …], where values correspond to <cite>param_names</cite>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.ConcatScheduler.state_dict">
<span class="sig-name descname"><span class="pre">state_dict</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#ConcatScheduler.state_dict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.ConcatScheduler.state_dict" title="Permalink to this definition">#</a></dt>
<dd><p>Returns a dictionary containing a whole state of ConcatScheduler.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a dictionary containing a whole state of ConcatScheduler</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.14)">dict</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.CosineAnnealingScheduler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.param_scheduler.</span></span><span class="sig-name descname"><span class="pre">CosineAnnealingScheduler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">start_value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">end_value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cycle_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cycle_mult</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">start_value_mult</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">end_value_mult</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_history</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_group_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#CosineAnnealingScheduler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.CosineAnnealingScheduler" title="Permalink to this definition">#</a></dt>
<dd><p>Anneals ‘start_value’ to ‘end_value’ over each cycle.</p>
<p>The annealing takes the form of the first half of a cosine
wave (as suggested in <a class="reference internal" href="#smith17" id="id1"><span>[Smith17]</span></a>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> (<cite>torch.optim.Optimizer</cite>) – optimizer</p></li>
<li><p><strong>param_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) – name of optimizer’s parameter to update.</p></li>
<li><p><strong>start_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a>) – value at start of cycle.</p></li>
<li><p><strong>end_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a>) – value at the end of the cycle.</p></li>
<li><p><strong>cycle_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a>) – length of cycle.</p></li>
<li><p><strong>cycle_mult</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>optional</em>) – ratio by which to change the cycle_size
at the end of each cycle (default=1).</p></li>
<li><p><strong>start_value_mult</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>optional</em>) – ratio by which to change the start value at the
end of each cycle (default=1.0).</p></li>
<li><p><strong>end_value_mult</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>optional</em>) – ratio by which to change the end value at the
end of each cycle (default=1.0).</p></li>
<li><p><strong>save_history</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) – whether to log the parameter values to
<cite>engine.state.param_history</cite>, (default=False).</p></li>
<li><p><strong>param_group_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><em>optional</em>) – optimizer’s parameters group to use.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If the scheduler is bound to an ‘ITERATION_*’ event, ‘cycle_size’ should
usually be the number of batches in an epoch.</p>
</div>
<p>Examples:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.param_scheduler</span><span class="w"> </span><span class="kn">import</span> <span class="n">CosineAnnealingScheduler</span>

<span class="n">scheduler</span> <span class="o">=</span> <span class="n">CosineAnnealingScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="mf">1e-1</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">))</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">add_event_handler</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">)</span>
<span class="c1">#</span>
<span class="c1"># Anneals the learning rate from 1e-1 to 1e-3 over the course of 1 epoch.</span>
<span class="c1">#</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.param_scheduler</span><span class="w"> </span><span class="kn">import</span> <span class="n">CosineAnnealingScheduler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.param_scheduler</span><span class="w"> </span><span class="kn">import</span> <span class="n">LinearCyclicalScheduler</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">{</span><span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">base</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">),</span>
        <span class="p">{</span><span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">),</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="n">scheduler1</span> <span class="o">=</span> <span class="n">LinearCyclicalScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="mf">1e-7</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">),</span> <span class="n">param_group_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">add_event_handler</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">,</span> <span class="n">scheduler1</span><span class="p">,</span> <span class="s2">&quot;lr (base)&quot;</span><span class="p">)</span>

<span class="n">scheduler2</span> <span class="o">=</span> <span class="n">CosineAnnealingScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">),</span> <span class="n">param_group_index</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">add_event_handler</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">,</span> <span class="n">scheduler2</span><span class="p">,</span> <span class="s2">&quot;lr (fc)&quot;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="citation">
<dt class="label" id="smith17"><span class="brackets"><a class="fn-backref" href="#id1">Smith17</a></span></dt>
<dd><p>Smith, Leslie N. “Cyclical learning rates for training neural networks.”
Applications of Computer Vision (WACV), 2017 IEEE Winter Conference on. IEEE, 2017</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.CosineAnnealingScheduler.get_param">
<span class="sig-name descname"><span class="pre">get_param</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#CosineAnnealingScheduler.get_param"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.CosineAnnealingScheduler.get_param" title="Permalink to this definition">#</a></dt>
<dd><p>Method to get current optimizer’s parameter value</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.CyclicalScheduler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.param_scheduler.</span></span><span class="sig-name descname"><span class="pre">CyclicalScheduler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">start_value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">end_value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cycle_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cycle_mult</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">start_value_mult</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">end_value_mult</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_history</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_group_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#CyclicalScheduler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.CyclicalScheduler" title="Permalink to this definition">#</a></dt>
<dd><p>An abstract class for updating an optimizer’s parameter value over a
cycle of some size.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> (<cite>torch.optim.Optimizer</cite>) – optimizer</p></li>
<li><p><strong>param_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) – name of optimizer’s parameter to update.</p></li>
<li><p><strong>start_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a>) – value at start of cycle.</p></li>
<li><p><strong>end_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a>) – value at the middle of the cycle.</p></li>
<li><p><strong>cycle_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a>) – length of cycle, value should be larger than 1.</p></li>
<li><p><strong>cycle_mult</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>optional</em>) – ratio by which to change the cycle_size.
at the end of each cycle (default=1.0).</p></li>
<li><p><strong>start_value_mult</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>optional</em>) – ratio by which to change the start value at the
end of each cycle (default=1.0).</p></li>
<li><p><strong>end_value_mult</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>optional</em>) – ratio by which to change the end value at the
end of each cycle (default=1.0).</p></li>
<li><p><strong>save_history</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) – whether to log the parameter values to
<cite>engine.state.param_history</cite>, (default=False).</p></li>
<li><p><strong>param_group_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><em>optional</em>) – optimizer’s parameters group to use.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If the scheduler is bound to an ‘ITERATION_*’ event, ‘cycle_size’ should
usually be the number of batches in an epoch.</p>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.LRScheduler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.param_scheduler.</span></span><span class="sig-name descname"><span class="pre">LRScheduler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lr_scheduler</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_history</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwds</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#LRScheduler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.LRScheduler" title="Permalink to this definition">#</a></dt>
<dd><p>A wrapper class to call <cite>torch.optim.lr_scheduler</cite> objects as <cite>ignite</cite> handlers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lr_scheduler</strong> (subclass of <cite>torch.optim.lr_scheduler._LRScheduler</cite>) – lr_scheduler object to wrap.</p></li>
<li><p><strong>save_history</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) – whether to log the parameter values to
<cite>engine.state.param_history</cite>, (default=False).</p></li>
</ul>
</dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.param_scheduler</span><span class="w"> </span><span class="kn">import</span> <span class="n">LRScheduler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim.lr_scheduler</span><span class="w"> </span><span class="kn">import</span> <span class="n">StepLR</span>

<span class="n">step_scheduler</span> <span class="o">=</span> <span class="n">StepLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">scheduler</span> <span class="o">=</span> <span class="n">LRScheduler</span><span class="p">(</span><span class="n">step_scheduler</span><span class="p">)</span>

<span class="c1"># In this example, we assume to have installed PyTorch&gt;=1.1.0</span>
<span class="c1"># (with new `torch.optim.lr_scheduler` behaviour) and</span>
<span class="c1"># we attach scheduler to Events.ITERATION_COMPLETED</span>
<span class="c1"># instead of Events.ITERATION_STARTED to make sure to use</span>
<span class="c1"># the first lr value from the optimizer, otherwise it is will be skipped:</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">add_event_handler</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.LRScheduler.get_param">
<span class="sig-name descname"><span class="pre">get_param</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#LRScheduler.get_param"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.LRScheduler.get_param" title="Permalink to this definition">#</a></dt>
<dd><p>Method to get current optimizer’s parameter value</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.LRScheduler.simulate_values">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">simulate_values</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_events</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr_scheduler</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#LRScheduler.simulate_values"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.LRScheduler.simulate_values" title="Permalink to this definition">#</a></dt>
<dd><p>Method to simulate scheduled values during num_events events.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_events</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a>) – number of events during the simulation.</p></li>
<li><p><strong>lr_scheduler</strong> (subclass of <cite>torch.optim.lr_scheduler._LRScheduler</cite>) – lr_scheduler object to wrap.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>[event_index, value]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.14)">list</a> of pairs</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.LinearCyclicalScheduler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.param_scheduler.</span></span><span class="sig-name descname"><span class="pre">LinearCyclicalScheduler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">start_value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">end_value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cycle_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cycle_mult</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">start_value_mult</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">end_value_mult</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_history</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_group_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#LinearCyclicalScheduler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.LinearCyclicalScheduler" title="Permalink to this definition">#</a></dt>
<dd><p>Linearly adjusts param value to ‘end_value’ for a half-cycle, then linearly
adjusts it back to ‘start_value’ for a half-cycle.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> (<cite>torch.optim.Optimizer</cite>) – optimizer</p></li>
<li><p><strong>param_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) – name of optimizer’s parameter to update.</p></li>
<li><p><strong>start_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a>) – value at start of cycle.</p></li>
<li><p><strong>end_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a>) – value at the middle of the cycle.</p></li>
<li><p><strong>cycle_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a>) – length of cycle.</p></li>
<li><p><strong>cycle_mult</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>optional</em>) – ratio by which to change the cycle_size
at the end of each cycle (default=1).</p></li>
<li><p><strong>start_value_mult</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>optional</em>) – ratio by which to change the start value at the
end of each cycle (default=1.0).</p></li>
<li><p><strong>end_value_mult</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>optional</em>) – ratio by which to change the end value at the
end of each cycle (default=1.0).</p></li>
<li><p><strong>save_history</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) – whether to log the parameter values to
<cite>engine.state.param_history</cite>, (default=False).</p></li>
<li><p><strong>param_group_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><em>optional</em>) – optimizer’s parameters group to use.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If the scheduler is bound to an ‘ITERATION_*’ event, ‘cycle_size’ should
usually be the number of batches in an epoch.</p>
</div>
<p>Examples:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.param_scheduler</span><span class="w"> </span><span class="kn">import</span> <span class="n">LinearCyclicalScheduler</span>

<span class="n">scheduler</span> <span class="o">=</span> <span class="n">LinearCyclicalScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="mf">1e-1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">))</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">add_event_handler</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">)</span>
<span class="c1">#</span>
<span class="c1"># Linearly increases the learning rate from 1e-3 to 1e-1 and back to 1e-3</span>
<span class="c1"># over the course of 1 epoch</span>
<span class="c1">#</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.LinearCyclicalScheduler.get_param">
<span class="sig-name descname"><span class="pre">get_param</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#LinearCyclicalScheduler.get_param"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.LinearCyclicalScheduler.get_param" title="Permalink to this definition">#</a></dt>
<dd><p>Method to get current optimizer’s parameter value</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.ParamGroupScheduler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.param_scheduler.</span></span><span class="sig-name descname"><span class="pre">ParamGroupScheduler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">schedulers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">names</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#ParamGroupScheduler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.ParamGroupScheduler" title="Permalink to this definition">#</a></dt>
<dd><p>Scheduler helper to group multiple schedulers into one.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>schedulers</strong> (<em>list/tuple</em><em> of </em><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ParamScheduler" title="ignite.contrib.handlers.param_scheduler.ParamScheduler"><em>ParamScheduler</em></a>) – list/tuple of parameter schedulers.</p></li>
<li><p><strong>names</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.14)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) – list of names of schedulers.</p></li>
</ul>
</dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">{</span><span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">base</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">),</span>
        <span class="p">{</span><span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">),</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="n">scheduler1</span> <span class="o">=</span> <span class="n">LinearCyclicalScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="mf">1e-7</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">),</span> <span class="n">param_group_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">scheduler2</span> <span class="o">=</span> <span class="n">CosineAnnealingScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">),</span> <span class="n">param_group_index</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">lr_schedulers</span> <span class="o">=</span> <span class="p">[</span><span class="n">scheduler1</span><span class="p">,</span> <span class="n">scheduler2</span><span class="p">]</span>
<span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;lr (base)&quot;</span><span class="p">,</span> <span class="s2">&quot;lr (fc)&quot;</span><span class="p">]</span>

<span class="n">scheduler</span> <span class="o">=</span> <span class="n">ParamGroupScheduler</span><span class="p">(</span><span class="n">schedulers</span><span class="o">=</span><span class="n">lr_schedulers</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="n">names</span><span class="p">)</span>
<span class="c1"># Attach single scheduler to the trainer</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">add_event_handler</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.ParamGroupScheduler.load_state_dict">
<span class="sig-name descname"><span class="pre">load_state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_dict</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#ParamGroupScheduler.load_state_dict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.ParamGroupScheduler.load_state_dict" title="Permalink to this definition">#</a></dt>
<dd><p>Copies parameters from <a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ParamGroupScheduler.state_dict" title="ignite.contrib.handlers.param_scheduler.ParamGroupScheduler.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> into this ParamScheduler.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>state_dict</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.14)"><em>dict</em></a>) – a dict containing parameters.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.ParamGroupScheduler.state_dict">
<span class="sig-name descname"><span class="pre">state_dict</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#ParamGroupScheduler.state_dict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.ParamGroupScheduler.state_dict" title="Permalink to this definition">#</a></dt>
<dd><p>Returns a dictionary containing a whole state of ParamGroupScheduler.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a dictionary containing a whole state of ParamGroupScheduler</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.14)">dict</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.ParamScheduler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.param_scheduler.</span></span><span class="sig-name descname"><span class="pre">ParamScheduler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_history</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_group_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#ParamScheduler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.ParamScheduler" title="Permalink to this definition">#</a></dt>
<dd><p>An abstract class for updating an optimizer’s parameter value during
training.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> (<cite>torch.optim.Optimizer</cite>) – optimizer</p></li>
<li><p><strong>param_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) – name of optimizer’s parameter to update.</p></li>
<li><p><strong>save_history</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) – whether to log the parameter values to
<cite>engine.state.param_history</cite>, (default=False).</p></li>
<li><p><strong>param_group_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><em>optional</em>) – optimizer’s parameters group to use</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Parameter scheduler works independently of the internal state of the attached optimizer.
More precisely, whatever the state of the optimizer (newly created or used by another scheduler) the scheduler
sets defined absolute values.</p>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.ParamScheduler.get_param">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_param</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#ParamScheduler.get_param"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.ParamScheduler.get_param" title="Permalink to this definition">#</a></dt>
<dd><p>Method to get current optimizer’s parameter value</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.ParamScheduler.load_state_dict">
<span class="sig-name descname"><span class="pre">load_state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_dict</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#ParamScheduler.load_state_dict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.ParamScheduler.load_state_dict" title="Permalink to this definition">#</a></dt>
<dd><p>Copies parameters from <a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ParamScheduler.state_dict" title="ignite.contrib.handlers.param_scheduler.ParamScheduler.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> into this ParamScheduler.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>state_dict</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.14)"><em>dict</em></a>) – a dict containing parameters.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.ParamScheduler.plot_values">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">plot_values</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_events</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">scheduler_kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#ParamScheduler.plot_values"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.ParamScheduler.plot_values" title="Permalink to this definition">#</a></dt>
<dd><p>Method to plot simulated scheduled values during <cite>num_events</cite> events.</p>
<p>This class requires <a class="reference external" href="https://matplotlib.org/">matplotlib package</a> to be installed:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>matplotlib
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_events</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a>) – number of events during the simulation.</p></li>
<li><p><strong>**scheduler_kwargs</strong> – parameter scheduler configuration kwargs.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>matplotlib.lines.Line2D</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pylab</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="n">LinearCyclicalScheduler</span><span class="o">.</span><span class="n">plot_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">param_name</span><span class="o">=</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span>
                                    <span class="n">start_value</span><span class="o">=</span><span class="mf">1e-1</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">cycle_size</span><span class="o">=</span><span class="mi">10</span><span class="p">))</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.ParamScheduler.simulate_values">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">simulate_values</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_events</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">scheduler_kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#ParamScheduler.simulate_values"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.ParamScheduler.simulate_values" title="Permalink to this definition">#</a></dt>
<dd><p>Method to simulate scheduled values during <cite>num_events</cite> events.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_events</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a>) – number of events during the simulation.</p></li>
<li><p><strong>**scheduler_kwargs</strong> – parameter scheduler configuration kwargs.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>[event_index, value]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.14)">list</a> of pairs</p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">lr_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">LinearCyclicalScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">param_name</span><span class="o">=</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span>
                                                             <span class="n">start_value</span><span class="o">=</span><span class="mf">1e-1</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
                                                             <span class="n">cycle_size</span><span class="o">=</span><span class="mi">10</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.ParamScheduler.state_dict">
<span class="sig-name descname"><span class="pre">state_dict</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#ParamScheduler.state_dict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.ParamScheduler.state_dict" title="Permalink to this definition">#</a></dt>
<dd><p>Returns a dictionary containing a whole state of ParamScheduler.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a dictionary containing a whole state of ParamScheduler</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.14)">dict</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.PiecewiseLinear">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.param_scheduler.</span></span><span class="sig-name descname"><span class="pre">PiecewiseLinear</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">milestones_values</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_history</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_group_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#PiecewiseLinear"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.PiecewiseLinear" title="Permalink to this definition">#</a></dt>
<dd><p>Piecewise linear parameter scheduler</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> (<cite>torch.optim.Optimizer</cite>) – optimizer.</p></li>
<li><p><strong>param_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) – name of optimizer’s parameter to update.</p></li>
<li><p><strong>milestones_values</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.14)"><em>list</em></a><em> of </em><em>tuples</em><em> (</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>)</em>) – list of tuples (event index, parameter value)
represents milestones and parameter. Milestones should be increasing integers.</p></li>
<li><p><strong>save_history</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) – whether to log the parameter values to
<cite>engine.state.param_history</cite>, (default=False).</p></li>
<li><p><strong>param_group_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><em>optional</em>) – optimizer’s parameters group to use.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>piecewise linear scheduler</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.PiecewiseLinear" title="ignite.contrib.handlers.param_scheduler.PiecewiseLinear">PiecewiseLinear</a></p>
</dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">PiecewiseLinear</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s2">&quot;lr&quot;</span><span class="p">,</span>
                            <span class="n">milestones_values</span><span class="o">=</span><span class="p">[(</span><span class="mi">10</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mf">0.45</span><span class="p">),</span> <span class="p">(</span><span class="mi">21</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">),</span> <span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">),</span> <span class="p">(</span><span class="mi">40</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)])</span>
<span class="c1"># Attach to the trainer</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">add_event_handler</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">)</span>
<span class="c1">#</span>
<span class="c1"># Sets the learning rate to 0.5 over the first 10 iterations, then decreases linearly from 0.5 to 0.45 between</span>
<span class="c1"># 10th and 20th iterations. Next there is a jump to 0.3 at the 21st iteration and LR decreases linearly</span>
<span class="c1"># from 0.3 to 0.1 between 21st and 30th iterations and remains 0.1 until the end of the iterations.</span>
<span class="c1">#</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.PiecewiseLinear.get_param">
<span class="sig-name descname"><span class="pre">get_param</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#PiecewiseLinear.get_param"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.PiecewiseLinear.get_param" title="Permalink to this definition">#</a></dt>
<dd><p>Method to get current optimizer’s parameter value</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ignite.contrib.handlers.param_scheduler.create_lr_scheduler_with_warmup">
<span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.param_scheduler.</span></span><span class="sig-name descname"><span class="pre">create_lr_scheduler_with_warmup</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lr_scheduler</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warmup_start_value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warmup_end_value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warmup_duration</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_history</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_simulated_values</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#create_lr_scheduler_with_warmup"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.create_lr_scheduler_with_warmup" title="Permalink to this definition">#</a></dt>
<dd><p>Helper method to create a learning rate scheduler with a linear warm-up.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lr_scheduler</strong> (ParamScheduler or subclass of <cite>torch.optim.lr_scheduler._LRScheduler</cite>) – learning rate scheduler
after the warm-up.</p></li>
<li><p><strong>warmup_start_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a>) – learning rate start value of the warm-up phase.</p></li>
<li><p><strong>warmup_end_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a>) – learning rate end value of the warm-up phase.</p></li>
<li><p><strong>warmup_duration</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a>) – warm-up phase duration, number of events.</p></li>
<li><p><strong>save_history</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) – whether to log the parameter values to
<cite>engine.state.param_history</cite>, (default=False).</p></li>
<li><p><strong>output_simulated_values</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.14)"><em>list</em></a><em>, </em><em>optional</em>) – optional output of simulated learning rate values.
If output_simulated_values is a list of None, e.g. <cite>[None] * 100</cite>, after the execution it will be filled
by 100 simulated learning rate values.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>learning rate scheduler with linear warm-up.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ConcatScheduler" title="ignite.contrib.handlers.param_scheduler.ConcatScheduler">ConcatScheduler</a></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If the first learning rate value provided by <cite>lr_scheduler</cite> is different from <cite>warmup_end_value</cite>, an additional
event is added after the warm-up phase such that the warm-up ends with <cite>warmup_end_value</cite> value and then
<cite>lr_scheduler</cite> provides its learning rate values as normally.</p>
</div>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">torch_lr_scheduler</span> <span class="o">=</span> <span class="n">ExponentialLR</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.98</span><span class="p">)</span>
<span class="n">lr_values</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span>
<span class="n">scheduler</span> <span class="o">=</span> <span class="n">create_lr_scheduler_with_warmup</span><span class="p">(</span><span class="n">torch_lr_scheduler</span><span class="p">,</span>
                                            <span class="n">warmup_start_value</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                                            <span class="n">warmup_end_value</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                                            <span class="n">warmup_duration</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                                            <span class="n">output_simulated_values</span><span class="o">=</span><span class="n">lr_values</span><span class="p">)</span>
<span class="n">lr_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">lr_values</span><span class="p">)</span>
<span class="c1"># Plot simulated values</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>

<span class="c1"># Attach to the trainer</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">add_event_handler</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="tensorboard-logger">
<h2>tensorboard_logger<a class="headerlink" href="#tensorboard-logger" title="Permalink to this heading">#</a></h2>
<p>See <a class="reference external" href="https://github.com/pytorch/ignite/blob/master/examples/contrib/mnist/mnist_with_tensorboard_logger.py">tensorboardX mnist example</a>
and <a class="reference external" href="https://github.com/pytorch/ignite/tree/master/examples/notebooks">CycleGAN and EfficientNet notebooks</a> for detailed usage.</p>
<span class="target" id="module-ignite.contrib.handlers.tensorboard_logger"></span><dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.tensorboard_logger.GradsHistHandler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.tensorboard_logger.</span></span><span class="sig-name descname"><span class="pre">GradsHistHandler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tag</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/tensorboard_logger.html#GradsHistHandler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.tensorboard_logger.GradsHistHandler" title="Permalink to this definition">#</a></dt>
<dd><p>Helper handler to log model’s gradients as histograms.</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.tensorboard_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">tb_logger</span> <span class="o">=</span> <span class="n">TensorboardLogger</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;experiments/tb_logs&quot;</span><span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log model&#39;s weights norm after each iteration</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">GradsHistHandler</span><span class="p">(</span><span class="n">model</span><span class="p">),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.10)"><em>torch.nn.Module</em></a>) – model to log weights</p></li>
<li><p><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) – common title for all produced plots. For example, ‘generator’</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.tensorboard_logger.GradsScalarHandler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.tensorboard_logger.</span></span><span class="sig-name descname"><span class="pre">GradsScalarHandler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction=&lt;function</span> <span class="pre">norm&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tag=None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/tensorboard_logger.html#GradsScalarHandler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.tensorboard_logger.GradsScalarHandler" title="Permalink to this definition">#</a></dt>
<dd><p>Helper handler to log model’s gradients as scalars.
Handler iterates over the gradients of named parameters of the model, applies reduction function to each parameter
produce a scalar and then logs the scalar.</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.tensorboard_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">tb_logger</span> <span class="o">=</span> <span class="n">TensorboardLogger</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;experiments/tb_logs&quot;</span><span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log model&#39;s weights norm after each iteration</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">GradsScalarHandler</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.10)"><em>torch.nn.Module</em></a>) – model to log weights</p></li>
<li><p><strong>reduction</strong> (<em>callable</em>) – function to reduce parameters into scalar</p></li>
<li><p><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) – common title for all produced plots. For example, ‘generator’</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.tensorboard_logger.OptimizerParamsHandler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.tensorboard_logger.</span></span><span class="sig-name descname"><span class="pre">OptimizerParamsHandler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'lr'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tag</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/tensorboard_logger.html#OptimizerParamsHandler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.tensorboard_logger.OptimizerParamsHandler" title="Permalink to this definition">#</a></dt>
<dd><p>Helper handler to log optimizer parameters</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.tensorboard_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">tb_logger</span> <span class="o">=</span> <span class="n">TensorboardLogger</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;experiments/tb_logs&quot;</span><span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log optimizer&#39;s parameters, e.g. learning rate at each iteration</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">OptimizerParamsHandler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch v2.10)"><em>torch.optim.Optimizer</em></a>) – torch optimizer which parameters to log</p></li>
<li><p><strong>param_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) – parameter name</p></li>
<li><p><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) – common title for all produced plots. For example, ‘generator’</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.tensorboard_logger.OutputHandler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.tensorboard_logger.</span></span><span class="sig-name descname"><span class="pre">OutputHandler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tag</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">another_engine</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">global_step_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/tensorboard_logger.html#OutputHandler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.tensorboard_logger.OutputHandler" title="Permalink to this definition">#</a></dt>
<dd><p>Helper handler to log engine’s output and/or metrics</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.tensorboard_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">tb_logger</span> <span class="o">=</span> <span class="n">TensorboardLogger</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;experiments/tb_logs&quot;</span><span class="p">)</span>

<span class="c1"># Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="c1"># each epoch. We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch</span>
<span class="c1"># of the `trainer`:</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">evaluator</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
                                           <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
                                           <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">)),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">)</span>
</pre></div>
</div>
<p>Example with CustomPeriodicEvent, where model is evaluated every 500 iterations:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers</span><span class="w"> </span><span class="kn">import</span> <span class="n">CustomPeriodicEvent</span>

<span class="n">cpe</span> <span class="o">=</span> <span class="n">CustomPeriodicEvent</span><span class="p">(</span><span class="n">n_iterations</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="n">cpe</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>

<span class="nd">@trainer</span><span class="o">.</span><span class="n">on</span><span class="p">(</span><span class="n">cpe</span><span class="o">.</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATIONS_500_COMPLETED</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span><span class="n">engine</span><span class="p">):</span>
    <span class="n">evaluator</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">validation_set</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.tensorboard_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="n">tb_logger</span> <span class="o">=</span> <span class="n">TensorboardLogger</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;experiments/tb_logs&quot;</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">global_step_transform</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">trainer</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">iteration</span>

<span class="c1"># Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="c1"># every 500 iterations. Since evaluator engine does not have CustomPeriodicEvent attached to it, we</span>
<span class="c1"># provide a global_step_transform to return the trainer.state.iteration for the global_step, each time</span>
<span class="c1"># evaluator metrics are plotted on Tensorboard.</span>

<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">evaluator</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
                                           <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
                                           <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_transform</span><span class="p">),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) – common title for all produced plots. For example, ‘training’</p></li>
<li><p><strong>metric_names</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.14)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) – list of metric names to plot or a string “all” to plot all available
metrics.</p></li>
<li><p><strong>output_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – output transform function to prepare <cite>engine.state.output</cite> as a number.
For example, <cite>output_transform = lambda output: output</cite>
This function can also return a dictionary, e.g <cite>{‘loss’: loss1, `another_loss</cite>: loss2}` to label the plot
with corresponding keys.</p></li>
<li><p><strong>another_engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.Engine" title="ignite.engine.Engine"><em>Engine</em></a>) – Deprecated (see <code class="xref py py-attr docutils literal notranslate"><span class="pre">global_step_transform</span></code>). Another engine to use to provide the
value of event. Typically, user can provide
the trainer if this handler is attached to an evaluator and thus it logs proper trainer’s
epoch/iteration value.</p></li>
<li><p><strong>global_step_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – global step transform function to output a desired global step.
Input of the function is <cite>(engine, event_name)</cite>. Output of function should be an integer.
Default is None, global_step based on attached engine. If provided,
uses function output as global_step. To setup global step from another engine, please use
<a class="reference internal" href="#ignite.contrib.handlers.tensorboard_logger.global_step_from_engine" title="ignite.contrib.handlers.tensorboard_logger.global_step_from_engine"><code class="xref py py-meth docutils literal notranslate"><span class="pre">global_step_from_engine()</span></code></a>.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Example of <cite>global_step_transform</cite>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">global_step_transform</span><span class="p">(</span><span class="n">engine</span><span class="p">,</span> <span class="n">event_name</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">get_event_attrib_value</span><span class="p">(</span><span class="n">event_name</span><span class="p">)</span>
</pre></div>
</div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.tensorboard_logger.TensorboardLogger">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.tensorboard_logger.</span></span><span class="sig-name descname"><span class="pre">TensorboardLogger</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/tensorboard_logger.html#TensorboardLogger"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.tensorboard_logger.TensorboardLogger" title="Permalink to this definition">#</a></dt>
<dd><p>TensorBoard handler to log metrics, model/optimizer parameters, gradients during the training and validation.</p>
<p>By default, this class favors <a class="reference external" href="https://github.com/lanpa/tensorboardX">tensorboardX</a> package if installed:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>tensorboardX
</pre></div>
</div>
<p>otherwise, it falls back to using PyTorch’s SummaryWriter (&gt;=v1.2.0).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>*args</strong> – Positional arguments accepted from <code class="xref py py-class docutils literal notranslate"><span class="pre">SummaryWriter</span></code>.</p></li>
<li><p><strong>**kwargs</strong> – Keyword arguments accepted from <code class="xref py py-class docutils literal notranslate"><span class="pre">SummaryWriter</span></code>, for example,
<cite>log_dir</cite> to setup path to the directory where to log.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.tensorboard_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">tb_logger</span> <span class="o">=</span> <span class="n">TensorboardLogger</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;experiments/tb_logs&quot;</span><span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log training loss at each iteration</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s2">&quot;training&quot;</span><span class="p">,</span> <span class="n">output_transform</span><span class="o">=</span><span class="k">lambda</span> <span class="n">loss</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">}),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">)</span>

<span class="c1"># Attach the logger to the evaluator on the training dataset and log NLL, Accuracy metrics after each epoch</span>
<span class="c1"># We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch</span>
<span class="c1"># of the `trainer` instead of `train_evaluator`.</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">train_evaluator</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s2">&quot;training&quot;</span><span class="p">,</span>
                                           <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
                                           <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">)),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">)</span>

<span class="c1"># Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="c1"># each epoch. We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch of the</span>
<span class="c1"># `trainer` instead of `evaluator`.</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">evaluator</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
                                           <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
                                           <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">)),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log optimizer&#39;s parameters, e.g. learning rate at each iteration</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">OptimizerParamsHandler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log model&#39;s weights norm after each iteration</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">WeightsScalarHandler</span><span class="p">(</span><span class="n">model</span><span class="p">),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log model&#39;s weights as a histogram after each epoch</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">WeightsHistHandler</span><span class="p">(</span><span class="n">model</span><span class="p">),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log model&#39;s gradients norm after each iteration</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">GradsScalarHandler</span><span class="p">(</span><span class="n">model</span><span class="p">),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log model&#39;s gradients as a histogram after each epoch</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">GradsHistHandler</span><span class="p">(</span><span class="n">model</span><span class="p">),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">)</span>

<span class="c1"># We need to close the logger with we are done</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
<p>It is also possible to use the logger as context manager:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.tensorboard_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="k">with</span> <span class="n">TensorboardLogger</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;experiments/tb_logs&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">tb_logger</span><span class="p">:</span>

    <span class="n">trainer</span> <span class="o">=</span> <span class="n">Engine</span><span class="p">(</span><span class="n">update_fn</span><span class="p">)</span>
    <span class="c1"># Attach the logger to the trainer to log training loss at each iteration</span>
    <span class="n">tb_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span>
                     <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s2">&quot;training&quot;</span><span class="p">,</span>
                                               <span class="n">output_transform</span><span class="o">=</span><span class="k">lambda</span> <span class="n">loss</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">}),</span>
                     <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.tensorboard_logger.TensorboardLogger.attach">
<span class="sig-name descname"><span class="pre">attach</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">engine</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_handler</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">event_name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ignite.contrib.handlers.tensorboard_logger.TensorboardLogger.attach" title="Permalink to this definition">#</a></dt>
<dd><p>Attach the logger to the engine and execute <cite>log_handler</cite> function at <cite>event_name</cite> events.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.Engine" title="ignite.engine.Engine"><em>Engine</em></a>) – engine object.</p></li>
<li><p><strong>log_handler</strong> (<em>callable</em>) – a logging handler to execute</p></li>
<li><p><strong>event_name</strong> – event to attach the logging handler to. Valid events are from <a class="reference internal" href="../engine.html#ignite.engine.Events" title="ignite.engine.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a>
or any <cite>event_name</cite> added by <a class="reference internal" href="../engine.html#ignite.engine.Engine.register_events" title="ignite.engine.Engine.register_events"><code class="xref py py-meth docutils literal notranslate"><span class="pre">register_events()</span></code></a>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.tensorboard_logger.WeightsHistHandler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.tensorboard_logger.</span></span><span class="sig-name descname"><span class="pre">WeightsHistHandler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tag</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/tensorboard_logger.html#WeightsHistHandler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.tensorboard_logger.WeightsHistHandler" title="Permalink to this definition">#</a></dt>
<dd><p>Helper handler to log model’s weights as histograms.</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.tensorboard_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">tb_logger</span> <span class="o">=</span> <span class="n">TensorboardLogger</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;experiments/tb_logs&quot;</span><span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log model&#39;s weights norm after each iteration</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">WeightsHistHandler</span><span class="p">(</span><span class="n">model</span><span class="p">),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.10)"><em>torch.nn.Module</em></a>) – model to log weights</p></li>
<li><p><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) – common title for all produced plots. For example, ‘generator’</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.tensorboard_logger.WeightsScalarHandler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.tensorboard_logger.</span></span><span class="sig-name descname"><span class="pre">WeightsScalarHandler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction=&lt;function</span> <span class="pre">norm&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tag=None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/tensorboard_logger.html#WeightsScalarHandler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.tensorboard_logger.WeightsScalarHandler" title="Permalink to this definition">#</a></dt>
<dd><p>Helper handler to log model’s weights as scalars.
Handler iterates over named parameters of the model, applies reduction function to each parameter
produce a scalar and then logs the scalar.</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.tensorboard_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">tb_logger</span> <span class="o">=</span> <span class="n">TensorboardLogger</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;experiments/tb_logs&quot;</span><span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log model&#39;s weights norm after each iteration</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">WeightsScalarHandler</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.10)"><em>torch.nn.Module</em></a>) – model to log weights</p></li>
<li><p><strong>reduction</strong> (<em>callable</em>) – function to reduce parameters into scalar</p></li>
<li><p><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) – common title for all produced plots. For example, ‘generator’</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ignite.contrib.handlers.tensorboard_logger.global_step_from_engine">
<span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.tensorboard_logger.</span></span><span class="sig-name descname"><span class="pre">global_step_from_engine</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">engine</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/handlers.html#global_step_from_engine"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.tensorboard_logger.global_step_from_engine" title="Permalink to this definition">#</a></dt>
<dd><p>Helper method to setup <cite>global_step_transform</cite> function using another engine.
This can be helpful for logging trainer epoch/iteration while output handler is attached to an evaluator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.Engine" title="ignite.engine.Engine"><em>Engine</em></a>) – engine which state is used to provide the global step</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>global step</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="visdom-logger">
<h2>visdom_logger<a class="headerlink" href="#visdom-logger" title="Permalink to this heading">#</a></h2>
<p>See <a class="reference external" href="https://github.com/pytorch/ignite/blob/master/examples/contrib/mnist/mnist_with_visdom_logger.py">visdom mnist example</a>
for detailed usage.</p>
<span class="target" id="module-ignite.contrib.handlers.visdom_logger"></span><dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.visdom_logger.GradsScalarHandler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.visdom_logger.</span></span><span class="sig-name descname"><span class="pre">GradsScalarHandler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction=&lt;function</span> <span class="pre">norm&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tag=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_legend=False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/visdom_logger.html#GradsScalarHandler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.visdom_logger.GradsScalarHandler" title="Permalink to this definition">#</a></dt>
<dd><p>Helper handler to log model’s gradients as scalars.
Handler iterates over the gradients of named parameters of the model, applies reduction function to each parameter
produce a scalar and then logs the scalar.</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.visdom_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">vd_logger</span> <span class="o">=</span> <span class="n">VisdomLogger</span><span class="p">()</span>

<span class="c1"># Attach the logger to the trainer to log model&#39;s weights norm after each iteration</span>
<span class="n">vd_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">GradsScalarHandler</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.10)"><em>torch.nn.Module</em></a>) – model to log weights</p></li>
<li><p><strong>reduction</strong> (<em>callable</em>) – function to reduce parameters into scalar</p></li>
<li><p><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) – common title for all produced plots. For example, ‘generator’</p></li>
<li><p><strong>show_legend</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) – flag to show legend in the window</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.visdom_logger.GradsScalarHandler.add_scalar">
<span class="sig-name descname"><span class="pre">add_scalar</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">logger</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">event_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">global_step</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ignite.contrib.handlers.visdom_logger.GradsScalarHandler.add_scalar" title="Permalink to this definition">#</a></dt>
<dd><p>Helper method to log a scalar with VisdomLogger.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>logger</strong> (<a class="reference internal" href="#ignite.contrib.handlers.visdom_logger.VisdomLogger" title="ignite.contrib.handlers.visdom_logger.VisdomLogger"><em>VisdomLogger</em></a>) – visdom logger</p></li>
<li><p><strong>k</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) – scalar name which is used to set window title and y-axis label</p></li>
<li><p><strong>v</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a>) – scalar value, y-axis value</p></li>
<li><p><strong>event_name</strong> – Event name which is used to setup x-axis label. Valid events are from
<a class="reference internal" href="../engine.html#ignite.engine.Events" title="ignite.engine.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a> or any <cite>event_name</cite> added by
<a class="reference internal" href="../engine.html#ignite.engine.Engine.register_events" title="ignite.engine.Engine.register_events"><code class="xref py py-meth docutils literal notranslate"><span class="pre">register_events()</span></code></a>.</p></li>
<li><p><strong>global_step</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a>) – global step, x-axis value</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.visdom_logger.OptimizerParamsHandler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.visdom_logger.</span></span><span class="sig-name descname"><span class="pre">OptimizerParamsHandler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'lr'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tag</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_legend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/visdom_logger.html#OptimizerParamsHandler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.visdom_logger.OptimizerParamsHandler" title="Permalink to this definition">#</a></dt>
<dd><p>Helper handler to log optimizer parameters</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.visdom_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">vb_logger</span> <span class="o">=</span> <span class="n">VisdomLogger</span><span class="p">()</span>

<span class="c1"># Attach the logger to the trainer to log optimizer&#39;s parameters, e.g. learning rate at each iteration</span>
<span class="n">vb_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">OptimizerParamsHandler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch v2.10)"><em>torch.optim.Optimizer</em></a>) – torch optimizer which parameters to log</p></li>
<li><p><strong>param_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) – parameter name</p></li>
<li><p><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) – common title for all produced plots. For example, ‘generator’</p></li>
<li><p><strong>show_legend</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) – flag to show legend in the window</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.visdom_logger.OptimizerParamsHandler.add_scalar">
<span class="sig-name descname"><span class="pre">add_scalar</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">logger</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">event_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">global_step</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ignite.contrib.handlers.visdom_logger.OptimizerParamsHandler.add_scalar" title="Permalink to this definition">#</a></dt>
<dd><p>Helper method to log a scalar with VisdomLogger.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>logger</strong> (<a class="reference internal" href="#ignite.contrib.handlers.visdom_logger.VisdomLogger" title="ignite.contrib.handlers.visdom_logger.VisdomLogger"><em>VisdomLogger</em></a>) – visdom logger</p></li>
<li><p><strong>k</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) – scalar name which is used to set window title and y-axis label</p></li>
<li><p><strong>v</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a>) – scalar value, y-axis value</p></li>
<li><p><strong>event_name</strong> – Event name which is used to setup x-axis label. Valid events are from
<a class="reference internal" href="../engine.html#ignite.engine.Events" title="ignite.engine.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a> or any <cite>event_name</cite> added by
<a class="reference internal" href="../engine.html#ignite.engine.Engine.register_events" title="ignite.engine.Engine.register_events"><code class="xref py py-meth docutils literal notranslate"><span class="pre">register_events()</span></code></a>.</p></li>
<li><p><strong>global_step</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a>) – global step, x-axis value</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.visdom_logger.OutputHandler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.visdom_logger.</span></span><span class="sig-name descname"><span class="pre">OutputHandler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tag</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">another_engine</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">global_step_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_legend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/visdom_logger.html#OutputHandler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.visdom_logger.OutputHandler" title="Permalink to this definition">#</a></dt>
<dd><p>Helper handler to log engine’s output and/or metrics</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.visdom_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">vd_logger</span> <span class="o">=</span> <span class="n">VisdomLogger</span><span class="p">()</span>

<span class="c1"># Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="c1"># each epoch. We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch of</span>
<span class="c1"># the `trainer`:</span>
<span class="n">vd_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">evaluator</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
                                           <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
                                           <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">)),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">)</span>
</pre></div>
</div>
<p>Example with CustomPeriodicEvent, where model is evaluated every 500 iterations:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers</span><span class="w"> </span><span class="kn">import</span> <span class="n">CustomPeriodicEvent</span>

<span class="n">cpe</span> <span class="o">=</span> <span class="n">CustomPeriodicEvent</span><span class="p">(</span><span class="n">n_iterations</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="n">cpe</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>

<span class="nd">@trainer</span><span class="o">.</span><span class="n">on</span><span class="p">(</span><span class="n">cpe</span><span class="o">.</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATIONS_500_COMPLETED</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span><span class="n">engine</span><span class="p">):</span>
    <span class="n">evaluator</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">validation_set</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.visdom_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="n">vd_logger</span> <span class="o">=</span> <span class="n">VisdomLogger</span><span class="p">()</span>

<span class="k">def</span><span class="w"> </span><span class="nf">global_step_transform</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">trainer</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">iteration</span>

<span class="c1"># Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="c1"># every 500 iterations. Since evaluator engine does not have CustomPeriodicEvent attached to it, we</span>
<span class="c1"># provide a global_step_transform to return the trainer.state.iteration for the global_step, each time</span>
<span class="c1"># evaluator metrics are plotted on Visdom.</span>


<span class="n">vd_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">evaluator</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
                                           <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
                                           <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_transform</span><span class="p">),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) – common title for all produced plots. For example, ‘training’</p></li>
<li><p><strong>metric_names</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.14)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) – list of metric names to plot or a string “all” to plot all available
metrics.</p></li>
<li><p><strong>output_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – output transform function to prepare <cite>engine.state.output</cite> as a number.
For example, <cite>output_transform = lambda output: output</cite>
This function can also return a dictionary, e.g <cite>{‘loss’: loss1, `another_loss</cite>: loss2}` to label the plot
with corresponding keys.</p></li>
<li><p><strong>another_engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.Engine" title="ignite.engine.Engine"><em>Engine</em></a>) – Deprecated (see <code class="xref py py-attr docutils literal notranslate"><span class="pre">global_step_transform</span></code>). Another engine to use to provide the
value of event. Typically, user can provide
the trainer if this handler is attached to an evaluator and thus it logs proper trainer’s
epoch/iteration value.</p></li>
<li><p><strong>global_step_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – global step transform function to output a desired global step.
Input of the function is <cite>(engine, event_name)</cite>. Output of function should be an integer.
Default is None, global_step based on attached engine. If provided,
uses function output as global_step. To setup global step from another engine, please use
<a class="reference internal" href="#ignite.contrib.handlers.visdom_logger.global_step_from_engine" title="ignite.contrib.handlers.visdom_logger.global_step_from_engine"><code class="xref py py-meth docutils literal notranslate"><span class="pre">global_step_from_engine()</span></code></a>.</p></li>
<li><p><strong>show_legend</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) – flag to show legend in the window</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Example of <cite>global_step_transform</cite>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">global_step_transform</span><span class="p">(</span><span class="n">engine</span><span class="p">,</span> <span class="n">event_name</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">get_event_attrib_value</span><span class="p">(</span><span class="n">event_name</span><span class="p">)</span>
</pre></div>
</div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.visdom_logger.OutputHandler.add_scalar">
<span class="sig-name descname"><span class="pre">add_scalar</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">logger</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">event_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">global_step</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ignite.contrib.handlers.visdom_logger.OutputHandler.add_scalar" title="Permalink to this definition">#</a></dt>
<dd><p>Helper method to log a scalar with VisdomLogger.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>logger</strong> (<a class="reference internal" href="#ignite.contrib.handlers.visdom_logger.VisdomLogger" title="ignite.contrib.handlers.visdom_logger.VisdomLogger"><em>VisdomLogger</em></a>) – visdom logger</p></li>
<li><p><strong>k</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) – scalar name which is used to set window title and y-axis label</p></li>
<li><p><strong>v</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a>) – scalar value, y-axis value</p></li>
<li><p><strong>event_name</strong> – Event name which is used to setup x-axis label. Valid events are from
<a class="reference internal" href="../engine.html#ignite.engine.Events" title="ignite.engine.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a> or any <cite>event_name</cite> added by
<a class="reference internal" href="../engine.html#ignite.engine.Engine.register_events" title="ignite.engine.Engine.register_events"><code class="xref py py-meth docutils literal notranslate"><span class="pre">register_events()</span></code></a>.</p></li>
<li><p><strong>global_step</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a>) – global step, x-axis value</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.visdom_logger.VisdomLogger">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.visdom_logger.</span></span><span class="sig-name descname"><span class="pre">VisdomLogger</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">server</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">port</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_workers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/visdom_logger.html#VisdomLogger"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.visdom_logger.VisdomLogger" title="Permalink to this definition">#</a></dt>
<dd><p>VisdomLogger handler to log metrics, model/optimizer parameters, gradients during the training and validation.</p>
<p>This class requires <a class="reference external" href="https://github.com/facebookresearch/visdom/">visdom</a> package to be installed:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>git+https://github.com/facebookresearch/visdom.git
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>server</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) – visdom server URL. It can be also specified by environment variable <cite>VISDOM_SERVER_URL</cite></p></li>
<li><p><strong>port</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><em>optional</em>) – visdom server’s port. It can be also specified by environment variable <cite>VISDOM_PORT</cite></p></li>
<li><p><strong>num_workers</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><em>optional</em>) – number of workers to use in <cite>concurrent.futures.ThreadPoolExecutor</cite> to post data to
visdom server. Default, <cite>num_workers=1</cite>. If <cite>num_workers=0</cite> and logger uses the main thread. If using
Python 2.7 and <cite>num_workers&gt;0</cite> the package <cite>futures</cite> should be installed: <cite>pip install futures</cite></p></li>
<li><p><strong>**kwargs</strong> – kwargs to pass into
<a class="reference external" href="https://github.com/facebookresearch/visdom#visdom-arguments-python-only">visdom.Visdom</a>.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We can also specify username/password using environment variables: VISDOM_USERNAME, VISDOM_PASSWORD</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Frequent logging, e.g. when logger is attached to <cite>Events.ITERATION_COMPLETED</cite>, can slow down the run if the
main thread is used to send the data to visdom server (<cite>num_workers=0</cite>). To avoid this situation we can either
log less frequently or set <cite>num_workers=1</cite>.</p>
</div>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.visdom_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">vd_logger</span> <span class="o">=</span> <span class="n">VisdomLogger</span><span class="p">()</span>

<span class="c1"># Attach the logger to the trainer to log training loss at each iteration</span>
<span class="n">vd_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s2">&quot;training&quot;</span><span class="p">,</span> <span class="n">output_transform</span><span class="o">=</span><span class="k">lambda</span> <span class="n">loss</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">}),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">)</span>

<span class="c1"># Attach the logger to the evaluator on the training dataset and log NLL, Accuracy metrics after each epoch</span>
<span class="c1"># We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch</span>
<span class="c1"># of the `trainer` instead of `train_evaluator`:</span>
<span class="n">vd_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">train_evaluator</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s2">&quot;training&quot;</span><span class="p">,</span>
                                           <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
                                           <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">)),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">)</span>

<span class="c1"># Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="c1"># each epoch. We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch of</span>
<span class="c1"># the `trainer` instead of `evaluator`:</span>
<span class="n">vd_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">evaluator</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
                                           <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
                                           <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log optimizer&#39;s parameters, e.g. learning rate at each iteration</span>
<span class="n">vd_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">optimizer_params_handler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log model&#39;s weights norm after each iteration</span>
<span class="n">vd_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">weights_scalar_handler</span><span class="p">(</span><span class="n">model</span><span class="p">),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log model&#39;s gradients norm after each iteration</span>
<span class="n">vd_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">grads_scalar_handler</span><span class="p">(</span><span class="n">model</span><span class="p">),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">)</span>

<span class="c1"># We need to close the logger with we are done</span>
<span class="n">vd_logger</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
<p>It is also possible to use the logger as context manager:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.visdom_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="k">with</span> <span class="n">VisdomLogger</span><span class="p">()</span> <span class="k">as</span> <span class="n">vd_logger</span><span class="p">:</span>

    <span class="n">trainer</span> <span class="o">=</span> <span class="n">Engine</span><span class="p">(</span><span class="n">update_fn</span><span class="p">)</span>
    <span class="c1"># Attach the logger to the trainer to log training loss at each iteration</span>
    <span class="n">vd_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span>
                     <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s2">&quot;training&quot;</span><span class="p">,</span>
                                               <span class="n">output_transform</span><span class="o">=</span><span class="k">lambda</span> <span class="n">loss</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">}),</span>
                     <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.visdom_logger.VisdomLogger.attach">
<span class="sig-name descname"><span class="pre">attach</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">engine</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_handler</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">event_name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ignite.contrib.handlers.visdom_logger.VisdomLogger.attach" title="Permalink to this definition">#</a></dt>
<dd><p>Attach the logger to the engine and execute <cite>log_handler</cite> function at <cite>event_name</cite> events.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.Engine" title="ignite.engine.Engine"><em>Engine</em></a>) – engine object.</p></li>
<li><p><strong>log_handler</strong> (<em>callable</em>) – a logging handler to execute</p></li>
<li><p><strong>event_name</strong> – event to attach the logging handler to. Valid events are from <a class="reference internal" href="../engine.html#ignite.engine.Events" title="ignite.engine.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a>
or any <cite>event_name</cite> added by <a class="reference internal" href="../engine.html#ignite.engine.Engine.register_events" title="ignite.engine.Engine.register_events"><code class="xref py py-meth docutils literal notranslate"><span class="pre">register_events()</span></code></a>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.visdom_logger.WeightsScalarHandler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.visdom_logger.</span></span><span class="sig-name descname"><span class="pre">WeightsScalarHandler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction=&lt;function</span> <span class="pre">norm&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tag=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_legend=False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/visdom_logger.html#WeightsScalarHandler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.visdom_logger.WeightsScalarHandler" title="Permalink to this definition">#</a></dt>
<dd><p>Helper handler to log model’s weights as scalars.
Handler iterates over named parameters of the model, applies reduction function to each parameter
produce a scalar and then logs the scalar.</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.visdom_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">vd_logger</span> <span class="o">=</span> <span class="n">VisdomLogger</span><span class="p">()</span>

<span class="c1"># Attach the logger to the trainer to log model&#39;s weights norm after each iteration</span>
<span class="n">vd_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">WeightsScalarHandler</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.10)"><em>torch.nn.Module</em></a>) – model to log weights</p></li>
<li><p><strong>reduction</strong> (<em>callable</em>) – function to reduce parameters into scalar</p></li>
<li><p><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) – common title for all produced plots. For example, ‘generator’</p></li>
<li><p><strong>show_legend</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) – flag to show legend in the window</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.visdom_logger.WeightsScalarHandler.add_scalar">
<span class="sig-name descname"><span class="pre">add_scalar</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">logger</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">event_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">global_step</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ignite.contrib.handlers.visdom_logger.WeightsScalarHandler.add_scalar" title="Permalink to this definition">#</a></dt>
<dd><p>Helper method to log a scalar with VisdomLogger.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>logger</strong> (<a class="reference internal" href="#ignite.contrib.handlers.visdom_logger.VisdomLogger" title="ignite.contrib.handlers.visdom_logger.VisdomLogger"><em>VisdomLogger</em></a>) – visdom logger</p></li>
<li><p><strong>k</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) – scalar name which is used to set window title and y-axis label</p></li>
<li><p><strong>v</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a>) – scalar value, y-axis value</p></li>
<li><p><strong>event_name</strong> – Event name which is used to setup x-axis label. Valid events are from
<a class="reference internal" href="../engine.html#ignite.engine.Events" title="ignite.engine.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a> or any <cite>event_name</cite> added by
<a class="reference internal" href="../engine.html#ignite.engine.Engine.register_events" title="ignite.engine.Engine.register_events"><code class="xref py py-meth docutils literal notranslate"><span class="pre">register_events()</span></code></a>.</p></li>
<li><p><strong>global_step</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a>) – global step, x-axis value</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ignite.contrib.handlers.visdom_logger.global_step_from_engine">
<span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.visdom_logger.</span></span><span class="sig-name descname"><span class="pre">global_step_from_engine</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">engine</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/handlers.html#global_step_from_engine"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.visdom_logger.global_step_from_engine" title="Permalink to this definition">#</a></dt>
<dd><p>Helper method to setup <cite>global_step_transform</cite> function using another engine.
This can be helpful for logging trainer epoch/iteration while output handler is attached to an evaluator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.Engine" title="ignite.engine.Engine"><em>Engine</em></a>) – engine which state is used to provide the global step</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>global step</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-ignite.contrib.handlers.mlflow_logger">
<span id="mlflow-logger"></span><h2>mlflow_logger<a class="headerlink" href="#module-ignite.contrib.handlers.mlflow_logger" title="Permalink to this heading">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.mlflow_logger.MLflowLogger">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.mlflow_logger.</span></span><span class="sig-name descname"><span class="pre">MLflowLogger</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tracking_uri</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/mlflow_logger.html#MLflowLogger"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.mlflow_logger.MLflowLogger" title="Permalink to this definition">#</a></dt>
<dd><p><a class="reference external" href="https://mlflow.org">MLflow</a> tracking client handler to log parameters and metrics during the training
and validation.</p>
<p>This class requires <a class="reference external" href="https://github.com/mlflow/mlflow/">mlflow package</a> to be installed:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>mlflow
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tracking_uri</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) – MLflow tracking uri. See MLflow docs for more details</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.mlflow_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">mlflow_logger</span> <span class="o">=</span> <span class="n">MLflowLogger</span><span class="p">()</span>

<span class="c1"># Log experiment parameters:</span>
<span class="n">mlflow_logger</span><span class="o">.</span><span class="n">log_params</span><span class="p">(</span><span class="o">**</span><span class="p">{</span>
    <span class="s2">&quot;seed&quot;</span><span class="p">:</span> <span class="n">seed</span><span class="p">,</span>
    <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="n">batch_size</span><span class="p">,</span>
    <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>

    <span class="s2">&quot;pytorch version&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
    <span class="s2">&quot;ignite version&quot;</span><span class="p">:</span> <span class="n">ignite</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
    <span class="s2">&quot;cuda version&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">version</span><span class="o">.</span><span class="n">cuda</span><span class="p">,</span>
    <span class="s2">&quot;device name&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_name</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="p">})</span>

<span class="c1"># Attach the logger to the evaluator on the training dataset and log NLL, Accuracy metrics after each epoch</span>
<span class="c1"># We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch</span>
<span class="c1"># of the `trainer` instead of `train_evaluator`.</span>
<span class="n">mlflow_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">train_evaluator</span><span class="p">,</span>
                     <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s2">&quot;training&quot;</span><span class="p">,</span>
                                               <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
                                               <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">)),</span>
                     <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">)</span>

<span class="c1"># Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="c1"># each epoch. We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch of the</span>
<span class="c1"># `trainer` instead of `evaluator`.</span>
<span class="n">mlflow_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">evaluator</span><span class="p">,</span>
                     <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
                                               <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
                                               <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">)),</span>
                     <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.mlflow_logger.MLflowLogger.attach">
<span class="sig-name descname"><span class="pre">attach</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">engine</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_handler</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">event_name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ignite.contrib.handlers.mlflow_logger.MLflowLogger.attach" title="Permalink to this definition">#</a></dt>
<dd><p>Attach the logger to the engine and execute <cite>log_handler</cite> function at <cite>event_name</cite> events.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.Engine" title="ignite.engine.Engine"><em>Engine</em></a>) – engine object.</p></li>
<li><p><strong>log_handler</strong> (<em>callable</em>) – a logging handler to execute</p></li>
<li><p><strong>event_name</strong> – event to attach the logging handler to. Valid events are from <a class="reference internal" href="../engine.html#ignite.engine.Events" title="ignite.engine.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a>
or any <cite>event_name</cite> added by <a class="reference internal" href="../engine.html#ignite.engine.Engine.register_events" title="ignite.engine.Engine.register_events"><code class="xref py py-meth docutils literal notranslate"><span class="pre">register_events()</span></code></a>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.mlflow_logger.OptimizerParamsHandler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.mlflow_logger.</span></span><span class="sig-name descname"><span class="pre">OptimizerParamsHandler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'lr'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tag</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/mlflow_logger.html#OptimizerParamsHandler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.mlflow_logger.OptimizerParamsHandler" title="Permalink to this definition">#</a></dt>
<dd><p>Helper handler to log optimizer parameters</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.mlflow_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">mlflow_logger</span> <span class="o">=</span> <span class="n">MLflowLogger</span><span class="p">()</span>
<span class="c1"># Optionally, user can specify tracking_uri with corresponds to MLFLOW_TRACKING_URI</span>
<span class="c1"># mlflow_logger = MLflowLogger(tracking_uri=&quot;uri&quot;)</span>

<span class="c1"># Attach the logger to the trainer to log optimizer&#39;s parameters, e.g. learning rate at each iteration</span>
<span class="n">mlflow_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span>
                     <span class="n">log_handler</span><span class="o">=</span><span class="n">OptimizerParamsHandler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">),</span>
                     <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch v2.10)"><em>torch.optim.Optimizer</em></a>) – torch optimizer which parameters to log</p></li>
<li><p><strong>param_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) – parameter name</p></li>
<li><p><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) – common title for all produced plots. For example, ‘generator’</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.mlflow_logger.OutputHandler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.mlflow_logger.</span></span><span class="sig-name descname"><span class="pre">OutputHandler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tag</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">another_engine</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">global_step_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/mlflow_logger.html#OutputHandler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.mlflow_logger.OutputHandler" title="Permalink to this definition">#</a></dt>
<dd><p>Helper handler to log engine’s output and/or metrics.</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.mlflow_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">mlflow_logger</span> <span class="o">=</span> <span class="n">MLflowLogger</span><span class="p">()</span>

<span class="c1"># Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="c1"># each epoch. We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch</span>
<span class="c1"># of the `trainer`:</span>
<span class="n">mlflow_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">evaluator</span><span class="p">,</span>
                     <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
                                               <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
                                               <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">)),</span>
                     <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">)</span>
</pre></div>
</div>
<p>Example with CustomPeriodicEvent, where model is evaluated every 500 iterations:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers</span><span class="w"> </span><span class="kn">import</span> <span class="n">CustomPeriodicEvent</span>

<span class="n">cpe</span> <span class="o">=</span> <span class="n">CustomPeriodicEvent</span><span class="p">(</span><span class="n">n_iterations</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="n">cpe</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>

<span class="nd">@trainer</span><span class="o">.</span><span class="n">on</span><span class="p">(</span><span class="n">cpe</span><span class="o">.</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATIONS_500_COMPLETED</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span><span class="n">engine</span><span class="p">):</span>
    <span class="n">evaluator</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">validation_set</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.mlflow_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="n">mlflow_logger</span> <span class="o">=</span> <span class="n">MLflowLogger</span><span class="p">()</span>

<span class="k">def</span><span class="w"> </span><span class="nf">global_step_transform</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">trainer</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">iteration</span>

<span class="c1"># Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="c1"># every 500 iterations. Since evaluator engine does not have CustomPeriodicEvent attached to it, we</span>
<span class="c1"># provide a global_step_transform to return the trainer.state.iteration for the global_step, each time</span>
<span class="c1"># evaluator metrics are plotted on MLflow.</span>

<span class="n">mlflow_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">evaluator</span><span class="p">,</span>
                    <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
                                              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
                                              <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_transform</span><span class="p">),</span>
                    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) – common title for all produced plots. For example, ‘training’</p></li>
<li><p><strong>metric_names</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.14)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) – list of metric names to plot or a string “all” to plot all available
metrics.</p></li>
<li><p><strong>output_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – output transform function to prepare <cite>engine.state.output</cite> as a number.
For example, <cite>output_transform = lambda output: output</cite>
This function can also return a dictionary, e.g <cite>{‘loss’: loss1, `another_loss</cite>: loss2}` to label the plot
with corresponding keys.</p></li>
<li><p><strong>another_engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.Engine" title="ignite.engine.Engine"><em>Engine</em></a>) – Deprecated (see <code class="xref py py-attr docutils literal notranslate"><span class="pre">global_step_transform</span></code>). Another engine to use to provide the
value of event. Typically, user can provide
the trainer if this handler is attached to an evaluator and thus it logs proper trainer’s
epoch/iteration value.</p></li>
<li><p><strong>global_step_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – global step transform function to output a desired global step.
Input of the function is <cite>(engine, event_name)</cite>. Output of function should be an integer.
Default is None, global_step based on attached engine. If provided,
uses function output as global_step. To setup global step from another engine, please use
<a class="reference internal" href="#ignite.contrib.handlers.mlflow_logger.global_step_from_engine" title="ignite.contrib.handlers.mlflow_logger.global_step_from_engine"><code class="xref py py-meth docutils literal notranslate"><span class="pre">global_step_from_engine()</span></code></a>.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Example of <cite>global_step_transform</cite>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">global_step_transform</span><span class="p">(</span><span class="n">engine</span><span class="p">,</span> <span class="n">event_name</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">get_event_attrib_value</span><span class="p">(</span><span class="n">event_name</span><span class="p">)</span>
</pre></div>
</div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ignite.contrib.handlers.mlflow_logger.global_step_from_engine">
<span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.mlflow_logger.</span></span><span class="sig-name descname"><span class="pre">global_step_from_engine</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">engine</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/handlers.html#global_step_from_engine"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.mlflow_logger.global_step_from_engine" title="Permalink to this definition">#</a></dt>
<dd><p>Helper method to setup <cite>global_step_transform</cite> function using another engine.
This can be helpful for logging trainer epoch/iteration while output handler is attached to an evaluator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.Engine" title="ignite.engine.Engine"><em>Engine</em></a>) – engine which state is used to provide the global step</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>global step</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-ignite.contrib.handlers.tqdm_logger">
<span id="tqdm-logger"></span><h2>tqdm_logger<a class="headerlink" href="#module-ignite.contrib.handlers.tqdm_logger" title="Permalink to this heading">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.tqdm_logger.ProgressBar">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.tqdm_logger.</span></span><span class="sig-name descname"><span class="pre">ProgressBar</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">persist</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bar_format</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'{desc}[{n_fmt}/{total_fmt}]</span> <span class="pre">{percentage:3.0f}%|{bar}{postfix}</span> <span class="pre">[{elapsed}&lt;{remaining}]'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">tqdm_kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/tqdm_logger.html#ProgressBar"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.tqdm_logger.ProgressBar" title="Permalink to this definition">#</a></dt>
<dd><p>TQDM progress bar handler to log training progress and computed metrics.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>persist</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) – set to <code class="docutils literal notranslate"><span class="pre">True</span></code> to persist the progress bar after completion (default = <code class="docutils literal notranslate"><span class="pre">False</span></code>)</p></li>
<li><p><strong>bar_format</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) – Specify a custom bar string formatting. May impact performance.
[default: ‘{desc}[{n_fmt}/{total_fmt}] {percentage:3.0f}%|{bar}{postfix} [{elapsed}&lt;{remaining}]’].
Set to <code class="docutils literal notranslate"><span class="pre">None</span></code> to use <code class="docutils literal notranslate"><span class="pre">tqdm</span></code> default bar formatting: ‘{l_bar}{bar}{r_bar}’, where
l_bar=’{desc}: {percentage:3.0f}%|’ and
r_bar=’| {n_fmt}/{total_fmt} [{elapsed}&lt;{remaining}, {rate_fmt}{postfix}]’. For more details on the
formatting, see <a class="reference external" href="https://tqdm.github.io/docs/tqdm/">tqdm docs</a>.</p></li>
<li><p><strong>**tqdm_kwargs</strong> – kwargs passed to tqdm progress bar.
By default, progress bar description displays “Epoch [5/10]” where 5 is the current epoch and 10 is the
number of epochs. If tqdm_kwargs defines <cite>desc</cite>, e.g. “Predictions”, than the description is
“Predictions [5/10]” if number of epochs is more than one otherwise it is simply “Predictions”.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>Simple progress bar</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span> <span class="o">=</span> <span class="n">create_supervised_trainer</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>

<span class="n">pbar</span> <span class="o">=</span> <span class="n">ProgressBar</span><span class="p">()</span>
<span class="n">pbar</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>

<span class="c1"># Progress bar will looks like</span>
<span class="c1"># Epoch [2/50]: [64/128]  50%|█████      [06:17&lt;12:34]</span>
</pre></div>
</div>
<p>Log output to a file instead of stderr (tqdm’s default output)</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span> <span class="o">=</span> <span class="n">create_supervised_trainer</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>

<span class="n">log_file</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;output.log&quot;</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span>
<span class="n">pbar</span> <span class="o">=</span> <span class="n">ProgressBar</span><span class="p">(</span><span class="n">file</span><span class="o">=</span><span class="n">log_file</span><span class="p">)</span>
<span class="n">pbar</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>
</pre></div>
</div>
<p>Attach metrics that already have been computed at <a class="reference internal" href="../engine.html#ignite.engine.Events.ITERATION_COMPLETED" title="ignite.engine.Events.ITERATION_COMPLETED"><code class="xref py py-attr docutils literal notranslate"><span class="pre">ITERATION_COMPLETED</span></code></a>
(such as <a class="reference internal" href="../metrics.html#ignite.metrics.RunningAverage" title="ignite.metrics.RunningAverage"><code class="xref py py-class docutils literal notranslate"><span class="pre">RunningAverage</span></code></a>)</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span> <span class="o">=</span> <span class="n">create_supervised_trainer</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>

<span class="n">RunningAverage</span><span class="p">(</span><span class="n">output_transform</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="s1">&#39;loss&#39;</span><span class="p">)</span>

<span class="n">pbar</span> <span class="o">=</span> <span class="n">ProgressBar</span><span class="p">()</span>
<span class="n">pbar</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">])</span>

<span class="c1"># Progress bar will looks like</span>
<span class="c1"># Epoch [2/50]: [64/128]  50%|█████      , loss=0.123 [06:17&lt;12:34]</span>
</pre></div>
</div>
<p>Directly attach the engine’s output</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span> <span class="o">=</span> <span class="n">create_supervised_trainer</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>

<span class="n">pbar</span> <span class="o">=</span> <span class="n">ProgressBar</span><span class="p">()</span>
<span class="n">pbar</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">output_transform</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">x</span><span class="p">})</span>

<span class="c1"># Progress bar will looks like</span>
<span class="c1"># Epoch [2/50]: [64/128]  50%|█████      , loss=0.123 [06:17&lt;12:34]</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When adding attaching the progress bar to an engine, it is recommend that you replace
every print operation in the engine’s handlers triggered every iteration with
<code class="docutils literal notranslate"><span class="pre">pbar.log_message</span></code> to guarantee the correct format of the stdout.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When using inside jupyter notebook, <cite>ProgressBar</cite> automatically uses <cite>tqdm_notebook</cite>. For correct rendering,
please install <a class="reference external" href="https://ipywidgets.readthedocs.io/en/stable/user_install.html#installation">ipywidgets</a>.
Due to <a class="reference external" href="https://github.com/tqdm/tqdm/issues/594">tqdm notebook bugs</a>, bar format may be needed to be set
to an empty string value.</p>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.tqdm_logger.ProgressBar.attach">
<span class="sig-name descname"><span class="pre">attach</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">engine</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">event_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">Events.ITERATION_COMPLETED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">closing_event_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">Events.EPOCH_COMPLETED</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/tqdm_logger.html#ProgressBar.attach"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.tqdm_logger.ProgressBar.attach" title="Permalink to this definition">#</a></dt>
<dd><p>Attaches the progress bar to an engine object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.Engine" title="ignite.engine.Engine"><em>Engine</em></a>) – engine object.</p></li>
<li><p><strong>metric_names</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.14)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) – list of metric names to plot or a string “all” to plot all available
metrics.</p></li>
<li><p><strong>output_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – a function to select what you want to print from the engine’s
output. This function may return either a dictionary with entries in the format of <code class="docutils literal notranslate"><span class="pre">{name:</span> <span class="pre">value}</span></code>,
or a single scalar, which will be displayed with the default name <cite>output</cite>.</p></li>
<li><p><strong>event_name</strong> – event’s name on which the progress bar advances. Valid events are from
<a class="reference internal" href="../engine.html#ignite.engine.Events" title="ignite.engine.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a>.</p></li>
<li><p><strong>closing_event_name</strong> – event’s name on which the progress bar is closed. Valid events are from
<a class="reference internal" href="../engine.html#ignite.engine.Events" title="ignite.engine.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a>.</p></li>
</ul>
</dd>
</dl>
<p>Note: accepted output value types are numbers, 0d and 1d torch tensors and strings</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.tqdm_logger.ProgressBar.log_message">
<span class="sig-name descname"><span class="pre">log_message</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">message</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/tqdm_logger.html#ProgressBar.log_message"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.tqdm_logger.ProgressBar.log_message" title="Permalink to this definition">#</a></dt>
<dd><p>Logs a message, preserving the progress bar correct output format.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>message</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) – string you wish to log.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-ignite.contrib.handlers.polyaxon_logger">
<span id="polyaxon-logger"></span><h2>polyaxon_logger<a class="headerlink" href="#module-ignite.contrib.handlers.polyaxon_logger" title="Permalink to this heading">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.polyaxon_logger.OptimizerParamsHandler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.polyaxon_logger.</span></span><span class="sig-name descname"><span class="pre">OptimizerParamsHandler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'lr'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tag</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/polyaxon_logger.html#OptimizerParamsHandler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.polyaxon_logger.OptimizerParamsHandler" title="Permalink to this definition">#</a></dt>
<dd><p>Helper handler to log optimizer parameters</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.polyaxon_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">plx_logger</span> <span class="o">=</span> <span class="n">PolyaxonLogger</span><span class="p">()</span>

<span class="c1"># Attach the logger to the trainer to log optimizer&#39;s parameters, e.g. learning rate at each iteration</span>
<span class="n">plx_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span>
                  <span class="n">log_handler</span><span class="o">=</span><span class="n">OptimizerParamsHandler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">),</span>
                  <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch v2.10)"><em>torch.optim.Optimizer</em></a>) – torch optimizer which parameters to log</p></li>
<li><p><strong>param_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) – parameter name</p></li>
<li><p><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) – common title for all produced plots. For example, ‘generator’</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.polyaxon_logger.OutputHandler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.polyaxon_logger.</span></span><span class="sig-name descname"><span class="pre">OutputHandler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tag</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">another_engine</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">global_step_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/polyaxon_logger.html#OutputHandler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.polyaxon_logger.OutputHandler" title="Permalink to this definition">#</a></dt>
<dd><p>Helper handler to log engine’s output and/or metrics.</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.polyaxon_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">plx_logger</span> <span class="o">=</span> <span class="n">PolyaxonLogger</span><span class="p">()</span>

<span class="c1"># Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="c1"># each epoch. We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch</span>
<span class="c1"># of the `trainer`:</span>
<span class="n">plx_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">evaluator</span><span class="p">,</span>
                  <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
                                            <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
                                            <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">)),</span>
                  <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">)</span>
</pre></div>
</div>
<p>Example with CustomPeriodicEvent, where model is evaluated every 500 iterations:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers</span><span class="w"> </span><span class="kn">import</span> <span class="n">CustomPeriodicEvent</span>

<span class="n">cpe</span> <span class="o">=</span> <span class="n">CustomPeriodicEvent</span><span class="p">(</span><span class="n">n_iterations</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="n">cpe</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>

<span class="nd">@trainer</span><span class="o">.</span><span class="n">on</span><span class="p">(</span><span class="n">cpe</span><span class="o">.</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATIONS_500_COMPLETED</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span><span class="n">engine</span><span class="p">):</span>
    <span class="n">evaluator</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">validation_set</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.polyaxon_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="n">plx_logger</span> <span class="o">=</span> <span class="n">PolyaxonLogger</span><span class="p">()</span>

<span class="k">def</span><span class="w"> </span><span class="nf">global_step_transform</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">trainer</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">iteration</span>

<span class="c1"># Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="c1"># every 500 iterations. Since evaluator engine does not have CustomPeriodicEvent attached to it, we</span>
<span class="c1"># provide a global_step_transform to return the trainer.state.iteration for the global_step, each time</span>
<span class="c1"># evaluator metrics are plotted on Polyaxon.</span>


<span class="n">plx_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">evaluator</span><span class="p">,</span>
                  <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
                                            <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
                                            <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_transform</span><span class="p">),</span>
                  <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) – common title for all produced plots. For example, ‘training’</p></li>
<li><p><strong>metric_names</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.14)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em>, </em><em>optional</em>) – list of metric names to plot or a string “all” to plot all available
metrics.</p></li>
<li><p><strong>output_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – output transform function to prepare <cite>engine.state.output</cite> as a number.
For example, <cite>output_transform = lambda output: output</cite>
This function can also return a dictionary, e.g <cite>{‘loss’: loss1, `another_loss</cite>: loss2}` to label the plot
with corresponding keys.</p></li>
<li><p><strong>another_engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.Engine" title="ignite.engine.Engine"><em>Engine</em></a>) – Deprecated (see <code class="xref py py-attr docutils literal notranslate"><span class="pre">global_step_transform</span></code>). Another engine to use to provide the
value of event. Typically, user can provide
the trainer if this handler is attached to an evaluator and thus it logs proper trainer’s
epoch/iteration value.</p></li>
<li><p><strong>global_step_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – global step transform function to output a desired global step.
Input of the function is <cite>(engine, event_name)</cite>. Output of function should be an integer.
Default is None, global_step based on attached engine. If provided,
uses function output as global_step. To setup global step from another engine, please use
<a class="reference internal" href="#ignite.contrib.handlers.polyaxon_logger.global_step_from_engine" title="ignite.contrib.handlers.polyaxon_logger.global_step_from_engine"><code class="xref py py-meth docutils literal notranslate"><span class="pre">global_step_from_engine()</span></code></a>.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Example of <cite>global_step_transform</cite>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">global_step_transform</span><span class="p">(</span><span class="n">engine</span><span class="p">,</span> <span class="n">event_name</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">get_event_attrib_value</span><span class="p">(</span><span class="n">event_name</span><span class="p">)</span>
</pre></div>
</div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ignite.contrib.handlers.polyaxon_logger.PolyaxonLogger">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.polyaxon_logger.</span></span><span class="sig-name descname"><span class="pre">PolyaxonLogger</span></span><a class="reference internal" href="../_modules/ignite/contrib/handlers/polyaxon_logger.html#PolyaxonLogger"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.polyaxon_logger.PolyaxonLogger" title="Permalink to this definition">#</a></dt>
<dd><p><a class="reference external" href="https://polyaxon.com/">Polyaxon</a> tracking client handler to log parameters and metrics during the training
and validation.</p>
<p>This class requires <a class="reference external" href="https://github.com/polyaxon/polyaxon-client/">polyaxon-client</a> package to be installed:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>polyaxon-client
</pre></div>
</div>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers.polyaxon_logger</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">plx_logger</span> <span class="o">=</span> <span class="n">PolyaxonLogger</span><span class="p">()</span>

<span class="c1"># Log experiment parameters:</span>
<span class="n">plx_logger</span><span class="o">.</span><span class="n">log_params</span><span class="p">(</span><span class="o">**</span><span class="p">{</span>
    <span class="s2">&quot;seed&quot;</span><span class="p">:</span> <span class="n">seed</span><span class="p">,</span>
    <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="n">batch_size</span><span class="p">,</span>
    <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>

    <span class="s2">&quot;pytorch version&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
    <span class="s2">&quot;ignite version&quot;</span><span class="p">:</span> <span class="n">ignite</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
    <span class="s2">&quot;cuda version&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">version</span><span class="o">.</span><span class="n">cuda</span><span class="p">,</span>
    <span class="s2">&quot;device name&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_name</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="p">})</span>

<span class="c1"># Attach the logger to the evaluator on the training dataset and log NLL, Accuracy metrics after each epoch</span>
<span class="c1"># We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch</span>
<span class="c1"># of the `trainer` instead of `train_evaluator`.</span>
<span class="n">plx_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">train_evaluator</span><span class="p">,</span>
                  <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s2">&quot;training&quot;</span><span class="p">,</span>
                                            <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
                                            <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">)),</span>
                  <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">)</span>

<span class="c1"># Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="c1"># each epoch. We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch of the</span>
<span class="c1"># `trainer` instead of `evaluator`.</span>
<span class="n">plx_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">evaluator</span><span class="p">,</span>
                  <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
                                            <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
                                            <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">)),</span>
                  <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="ignite.contrib.handlers.polyaxon_logger.PolyaxonLogger.attach">
<span class="sig-name descname"><span class="pre">attach</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">engine</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_handler</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">event_name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ignite.contrib.handlers.polyaxon_logger.PolyaxonLogger.attach" title="Permalink to this definition">#</a></dt>
<dd><p>Attach the logger to the engine and execute <cite>log_handler</cite> function at <cite>event_name</cite> events.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.Engine" title="ignite.engine.Engine"><em>Engine</em></a>) – engine object.</p></li>
<li><p><strong>log_handler</strong> (<em>callable</em>) – a logging handler to execute</p></li>
<li><p><strong>event_name</strong> – event to attach the logging handler to. Valid events are from <a class="reference internal" href="../engine.html#ignite.engine.Events" title="ignite.engine.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a>
or any <cite>event_name</cite> added by <a class="reference internal" href="../engine.html#ignite.engine.Engine.register_events" title="ignite.engine.Engine.register_events"><code class="xref py py-meth docutils literal notranslate"><span class="pre">register_events()</span></code></a>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ignite.contrib.handlers.polyaxon_logger.global_step_from_engine">
<span class="sig-prename descclassname"><span class="pre">ignite.contrib.handlers.polyaxon_logger.</span></span><span class="sig-name descname"><span class="pre">global_step_from_engine</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">engine</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/handlers.html#global_step_from_engine"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ignite.contrib.handlers.polyaxon_logger.global_step_from_engine" title="Permalink to this definition">#</a></dt>
<dd><p>Helper method to setup <cite>global_step_transform</cite> function using another engine.
This can be helpful for logging trainer epoch/iteration while output handler is attached to an evaluator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.Engine" title="ignite.engine.Engine"><em>Engine</em></a>) – engine which state is used to provide the global step</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>global step</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="more-on-parameter-scheduling">
<h2>More on parameter scheduling<a class="headerlink" href="#more-on-parameter-scheduling" title="Permalink to this heading">#</a></h2>
<p>In this section there are visual examples of various parameter schedulings that can be achieved.</p>
<section id="example-with-ignite-contrib-handlers-cosineannealingscheduler">
<h3>Example with <code class="xref py py-class docutils literal notranslate"><span class="pre">ignite.contrib.handlers.CosineAnnealingScheduler</span></code><a class="headerlink" href="#example-with-ignite-contrib-handlers-cosineannealingscheduler" title="Permalink to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pylab</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers</span><span class="w"> </span><span class="kn">import</span> <span class="n">CosineAnnealingScheduler</span>

<span class="n">lr_values_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">CosineAnnealingScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">75</span><span class="p">,</span> <span class="n">param_name</span><span class="o">=</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span>
                                                            <span class="n">start_value</span><span class="o">=</span><span class="mf">1e-1</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">2e-2</span><span class="p">,</span> <span class="n">cycle_size</span><span class="o">=</span><span class="mi">20</span><span class="p">))</span>

<span class="n">lr_values_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">CosineAnnealingScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">75</span><span class="p">,</span> <span class="n">param_name</span><span class="o">=</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span>
                                                                <span class="n">start_value</span><span class="o">=</span><span class="mf">1e-1</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">2e-2</span><span class="p">,</span> <span class="n">cycle_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">cycle_mult</span><span class="o">=</span><span class="mf">1.3</span><span class="p">))</span>

<span class="n">lr_values_3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">CosineAnnealingScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">75</span><span class="p">,</span> <span class="n">param_name</span><span class="o">=</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span>
                                                                <span class="n">start_value</span><span class="o">=</span><span class="mf">1e-1</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">2e-2</span><span class="p">,</span>
                                                                <span class="n">cycle_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">start_value_mult</span><span class="o">=</span><span class="mf">0.7</span><span class="p">))</span>

<span class="n">lr_values_4</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">CosineAnnealingScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">75</span><span class="p">,</span> <span class="n">param_name</span><span class="o">=</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span>
                                                                <span class="n">start_value</span><span class="o">=</span><span class="mf">1e-1</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">2e-2</span><span class="p">,</span>
                                                                <span class="n">cycle_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">end_value_mult</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))</span>


<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">141</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Cosine annealing&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.12</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">142</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Cosine annealing with cycle_mult=1.3&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.12</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">143</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Cosine annealing with start_value_mult=0.7&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_3</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_3</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.12</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">144</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Cosine annealing with end_value_mult=0.1&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_4</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_4</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.12</span><span class="p">])</span>
</pre></div>
</div>
<img alt="../_images/cosine_annealing_example.png" src="../_images/cosine_annealing_example.png" />
</section>
<section id="example-with-ignite-contrib-handlers-linearcyclicalscheduler">
<h3>Example with <code class="xref py py-class docutils literal notranslate"><span class="pre">ignite.contrib.handlers.LinearCyclicalScheduler</span></code><a class="headerlink" href="#example-with-ignite-contrib-handlers-linearcyclicalscheduler" title="Permalink to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pylab</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers</span><span class="w"> </span><span class="kn">import</span> <span class="n">LinearCyclicalScheduler</span>

<span class="n">lr_values_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">LinearCyclicalScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">75</span><span class="p">,</span> <span class="n">param_name</span><span class="o">=</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span>
                                                                <span class="n">start_value</span><span class="o">=</span><span class="mf">1e-1</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">2e-2</span><span class="p">,</span> <span class="n">cycle_size</span><span class="o">=</span><span class="mi">20</span><span class="p">))</span>

<span class="n">lr_values_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">LinearCyclicalScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">75</span><span class="p">,</span> <span class="n">param_name</span><span class="o">=</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span>
                                                                <span class="n">start_value</span><span class="o">=</span><span class="mf">1e-1</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">2e-2</span><span class="p">,</span> <span class="n">cycle_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">cycle_mult</span><span class="o">=</span><span class="mf">1.3</span><span class="p">))</span>

<span class="n">lr_values_3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">LinearCyclicalScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">75</span><span class="p">,</span> <span class="n">param_name</span><span class="o">=</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span>
                                                                <span class="n">start_value</span><span class="o">=</span><span class="mf">1e-1</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">2e-2</span><span class="p">,</span>
                                                                <span class="n">cycle_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">start_value_mult</span><span class="o">=</span><span class="mf">0.7</span><span class="p">))</span>

<span class="n">lr_values_4</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">LinearCyclicalScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">75</span><span class="p">,</span> <span class="n">param_name</span><span class="o">=</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span>
                                                                <span class="n">start_value</span><span class="o">=</span><span class="mf">1e-1</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">2e-2</span><span class="p">,</span>
                                                                <span class="n">cycle_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">end_value_mult</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))</span>


<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">141</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Linear cyclical scheduler&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.12</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">142</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Linear cyclical scheduler with cycle_mult=1.3&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.12</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">143</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Linear cyclical scheduler with start_value_mult=0.7&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_3</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_3</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.12</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">144</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Linear cyclical scheduler with end_value_mult=0.1&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_4</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_4</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.12</span><span class="p">])</span>
</pre></div>
</div>
<img alt="../_images/linear_cyclical_example.png" src="../_images/linear_cyclical_example.png" />
</section>
<section id="example-with-ignite-contrib-handlers-concatscheduler">
<h3>Example with <code class="xref py py-class docutils literal notranslate"><span class="pre">ignite.contrib.handlers.ConcatScheduler</span></code><a class="headerlink" href="#example-with-ignite-contrib-handlers-concatscheduler" title="Permalink to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pylab</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers</span><span class="w"> </span><span class="kn">import</span> <span class="n">LinearCyclicalScheduler</span><span class="p">,</span> <span class="n">CosineAnnealingScheduler</span><span class="p">,</span> <span class="n">ConcatScheduler</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="n">t1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">([</span><span class="n">t1</span><span class="p">],</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>


<span class="n">scheduler_1</span> <span class="o">=</span> <span class="n">LinearCyclicalScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="n">start_value</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">cycle_size</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">scheduler_2</span> <span class="o">=</span> <span class="n">CosineAnnealingScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="n">start_value</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">cycle_size</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="n">durations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">15</span><span class="p">,</span> <span class="p">]</span>

<span class="n">lr_values_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">ConcatScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">schedulers</span><span class="o">=</span><span class="p">[</span><span class="n">scheduler_1</span><span class="p">,</span> <span class="n">scheduler_2</span><span class="p">],</span> <span class="n">durations</span><span class="o">=</span><span class="n">durations</span><span class="p">))</span>


<span class="n">t1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">([</span><span class="n">t1</span><span class="p">],</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

<span class="n">scheduler_1</span> <span class="o">=</span> <span class="n">LinearCyclicalScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="n">start_value</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">cycle_size</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">scheduler_2</span> <span class="o">=</span> <span class="n">CosineAnnealingScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s2">&quot;momentum&quot;</span><span class="p">,</span> <span class="n">start_value</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">cycle_size</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="n">durations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">15</span><span class="p">,</span> <span class="p">]</span>

<span class="n">lr_values_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">ConcatScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">schedulers</span><span class="o">=</span><span class="p">[</span><span class="n">scheduler_1</span><span class="p">,</span> <span class="n">scheduler_2</span><span class="p">],</span> <span class="n">durations</span><span class="o">=</span><span class="n">durations</span><span class="p">,</span>
                                                        <span class="n">param_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="s2">&quot;momentum&quot;</span><span class="p">]))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">131</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Concat scheduler of linear + cosine annealing&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">132</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Concat scheduler of linear LR scheduler</span><span class="se">\n</span><span class="s2"> and cosine annealing on momentum&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">133</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Concat scheduler of linear LR scheduler</span><span class="se">\n</span><span class="s2"> and cosine annealing on momentum&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_2</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;momentum&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
<img alt="../_images/concat_example.png" src="../_images/concat_example.png" />
<section id="piecewise-linear-scheduler">
<h4>Piecewise linear scheduler<a class="headerlink" href="#piecewise-linear-scheduler" title="Permalink to this heading">#</a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pylab</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers</span><span class="w"> </span><span class="kn">import</span> <span class="n">LinearCyclicalScheduler</span><span class="p">,</span> <span class="n">ConcatScheduler</span>

<span class="n">scheduler_1</span> <span class="o">=</span> <span class="n">LinearCyclicalScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="n">start_value</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">cycle_size</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="n">scheduler_2</span> <span class="o">=</span> <span class="n">LinearCyclicalScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="n">start_value</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">cycle_size</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
<span class="n">durations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">25</span><span class="p">,</span> <span class="p">]</span>

<span class="n">lr_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">ConcatScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">schedulers</span><span class="o">=</span><span class="p">[</span><span class="n">scheduler_1</span><span class="p">,</span> <span class="n">scheduler_2</span><span class="p">],</span> <span class="n">durations</span><span class="o">=</span><span class="n">durations</span><span class="p">))</span>


<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Piecewise linear scheduler&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
<img alt="../_images/piecewise_linear.png" src="../_images/piecewise_linear.png" />
</section>
</section>
<section id="example-with-ignite-contrib-handlers-lrscheduler">
<h3>Example with <code class="xref py py-class docutils literal notranslate"><span class="pre">ignite.contrib.handlers.LRScheduler</span></code><a class="headerlink" href="#example-with-ignite-contrib-handlers-lrscheduler" title="Permalink to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pylab</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers</span><span class="w"> </span><span class="kn">import</span> <span class="n">LRScheduler</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim.lr_scheduler</span><span class="w"> </span><span class="kn">import</span> <span class="n">ExponentialLR</span><span class="p">,</span> <span class="n">StepLR</span><span class="p">,</span> <span class="n">CosineAnnealingLR</span>

<span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">([</span><span class="n">tensor</span><span class="p">],</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

<span class="n">lr_scheduler_1</span> <span class="o">=</span> <span class="n">StepLR</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.77</span><span class="p">)</span>
<span class="n">lr_scheduler_2</span> <span class="o">=</span> <span class="n">ExponentialLR</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.98</span><span class="p">)</span>
<span class="n">lr_scheduler_3</span> <span class="o">=</span> <span class="n">CosineAnnealingLR</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">T_max</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">eta_min</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

<span class="n">lr_values_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">LRScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">lr_scheduler</span><span class="o">=</span><span class="n">lr_scheduler_1</span><span class="p">))</span>
<span class="n">lr_values_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">LRScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">lr_scheduler</span><span class="o">=</span><span class="n">lr_scheduler_2</span><span class="p">))</span>
<span class="n">lr_values_3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">LRScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">lr_scheduler</span><span class="o">=</span><span class="n">lr_scheduler_3</span><span class="p">))</span>


<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">131</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Torch LR scheduler wrapping StepLR&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">132</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Torch LR scheduler wrapping ExponentialLR&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">133</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Torch LR scheduler wrapping CosineAnnealingLR&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_3</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_3</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
<img alt="../_images/lr_scheduler.png" src="../_images/lr_scheduler.png" />
<section id="concatenate-with-torch-schedulers">
<h4>Concatenate with torch schedulers<a class="headerlink" href="#concatenate-with-torch-schedulers" title="Permalink to this heading">#</a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pylab</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ignite.contrib.handlers</span><span class="w"> </span><span class="kn">import</span> <span class="n">LRScheduler</span><span class="p">,</span> <span class="n">ConcatScheduler</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim.lr_scheduler</span><span class="w"> </span><span class="kn">import</span> <span class="n">ExponentialLR</span><span class="p">,</span> <span class="n">StepLR</span>

<span class="n">t1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">([</span><span class="n">t1</span><span class="p">],</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

<span class="n">scheduler_1</span> <span class="o">=</span> <span class="n">LinearCyclicalScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="n">start_value</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">cycle_size</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">ExponentialLR</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">scheduler_2</span> <span class="o">=</span> <span class="n">LRScheduler</span><span class="p">(</span><span class="n">lr_scheduler</span><span class="o">=</span><span class="n">lr_scheduler</span><span class="p">)</span>
<span class="n">durations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">15</span><span class="p">,</span> <span class="p">]</span>
<span class="n">lr_values_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">ConcatScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">schedulers</span><span class="o">=</span><span class="p">[</span><span class="n">scheduler_1</span><span class="p">,</span> <span class="n">scheduler_2</span><span class="p">],</span> <span class="n">durations</span><span class="o">=</span><span class="n">durations</span><span class="p">))</span>


<span class="n">scheduler_1</span> <span class="o">=</span> <span class="n">LinearCyclicalScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="n">start_value</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">cycle_size</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">StepLR</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">scheduler_2</span> <span class="o">=</span> <span class="n">LRScheduler</span><span class="p">(</span><span class="n">lr_scheduler</span><span class="o">=</span><span class="n">lr_scheduler</span><span class="p">)</span>
<span class="n">durations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">15</span><span class="p">,</span> <span class="p">]</span>
<span class="n">lr_values_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">ConcatScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">75</span><span class="p">,</span> <span class="n">schedulers</span><span class="o">=</span><span class="p">[</span><span class="n">scheduler_1</span><span class="p">,</span> <span class="n">scheduler_2</span><span class="p">],</span> <span class="n">durations</span><span class="o">=</span><span class="n">durations</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Concat scheduler of linear + ExponentialLR&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Concat scheduler of linear + StepLR&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
<img alt="../_images/concat_linear_exp_step_lr.png" src="../_images/concat_linear_exp_step_lr.png" />
</section>
</section>
</section>
</section>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
      
        <a href="metrics.html" class="btn btn-neutral" title="ignite.contrib.metrics" accesskey="p" rel="prev">
          <img src="../_static/images/chevron-right-orange.svg" alt="left arrow" class="previous-page"> Previous
        </a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <table>
      <tr>
        <td>
            <p>
                &copy; Copyright 2026, PyTorch-Ignite Contributors.
              Last updated on 09/20/2019, 11:32:16 PM.
            </p>
            
              <div>
                Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
              </div>
          
        </td>
        <td>
            
              <div>
                <a href="https://www.netlify.com" target="_blank" rel="noopener noreferrer">
                  <img
                  src="_static/img/netlify-light.svg"
                  alt="Deploys by Netlify"
                  width=114
                  height=51 />
                </a>
              </div>
            
        </td>
      </tr>
    </table>
  </div> 

</footer>
          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">ignite.contrib.handlers</a><ul>
<li><a class="reference internal" href="#module-ignite.contrib.handlers.custom_events">custom_events</a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.custom_events.CustomPeriodicEvent"><code class="docutils literal notranslate"><span class="pre">CustomPeriodicEvent</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#module-ignite.contrib.handlers.param_scheduler">param_scheduler</a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ConcatScheduler"><code class="docutils literal notranslate"><span class="pre">ConcatScheduler</span></code></a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ConcatScheduler.get_param"><code class="docutils literal notranslate"><span class="pre">ConcatScheduler.get_param()</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ConcatScheduler.load_state_dict"><code class="docutils literal notranslate"><span class="pre">ConcatScheduler.load_state_dict()</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ConcatScheduler.simulate_values"><code class="docutils literal notranslate"><span class="pre">ConcatScheduler.simulate_values()</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ConcatScheduler.state_dict"><code class="docutils literal notranslate"><span class="pre">ConcatScheduler.state_dict()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.CosineAnnealingScheduler"><code class="docutils literal notranslate"><span class="pre">CosineAnnealingScheduler</span></code></a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.CosineAnnealingScheduler.get_param"><code class="docutils literal notranslate"><span class="pre">CosineAnnealingScheduler.get_param()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.CyclicalScheduler"><code class="docutils literal notranslate"><span class="pre">CyclicalScheduler</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.LRScheduler"><code class="docutils literal notranslate"><span class="pre">LRScheduler</span></code></a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.LRScheduler.get_param"><code class="docutils literal notranslate"><span class="pre">LRScheduler.get_param()</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.LRScheduler.simulate_values"><code class="docutils literal notranslate"><span class="pre">LRScheduler.simulate_values()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.LinearCyclicalScheduler"><code class="docutils literal notranslate"><span class="pre">LinearCyclicalScheduler</span></code></a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.LinearCyclicalScheduler.get_param"><code class="docutils literal notranslate"><span class="pre">LinearCyclicalScheduler.get_param()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ParamGroupScheduler"><code class="docutils literal notranslate"><span class="pre">ParamGroupScheduler</span></code></a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ParamGroupScheduler.load_state_dict"><code class="docutils literal notranslate"><span class="pre">ParamGroupScheduler.load_state_dict()</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ParamGroupScheduler.state_dict"><code class="docutils literal notranslate"><span class="pre">ParamGroupScheduler.state_dict()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ParamScheduler"><code class="docutils literal notranslate"><span class="pre">ParamScheduler</span></code></a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ParamScheduler.get_param"><code class="docutils literal notranslate"><span class="pre">ParamScheduler.get_param()</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ParamScheduler.load_state_dict"><code class="docutils literal notranslate"><span class="pre">ParamScheduler.load_state_dict()</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ParamScheduler.plot_values"><code class="docutils literal notranslate"><span class="pre">ParamScheduler.plot_values()</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ParamScheduler.simulate_values"><code class="docutils literal notranslate"><span class="pre">ParamScheduler.simulate_values()</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ParamScheduler.state_dict"><code class="docutils literal notranslate"><span class="pre">ParamScheduler.state_dict()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.PiecewiseLinear"><code class="docutils literal notranslate"><span class="pre">PiecewiseLinear</span></code></a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.PiecewiseLinear.get_param"><code class="docutils literal notranslate"><span class="pre">PiecewiseLinear.get_param()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.create_lr_scheduler_with_warmup"><code class="docutils literal notranslate"><span class="pre">create_lr_scheduler_with_warmup()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#tensorboard-logger">tensorboard_logger</a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.tensorboard_logger.GradsHistHandler"><code class="docutils literal notranslate"><span class="pre">GradsHistHandler</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.tensorboard_logger.GradsScalarHandler"><code class="docutils literal notranslate"><span class="pre">GradsScalarHandler</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.tensorboard_logger.OptimizerParamsHandler"><code class="docutils literal notranslate"><span class="pre">OptimizerParamsHandler</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.tensorboard_logger.OutputHandler"><code class="docutils literal notranslate"><span class="pre">OutputHandler</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.tensorboard_logger.TensorboardLogger"><code class="docutils literal notranslate"><span class="pre">TensorboardLogger</span></code></a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.tensorboard_logger.TensorboardLogger.attach"><code class="docutils literal notranslate"><span class="pre">TensorboardLogger.attach()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#ignite.contrib.handlers.tensorboard_logger.WeightsHistHandler"><code class="docutils literal notranslate"><span class="pre">WeightsHistHandler</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.tensorboard_logger.WeightsScalarHandler"><code class="docutils literal notranslate"><span class="pre">WeightsScalarHandler</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.tensorboard_logger.global_step_from_engine"><code class="docutils literal notranslate"><span class="pre">global_step_from_engine()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#visdom-logger">visdom_logger</a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.visdom_logger.GradsScalarHandler"><code class="docutils literal notranslate"><span class="pre">GradsScalarHandler</span></code></a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.visdom_logger.GradsScalarHandler.add_scalar"><code class="docutils literal notranslate"><span class="pre">GradsScalarHandler.add_scalar()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#ignite.contrib.handlers.visdom_logger.OptimizerParamsHandler"><code class="docutils literal notranslate"><span class="pre">OptimizerParamsHandler</span></code></a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.visdom_logger.OptimizerParamsHandler.add_scalar"><code class="docutils literal notranslate"><span class="pre">OptimizerParamsHandler.add_scalar()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#ignite.contrib.handlers.visdom_logger.OutputHandler"><code class="docutils literal notranslate"><span class="pre">OutputHandler</span></code></a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.visdom_logger.OutputHandler.add_scalar"><code class="docutils literal notranslate"><span class="pre">OutputHandler.add_scalar()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#ignite.contrib.handlers.visdom_logger.VisdomLogger"><code class="docutils literal notranslate"><span class="pre">VisdomLogger</span></code></a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.visdom_logger.VisdomLogger.attach"><code class="docutils literal notranslate"><span class="pre">VisdomLogger.attach()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#ignite.contrib.handlers.visdom_logger.WeightsScalarHandler"><code class="docutils literal notranslate"><span class="pre">WeightsScalarHandler</span></code></a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.visdom_logger.WeightsScalarHandler.add_scalar"><code class="docutils literal notranslate"><span class="pre">WeightsScalarHandler.add_scalar()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#ignite.contrib.handlers.visdom_logger.global_step_from_engine"><code class="docutils literal notranslate"><span class="pre">global_step_from_engine()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#module-ignite.contrib.handlers.mlflow_logger">mlflow_logger</a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.mlflow_logger.MLflowLogger"><code class="docutils literal notranslate"><span class="pre">MLflowLogger</span></code></a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.mlflow_logger.MLflowLogger.attach"><code class="docutils literal notranslate"><span class="pre">MLflowLogger.attach()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#ignite.contrib.handlers.mlflow_logger.OptimizerParamsHandler"><code class="docutils literal notranslate"><span class="pre">OptimizerParamsHandler</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.mlflow_logger.OutputHandler"><code class="docutils literal notranslate"><span class="pre">OutputHandler</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.mlflow_logger.global_step_from_engine"><code class="docutils literal notranslate"><span class="pre">global_step_from_engine()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#module-ignite.contrib.handlers.tqdm_logger">tqdm_logger</a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.tqdm_logger.ProgressBar"><code class="docutils literal notranslate"><span class="pre">ProgressBar</span></code></a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.tqdm_logger.ProgressBar.attach"><code class="docutils literal notranslate"><span class="pre">ProgressBar.attach()</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.tqdm_logger.ProgressBar.log_message"><code class="docutils literal notranslate"><span class="pre">ProgressBar.log_message()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#module-ignite.contrib.handlers.polyaxon_logger">polyaxon_logger</a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.polyaxon_logger.OptimizerParamsHandler"><code class="docutils literal notranslate"><span class="pre">OptimizerParamsHandler</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.polyaxon_logger.OutputHandler"><code class="docutils literal notranslate"><span class="pre">OutputHandler</span></code></a></li>
<li><a class="reference internal" href="#ignite.contrib.handlers.polyaxon_logger.PolyaxonLogger"><code class="docutils literal notranslate"><span class="pre">PolyaxonLogger</span></code></a><ul>
<li><a class="reference internal" href="#ignite.contrib.handlers.polyaxon_logger.PolyaxonLogger.attach"><code class="docutils literal notranslate"><span class="pre">PolyaxonLogger.attach()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#ignite.contrib.handlers.polyaxon_logger.global_step_from_engine"><code class="docutils literal notranslate"><span class="pre">global_step_from_engine()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#more-on-parameter-scheduling">More on parameter scheduling</a><ul>
<li><a class="reference internal" href="#example-with-ignite-contrib-handlers-cosineannealingscheduler">Example with <code class="xref py py-class docutils literal notranslate"><span class="pre">ignite.contrib.handlers.CosineAnnealingScheduler</span></code></a></li>
<li><a class="reference internal" href="#example-with-ignite-contrib-handlers-linearcyclicalscheduler">Example with <code class="xref py py-class docutils literal notranslate"><span class="pre">ignite.contrib.handlers.LinearCyclicalScheduler</span></code></a></li>
<li><a class="reference internal" href="#example-with-ignite-contrib-handlers-concatscheduler">Example with <code class="xref py py-class docutils literal notranslate"><span class="pre">ignite.contrib.handlers.ConcatScheduler</span></code></a><ul>
<li><a class="reference internal" href="#piecewise-linear-scheduler">Piecewise linear scheduler</a></li>
</ul>
</li>
<li><a class="reference internal" href="#example-with-ignite-contrib-handlers-lrscheduler">Example with <code class="xref py py-class docutils literal notranslate"><span class="pre">ignite.contrib.handlers.LRScheduler</span></code></a><ul>
<li><a class="reference internal" href="#concatenate-with-torch-schedulers">Concatenate with torch schedulers</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
         <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
         <script src="../_static/jquery.js"></script>
         <script src="../_static/underscore.js"></script>
         <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="../_static/doctools.js"></script>
         <script src="../_static/sphinx_highlight.js"></script>
         <script src="../_static/clipboard.min.js"></script>
         <script src="../_static/copybutton.js"></script>
         <script>let toggleHintShow = 'Show default setup';</script>
         <script>let toggleHintHide = 'Hide default setup';</script>
         <script>let toggleOpenOnPrint = 'true';</script>
         <script src="../_static/togglebutton.js"></script>
         <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
         <script src="../_static/design-tabs.js"></script>
     

  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <!-- commented out for Ignite -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <!-- <div class="container">
      <div class="row">
        <div class="text-center col-md-4">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/ignite/index.html">View Docs</a>
        </div>

        <div class="text-center col-md-4">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="">View Tutorials</a>
        </div>

        <div class="text-center col-md-4">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="">View Resources</a>
        </div>
      </div>
    </div> -->
  </div>

  <!-- <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch-ignite.ai" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch-ignite.ai">PyTorch</a></li>
            <li><a href="">Get Started</a></li>
            <li><a href="">Features</a></li>
            <li><a href="">Ecosystem</a></li>
            <li><a href="">Blog</a></li>
            <li><a href="">Resources</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="">Support</a></li>
            <li><a href="">Tutorials</a></li>
            <li><a href="https://pytorch.org/ignite/index.html">Docs</a></li>
            <li><a href="" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/ignite/issues" target="_blank">Github Issues</a></li>
            <li><a href="" target="_blank">Slack</a></li>
            <li><a href="https://github.com/pytorch/ignite/blob/master/CONTRIBUTING.md" target="_blank">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Follow Us</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>    <!~~ real people should not fill this in and expect good things - do not remove this or risk form bot signups ~~>

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="" target="_blank" class="facebook"></a>
            <a href="" target="_blank" class="twitter"></a>
          </div>
        </div>
      </div>
    </div>
  </footer> -->


  <!-- end of commented out for Ignite -->

  <!-- <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../_static/images/pytorch-x.svg">
  </div>
</div> -->

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->
  <!--
  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch-ignite.ai" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="#">Get Started</a>
          </li>

          <li>
            <a href="#">Features</a>
          </li>

          <li>
            <a href="#">Ecosystem</a>
          </li>

          <li>
            <a href="">Blog</a>
          </li>

          <li>
            <a href="">Tutorials</a>
          </li>

          <li>
            <a href="https://pytorch.org/ignite/index.html">Docs</a>
          </li>

          <li>
            <a href="">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/ignite">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>
  -->
  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    var collapsedSections = []
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
  <script src="https://cdn.jsdelivr.net/npm/@docsearch/js@3"></script>
  <script type="text/javascript">
  let VERSION
  if ('v0.3.0'.startsWith('v')) {
    VERSION = 'v0.3.0'
  } else {
    VERSION = 'master'
  }
  docsearch({
    container: '#docsearch',
    appId: '7EWYE1JCT3',
    apiKey: '841e93e60c16975ba1bd8c7c716eed82',
    indexName: 'pytorch-ignite',
    placeholder: 'Search PyTorch-Ignite docs',
    searchParameters: {
      facetFilters: [`version:${VERSION}`, 'tags:API-reference'],
    }
  });
  </script>
</body>
</html>