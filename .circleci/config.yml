version: 2.1

parameters:
  pytorch_stable_image:
    type: string
    # https://hub.docker.com/r/pytorch/pytorch/tags
    default: "pytorch/pytorch:1.4-cuda10.1-cudnn7-runtime"
  workingdir:
    type: string
    default: "/tmp/ignite"

# -------------------------------------------------------------------------------------
# Environments to run the jobs in
# -------------------------------------------------------------------------------------

one_gpu: &one_gpu
  machine:
    # https://circleci.com/docs/2.0/configuration-reference/#available-linux-gpu-images
    image: ubuntu-1604-cuda-10.1:201909-23  # CUDA 10.1, docker 19.03.0-ce, nvidia-docker 2.2.2
    docker_layer_caching: true
  # https://circleci.com/product/features/resource-classes/#linux-vm
  resource_class: gpu.small

two_gpus: &two_gpus
  machine:
    # https://circleci.com/docs/2.0/configuration-reference/#available-linux-gpu-images
    image: ubuntu-1604-cuda-10.1:201909-23  # CUDA 10.1, docker 19.03.0-ce, nvidia-docker 2.2.2
    docker_layer_caching: true
  # https://circleci.com/product/features/resource-classes/#linux-vm
  resource_class: gpu.medium


# -------------------------------------------------------------------------------------
# Re-usable commands
# -------------------------------------------------------------------------------------

pull_pytorch_stable_image: &pull_pytorch_stable_image
  - run:
      name: Pull PyTorch Stable Image
      command: |
        docker pull << pipeline.parameters.pytorch_stable_image >>


run_pytorch_container: &run_pytorch_container
  - run:
      name: Start Pytorch container
      environment:
        wd: << pipeline.parameters.workingdir >>
      command: |
        docker run --gpus=all --rm -itd -v ${wd}:/ignite -w /ignite --name pthd << pipeline.parameters.pytorch_stable_image >>
        docker exec -it pthd nvidia-smi
        docker exec -it pthd ls

install_dependencies: &install_dependencies
  - run:
      name: Install dependencies
      command: |
        docker exec -it pthd pip install -r requirements-dev.txt
        export install_ignite_cmd='pip install .'
        docker exec -it pthd /bin/bash -c "$install_ignite_cmd"

# -------------------------------------------------------------------------------------
# Jobs to run
# -------------------------------------------------------------------------------------
jobs:

  one_gpu_tests:
    <<: *one_gpu

    working_directory: << pipeline.parameters.workingdir >>

    steps:
      - checkout
      - <<: *pull_pytorch_stable_image
      - <<: *run_pytorch_container
      - <<: *install_dependencies
      - run:
          name: Run GPU Unit Tests
          command: |

            # pytest on cuda
            export test1_cmd='CUDA_VISIBLE_DEVICES=0 py.test -vvv tests/ -k "on_cuda"'
            docker exec -it pthd /bin/bash -c "$test1_cmd"

            # pytest on cuda and distributed (one process)
            export test2_cmd='export WORLD_SIZE=1 && py.test --dist=each --tx $WORLD_SIZE*popen//python=python3.7 tests -m distributed -vvv'
            docker exec -it pthd /bin/bash -c "$test2_cmd"

            # MNIST tests

            # 1) mnist.py
            export minst1_cmd='CUDA_VISIBLE_DEVICES=0 python examples/mnist/mnist.py --epochs=1'
            docker exec -it pthd /bin/bash -c "$minst1_cmd"

            # 2) mnist_with_visdom.py
            export visdom_script_cmd='python -c "from visdom.server import download_scripts; download_scripts()"'
            export visdom_cmd='python -m visdom.server'
            docker exec -d pthd /bin/bash -c "$visdom_script_cmd && $visdom_cmd"
            export sleep_cmd='sleep 10'
            export mnist2_cmd='python examples/mnist/mnist_with_visdom.py --epochs=1'
            docker exec -it pthd /bin/bash -c "$sleep_cmd && $mnist2_cmd"

            # 3.1) mnist_with_tensorboard.py with tbX
            export mnist3_cmd='CUDA_VISIBLE_DEVICES=0 python examples/mnist/mnist_with_tensorboard.py --epochs=1'
            docker exec -it pthd /bin/bash -c "$mnist3_cmd"

            # uninstall tensorboardX
            export pip_cmd='pip uninstall -y tensorboardX'
            docker exec -it pthd /bin/bash -c "$pip_cmd"

            # 3.2) mnist_with_tensorboard.py with native torch tb
            docker exec -it pthd /bin/bash -c "$mnist3_cmd"

            # 4) mnist_save_resume_engine.py
            # save
            export mnist4_cmd='CUDA_VISIBLE_DEVICES=0 python examples/mnist/mnist_save_resume_engine.py --epochs=1 --crash_iteration 700'
            docker exec -it pthd /bin/bash -c "$mnist4_cmd"
            # resume
            export mnist4_cmd='CUDA_VISIBLE_DEVICES=0 python examples/mnist/mnist_save_resume_engine.py --epochs=1 --resume_from=/tmp/mnist_save_resume/checkpoint_550.pt'
            docker exec -it pthd /bin/bash -c "$mnist4_cmd"

  two_gpus_tests:
    <<: *two_gpus

    working_directory: << pipeline.parameters.workingdir >>

    steps:
      - checkout
      - <<: *pull_pytorch_stable_image
      - <<: *run_pytorch_container
      - <<: *install_dependencies
      - run:
          name: Run 1 Node 2 GPUs Unit Tests
          command: |
            export test1_cmd='export WORLD_SIZE=2 && py.test --dist=each --tx $WORLD_SIZE*popen//python=python3.7 tests -m distributed -vvv'
            docker exec -it pthd /bin/bash -c "$test1_cmd"

# -------------------------------------------------------------------------------------
# Workflows
# -------------------------------------------------------------------------------------
workflows:
  version: 2
  gpu_tests:
    jobs:
      - one_gpu_tests
      - two_gpus_tests