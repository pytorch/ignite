version: 2.1

parameters:
  pytorch_stable_image:
    type: string
    # https://hub.docker.com/r/pytorch/pytorch/tags
    default: "pytorch/pytorch:1.5-cuda10.1-cudnn7-runtime"
  workingdir:
    type: string
    default: "/tmp/ignite"

# -------------------------------------------------------------------------------------
# Environments to run the jobs in
# -------------------------------------------------------------------------------------

one_gpu: &one_gpu
  machine:
    # https://circleci.com/docs/2.0/configuration-reference/#available-linux-gpu-images
    image: ubuntu-1604-cuda-10.1:201909-23  # CUDA 10.1, docker 19.03.0-ce, nvidia-docker 2.2.2
    docker_layer_caching: true
  # https://circleci.com/product/features/resource-classes/#linux-vm
  resource_class: gpu.small

two_gpus: &two_gpus
  machine:
    # https://circleci.com/docs/2.0/configuration-reference/#available-linux-gpu-images
    image: ubuntu-1604-cuda-10.1:201909-23  # CUDA 10.1, docker 19.03.0-ce, nvidia-docker 2.2.2
    docker_layer_caching: true
  # https://circleci.com/product/features/resource-classes/#linux-vm
  resource_class: gpu.medium


# -------------------------------------------------------------------------------------
# Re-usable commands
# -------------------------------------------------------------------------------------

pull_pytorch_stable_image: &pull_pytorch_stable_image
  - run:
      name: Pull PyTorch Stable Image
      command: |
        docker pull << pipeline.parameters.pytorch_stable_image >>


run_pytorch_container: &run_pytorch_container
  - run:
      name: Start Pytorch container
      environment:
        wd: << pipeline.parameters.workingdir >>
      command: |
        docker run --gpus=all --rm -itd --shm-size 16G -v ${wd}:/ignite -w /ignite --name pthd << pipeline.parameters.pytorch_stable_image >>
        docker exec -it pthd nvidia-smi
        docker exec -it pthd ls

install_dependencies: &install_dependencies
  - run:
      name: Install dependencies
      command: |
        docker exec -it pthd pip install -r requirements-dev.txt
        export install_ignite_cmd='pip install .'
        docker exec -it pthd /bin/bash -c "$install_ignite_cmd"

# -------------------------------------------------------------------------------------
# Jobs to run
# -------------------------------------------------------------------------------------
jobs:

  one_gpu_tests:
    <<: *one_gpu

    working_directory: << pipeline.parameters.workingdir >>

    steps:
      - checkout
      - <<: *pull_pytorch_stable_image
      - <<: *run_pytorch_container
      - <<: *install_dependencies
      - run:
          name: Run GPU Unit Tests
          command: |

            # pytest on cuda
            export test_cmd='sh tests/run_gpu_tests.sh'
            docker exec -it pthd /bin/bash -c "${test_cmd}"

            # MNIST tests

            # 1) mnist.py
            export minst1_cmd='CUDA_VISIBLE_DEVICES=0 python examples/mnist/mnist.py --epochs=1'
            docker exec -it pthd /bin/bash -c "$minst1_cmd"

            # 2) mnist_with_visdom.py
            export visdom_script_cmd='python -c "from visdom.server import download_scripts; download_scripts()"'
            export visdom_cmd='python -m visdom.server'
            docker exec -d pthd /bin/bash -c "$visdom_script_cmd && $visdom_cmd"
            export sleep_cmd='sleep 10'
            export mnist2_cmd='python examples/mnist/mnist_with_visdom.py --epochs=1'
            docker exec -it pthd /bin/bash -c "$sleep_cmd && $mnist2_cmd"

            # 3.1) mnist_with_tensorboard.py with tbX
            export mnist3_cmd='CUDA_VISIBLE_DEVICES=0 python examples/mnist/mnist_with_tensorboard.py --epochs=1'
            docker exec -it pthd /bin/bash -c "$mnist3_cmd"

            # uninstall tensorboardX
            export pip_cmd='pip uninstall -y tensorboardX'
            docker exec -it pthd /bin/bash -c "$pip_cmd"

            # 3.2) mnist_with_tensorboard.py with native torch tb
            docker exec -it pthd /bin/bash -c "$mnist3_cmd"

            # 4) mnist_save_resume_engine.py
            # save
            export mnist4_cmd='CUDA_VISIBLE_DEVICES=0 python examples/mnist/mnist_save_resume_engine.py --epochs=2 --crash_iteration 1100'
            docker exec -it pthd /bin/bash -c "$mnist4_cmd"
            # resume
            export mnist4_cmd='CUDA_VISIBLE_DEVICES=0 python examples/mnist/mnist_save_resume_engine.py --epochs=2 --resume_from=/tmp/mnist_save_resume/checkpoint_1.pt'
            docker exec -it pthd /bin/bash -c "$mnist4_cmd"

      - run:
          name: Codecov upload
          command: |
            bash <(curl -s https://codecov.io/bash) -Z -F gpu


  two_gpus_tests:
    <<: *two_gpus

    working_directory: << pipeline.parameters.workingdir >>

    steps:
      - checkout
      - <<: *pull_pytorch_stable_image
      - <<: *run_pytorch_container
      - <<: *install_dependencies
      - run:
          name: Run 1 Node 2 GPUs Unit Tests
          command: |
            export test_cmd='sh tests/run_gpu_tests.sh 2'
            docker exec -it pthd /bin/bash -c "${test_cmd}"

      - run:
          name: Codecov upload
          command: |
            bash <(curl -s https://codecov.io/bash) -Z -F gpu-2


  two_gpus_check_dist_cifar10_example:
    <<: *two_gpus

    working_directory: << pipeline.parameters.workingdir >>

    steps:
      - checkout
      - <<: *pull_pytorch_stable_image
      - <<: *run_pytorch_container
      - <<: *install_dependencies
      - run:
          name: "Install additional example dependencies"
          command: |
            docker exec -it pthd pip install fire
      - run:
          name: "Run without backend"
          command: |
            export example_path="examples/contrib/cifar10"
            # initial run
            export stop_cmd="--stop_iteration=500"
            export test_cmd="CI=1 python ${example_path}/main.py run"
            docker exec -it pthd /bin/bash -c "${test_cmd} ${stop_cmd}"
            # resume
            export resume_opt="--resume-from=/tmp/output-cifar10/resnet18_backend-None-1_stop-on-500/training_checkpoint_400.pt"
            docker exec -it pthd /bin/bash -c "${test_cmd} --num_epochs=7 ${resume_opt}"

      - run:
          name: "Run with NCCL backend using torch dist launch"
          command: |
            export example_path="examples/contrib/cifar10"
            # initial run
            export stop_cmd="--stop_iteration=500"
            export test_cmd="CI=1 python -u -m torch.distributed.launch --nproc_per_node=2 --use_env ${example_path}/main.py run --backend=nccl"
            docker exec -it pthd /bin/bash -c "${test_cmd} ${stop_cmd}"
            # resume
            export resume_opt="--resume-from=/tmp/output-cifar10/resnet18_backend-nccl-2_stop-on-500/training_checkpoint_400.pt"
            docker exec -it pthd /bin/bash -c "${test_cmd} --num_epochs=7 ${resume_opt}"

      - run:
          name: "Run with NCCL backend using spawn"
          command: |
            export example_path="examples/contrib/cifar10"
            # initial run
            export stop_cmd="--stop_iteration=500"
            export test_cmd="CI=1 python -u ${example_path}/main.py run --backend=nccl --nproc_per_node=2"
            docker exec -it pthd /bin/bash -c "${test_cmd} ${stop_cmd}"
            # resume
            export resume_opt="--resume-from=/tmp/output-cifar10/resnet18_backend-nccl-2_stop-on-500/training_checkpoint_400.pt"
            docker exec -it pthd /bin/bash -c "${test_cmd} --num_epochs=7 ${resume_opt}"


# -------------------------------------------------------------------------------------
# Workflows
# -------------------------------------------------------------------------------------
workflows:
  version: 2
  gpu_tests:
    jobs:
      - one_gpu_tests
      - two_gpus_tests
      - two_gpus_check_dist_cifar10_example
