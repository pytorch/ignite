version: 2.1

parameters:
  pytorch_stable_image:
    type: string
    # https://hub.docker.com/r/pytorch/pytorch/tags
    default: "pytorch/pytorch:1.4-cuda10.1-cudnn7-runtime"
  workingdir:
    type: string
    default: "/tmp/ignite"

# -------------------------------------------------------------------------------------
# Environments to run the jobs in
# -------------------------------------------------------------------------------------

one_gpu: &one_gpu
  machine:
    # https://circleci.com/docs/2.0/configuration-reference/#available-linux-gpu-images
    image: ubuntu-1604-cuda-10.1:201909-23  # CUDA 10.1, docker 19.03.0-ce, nvidia-docker 2.2.2
    docker_layer_caching: true
  # https://circleci.com/product/features/resource-classes/#linux-vm
  resource_class: gpu.small

two_gpus: &two_gpus
  machine:
    # https://circleci.com/docs/2.0/configuration-reference/#available-linux-gpu-images
    image: ubuntu-1604-cuda-10.1:201909-23  # CUDA 10.1, docker 19.03.0-ce, nvidia-docker 2.2.2
    docker_layer_caching: true
  # https://circleci.com/product/features/resource-classes/#linux-vm
  resource_class: gpu.medium


# -------------------------------------------------------------------------------------
# Re-usable commands
# -------------------------------------------------------------------------------------

pull_pytorch_stable_image: &pull_pytorch_stable_image
  - run:
      name: Pull PyTorch Stable Image
      command: |
        docker pull << pipeline.parameters.pytorch_stable_image >>


run_pytorch_container: &run_pytorch_container
  - run:
      name: Start Pytorch container
      environment:
        wd: << pipeline.parameters.workingdir >>
      command: |
        docker run --gpus=all --rm -itd -v ${wd}:/ignite -w /ignite --name pthd << pipeline.parameters.pytorch_stable_image >>
        docker exec -it pthd nvidia-smi
        docker exec -it pthd ls

install_dependencies: &install_dependencies
  - run:
      name: Install dependencies
      command: |
        docker exec -it pthd pip install \
          tqdm scikit-learn matplotlib tensorboardX visdom polyaxon-client \
          mlflow neptune-client tensorboard pynvml \
          numpy pytest codecov pytest-cov pytest-xdist \
          pandas gym


# -------------------------------------------------------------------------------------
# Jobs to run
# -------------------------------------------------------------------------------------
jobs:

  one_gpu_tests:
    <<: *one_gpu

    working_directory: << pipeline.parameters.workingdir >>

    steps:
      - checkout
      - <<: *pull_pytorch_stable_image
      - <<: *run_pytorch_container
      - <<: *install_dependencies
      - run:
          name: Run GPU Unit Tests
          command: |
            export test1_cmd='CUDA_VISIBLE_DEVICES=0 py.test -vvv tests/ -k "on_cuda"'
            docker exec -it pthd /bin/bash -c "$test1_cmd"
            export test2_cmd='export WORLD_SIZE=1 && py.test --dist=each --tx $WORLD_SIZE*popen//python=python3.7 tests -m distributed -vvv'
            docker exec -it pthd /bin/bash -c "$test2_cmd"

  two_gpus_tests:
    <<: *two_gpus

    working_directory: << pipeline.parameters.workingdir >>

    steps:
      - checkout
      - <<: *pull_pytorch_stable_image
      - <<: *run_pytorch_container
      - <<: *install_dependencies
      - run:
          name: Run 1 Node 2 GPUs Unit Tests
          command: |
            export test1_cmd='export WORLD_SIZE=2 && py.test --dist=each --tx $WORLD_SIZE*popen//python=python3.7 tests -m distributed -vvv'
            docker exec -it pthd /bin/bash -c "$test1_cmd"

# -------------------------------------------------------------------------------------
# Workflows
# -------------------------------------------------------------------------------------
workflows:
  version: 2
  gpu_tests:
    jobs:
      - one_gpu_tests
      - two_gpus_tests