version: 2.1

parameters:
  pytorch_stable_image:
    type: string
    # https://hub.docker.com/r/pytorch/pytorch/tags
    default: "pytorch/pytorch:1.6.0-cuda10.1-cudnn7-runtime"
  pytorch_stable_image_devel:
    type: string
    # https://hub.docker.com/r/pytorch/pytorch/tags
    default: "pytorch/pytorch:1.6.0-cuda10.1-cudnn7-devel"
  workingdir:
    type: string
    default: "/tmp/ignite"

# -------------------------------------------------------------------------------------
# Environments to run the jobs in
# -------------------------------------------------------------------------------------

one_gpu: &one_gpu
  machine:
    # https://circleci.com/docs/2.0/configuration-reference/#available-linux-gpu-images
    image: ubuntu-1604-cuda-10.1:201909-23  # CUDA 10.1, docker 19.03.0-ce, nvidia-docker 2.2.2
    docker_layer_caching: true
  # https://circleci.com/product/features/resource-classes/#linux-vm
  resource_class: gpu.small

two_gpus: &two_gpus
  machine:
    # https://circleci.com/docs/2.0/configuration-reference/#available-linux-gpu-images
    image: ubuntu-1604-cuda-10.1:201909-23  # CUDA 10.1, docker 19.03.0-ce, nvidia-docker 2.2.2
    docker_layer_caching: true
  # https://circleci.com/product/features/resource-classes/#linux-vm
  resource_class: gpu.medium


# -------------------------------------------------------------------------------------
# Re-usable commands
# -------------------------------------------------------------------------------------

pull_pytorch_stable_image: &pull_pytorch_stable_image
  - run:
      name: Pull PyTorch Stable Image
      command: |
        docker pull << pipeline.parameters.pytorch_stable_image >>

pull_pytorch_stable_devel_image: &pull_pytorch_stable_devel_image
  - run:
      name: Pull PyTorch Stable Develop Image
      command: |
        docker pull << pipeline.parameters.pytorch_stable_image_devel >>


run_pytorch_container: &run_pytorch_container
  - run:
      name: Start Pytorch container
      environment:
        wd: << pipeline.parameters.workingdir >>
      command: |
        docker run --gpus=all --rm -itd --shm-size 16G -v ${wd}:/ignite -w /ignite --name pthd << pipeline.parameters.pytorch_stable_image >>
        docker exec -it pthd nvidia-smi
        docker exec -it pthd ls


run_pytorch_devel_container: &run_pytorch_devel_container
  - run:
      name: Start Pytorch dev container
      environment:
        wd: << pipeline.parameters.workingdir >>
      command: |
        docker run --gpus=all --rm -itd --shm-size 16G -v ${wd}:/ignite -w /ignite --name pthd << pipeline.parameters.pytorch_stable_image_devel >>
        docker exec -it pthd nvidia-smi
        docker exec -it pthd ls

install_dependencies: &install_dependencies
  - run:
      name: Install dependencies
      command: |
        docker exec -it pthd pip install -r requirements-dev.txt
        export install_ignite_cmd='pip install .'
        docker exec -it pthd /bin/bash -c "$install_ignite_cmd"

# -------------------------------------------------------------------------------------
# Jobs to run
# -------------------------------------------------------------------------------------
jobs:

  one_gpu_tests:
    <<: *one_gpu

    working_directory: << pipeline.parameters.workingdir >>

    steps:
      - checkout
      - <<: *pull_pytorch_stable_image
      - <<: *run_pytorch_container
      - <<: *install_dependencies
      - run:
          name: Run GPU Unit Tests
          command: |

            # pytest on cuda
            export test_cmd='sh tests/run_gpu_tests.sh'
            docker exec -it pthd /bin/bash -c "${test_cmd}"

            # MNIST tests

            # 1) mnist.py
            export minst1_cmd='CUDA_VISIBLE_DEVICES=0 python examples/mnist/mnist.py --epochs=1'
            docker exec -it pthd /bin/bash -c "$minst1_cmd"

            # 2) mnist_with_visdom.py
            export visdom_script_cmd='python -c "from visdom.server import download_scripts; download_scripts()"'
            export visdom_cmd='python -m visdom.server'
            docker exec -d pthd /bin/bash -c "$visdom_script_cmd && $visdom_cmd"
            export sleep_cmd='sleep 10'
            export mnist2_cmd='python examples/mnist/mnist_with_visdom.py --epochs=1'
            docker exec -it pthd /bin/bash -c "$sleep_cmd && $mnist2_cmd"

            # 3.1) mnist_with_tensorboard.py with tbX
            export mnist3_cmd='CUDA_VISIBLE_DEVICES=0 python examples/mnist/mnist_with_tensorboard.py --epochs=1'
            docker exec -it pthd /bin/bash -c "$mnist3_cmd"

            # uninstall tensorboardX
            export pip_cmd='pip uninstall -y tensorboardX'
            docker exec -it pthd /bin/bash -c "$pip_cmd"

            # 3.2) mnist_with_tensorboard.py with native torch tb
            docker exec -it pthd /bin/bash -c "$mnist3_cmd"

            # 4) mnist_save_resume_engine.py
            # save
            export mnist4_cmd='CUDA_VISIBLE_DEVICES=0 python examples/mnist/mnist_save_resume_engine.py --epochs=2 --crash_iteration 1100'
            docker exec -it pthd /bin/bash -c "$mnist4_cmd"
            # resume
            export mnist4_cmd='CUDA_VISIBLE_DEVICES=0 python examples/mnist/mnist_save_resume_engine.py --epochs=2 --resume_from=/tmp/mnist_save_resume/checkpoint_1.pt'
            docker exec -it pthd /bin/bash -c "$mnist4_cmd"

      - run:
          name: Codecov upload
          command: |
            bash <(curl -s https://codecov.io/bash) -Z -F gpu


  two_gpus_tests:
    <<: *two_gpus

    working_directory: << pipeline.parameters.workingdir >>

    steps:
      - checkout
      - <<: *pull_pytorch_stable_image
      - <<: *run_pytorch_container
      - <<: *install_dependencies
      - run:
          name: Run 1 Node 2 GPUs Unit Tests
          command: |
            export test_cmd='sh tests/run_gpu_tests.sh 2'
            docker exec -it pthd /bin/bash -c "${test_cmd}"

      - run:
          name: Codecov upload
          command: |
            bash <(curl -s https://codecov.io/bash) -Z -F gpu-2


  two_gpus_check_dist_cifar10_example:
    <<: *two_gpus

    working_directory: << pipeline.parameters.workingdir >>

    steps:
      - checkout
      - <<: *pull_pytorch_stable_image
      - <<: *run_pytorch_container
      - <<: *install_dependencies
      - run:
          name: "Install additional example dependencies"
          command: |
            docker exec -it pthd pip install fire
      - run:
          name: "Run without backend"
          command: |
            export example_path="examples/contrib/cifar10"
            # initial run
            export stop_cmd="--stop_iteration=500"
            export test_cmd="CI=1 python ${example_path}/main.py run"
            docker exec -it pthd /bin/bash -c "${test_cmd} ${stop_cmd}"
            # resume
            export resume_opt="--resume-from=/tmp/output-cifar10/resnet18_backend-None-1_stop-on-500/training_checkpoint_400.pt"
            docker exec -it pthd /bin/bash -c "${test_cmd} --num_epochs=7 ${resume_opt}"

      - run:
          name: "Run with NCCL backend using torch dist launch"
          command: |
            export example_path="examples/contrib/cifar10"
            # initial run
            export stop_cmd="--stop_iteration=500"
            export test_cmd="CI=1 python -u -m torch.distributed.launch --nproc_per_node=2 --use_env ${example_path}/main.py run --backend=nccl"
            docker exec -it pthd /bin/bash -c "${test_cmd} ${stop_cmd}"
            # resume
            export resume_opt="--resume-from=/tmp/output-cifar10/resnet18_backend-nccl-2_stop-on-500/training_checkpoint_400.pt"
            docker exec -it pthd /bin/bash -c "${test_cmd} --num_epochs=7 ${resume_opt}"

      - run:
          name: "Run with NCCL backend using spawn"
          command: |
            export example_path="examples/contrib/cifar10"
            # initial run
            export stop_cmd="--stop_iteration=500"
            export test_cmd="CI=1 python -u ${example_path}/main.py run --backend=nccl --nproc_per_node=2"
            docker exec -it pthd /bin/bash -c "${test_cmd} ${stop_cmd}"
            # resume
            export resume_opt="--resume-from=/tmp/output-cifar10/resnet18_backend-nccl-2_stop-on-500/training_checkpoint_400.pt"
            docker exec -it pthd /bin/bash -c "${test_cmd} --num_epochs=7 ${resume_opt}"


  two_gpus_hvd_tests:
    <<: *two_gpus

    working_directory: << pipeline.parameters.workingdir >>

    steps:
      - checkout
      - <<: *pull_pytorch_stable_devel_image
      - <<: *run_pytorch_devel_container
      - <<: *install_dependencies
      - run:
          name: "Install Horovod with NCCL GPU ops"
          command: |

            # Following https://github.com/horovod/horovod/blob/master/Dockerfile.test.gpu
            # and https://github.com/horovod/horovod/issues/1944#issuecomment-628192778
            docker exec -it pthd /bin/bash -c "apt-get update && apt-get install -y git"
            docker exec -it pthd /bin/bash -c "git clone --recursive https://github.com/horovod/horovod.git /horovod && cd /horovod && python setup.py sdist"
            docker exec -it pthd /bin/bash -c "conda install -y cmake=3.16 nccl=2.7 -c conda-forge"
            docker exec -it pthd /bin/bash -c 'cd /horovod && HOROVOD_GPU_OPERATIONS=NCCL HOROVOD_NCCL_LINK=SHARED HOROVOD_WITHOUT_MPI=1 HOROVOD_WITH_PYTORCH=1 pip install -v $(ls /horovod/dist/horovod-*.tar.gz) && ldconfig'
            docker exec -it pthd horovodrun --check-build

      - run:
          name: Run 1 Node 2 GPUs Unit Tests
          command: |
            export test_cmd='sh tests/run_gpu_tests.sh'
            docker exec -it pthd /bin/bash -c "${test_cmd}"
            # no CUDA devices Horovod tests
            export test_cmd='CUDA_VISIBLE_DEVICES="" py.test --cov ignite --cov-append --cov-report term-missing --cov-report xml -vvv tests/ -m distributed'
            docker exec -it pthd /bin/bash -c "${test_cmd}"

      - run:
          name: Codecov upload
          command: |
            bash <(curl -s https://codecov.io/bash) -Z -F gpu-2-hvd

      - run:
          name: "Check CIFAR10 using horovodrun"
          command: |
            docker exec -it pthd pip install fire
            export example_path="examples/contrib/cifar10"
            # initial run
            export stop_cmd="--stop_iteration=500"
            export test_cmd="cd ${example_path} && CI=1 horovodrun -np 2 python -u main.py run --backend=horovod"
            docker exec -it pthd /bin/bash -c "${test_cmd} ${stop_cmd}"
            # resume
            export resume_opt="--resume-from=/tmp/output-cifar10/resnet18_backend-horovod-2_stop-on-500/training_checkpoint_400.pt"
            docker exec -it pthd /bin/bash -c "${test_cmd} --num_epochs=7 ${resume_opt}"

      - run:
          name: "Check CIFAR10 using spawn"
          command: |
            export example_path="examples/contrib/cifar10"
            # initial run
            export stop_cmd="--stop_iteration=500"
            export test_cmd="cd ${example_path} && CI=1 python -u main.py run --backend=horovod --nproc_per_node=2"
            docker exec -it pthd /bin/bash -c "${test_cmd} ${stop_cmd}"
            # resume
            export resume_opt="--resume-from=/tmp/output-cifar10/resnet18_backend-horovod-2_stop-on-500/training_checkpoint_400.pt"
            docker exec -it pthd /bin/bash -c "${test_cmd} --num_epochs=7 ${resume_opt}"


# -------------------------------------------------------------------------------------
# Workflows
# -------------------------------------------------------------------------------------
workflows:
  version: 2
  gpu_tests:
    jobs:
      - one_gpu_tests
      - two_gpus_tests
      - two_gpus_check_dist_cifar10_example
      - two_gpus_hvd_tests
